//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_61
.address_size 64

	// .globl	fused_qkv_attention_forward
.extern .shared .align 16 .b8 smem[];

.visible .entry fused_qkv_attention_forward(
	.param .u64 fused_qkv_attention_forward_param_0,
	.param .u64 fused_qkv_attention_forward_param_1,
	.param .u64 fused_qkv_attention_forward_param_2,
	.param .u64 fused_qkv_attention_forward_param_3,
	.param .u32 fused_qkv_attention_forward_param_4,
	.param .u32 fused_qkv_attention_forward_param_5,
	.param .u32 fused_qkv_attention_forward_param_6,
	.param .u32 fused_qkv_attention_forward_param_7,
	.param .u32 fused_qkv_attention_forward_param_8
)
{
	.local .align 16 .b8 	__local_depot0[1024];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<89>;
	.reg .f32 	%f<337>;
	.reg .b32 	%r<309>;
	.reg .b64 	%rd<180>;
	.loc	1 22 0


	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd64, [fused_qkv_attention_forward_param_0];
	ld.param.u64 	%rd65, [fused_qkv_attention_forward_param_1];
	ld.param.u64 	%rd63, [fused_qkv_attention_forward_param_2];
	ld.param.u64 	%rd66, [fused_qkv_attention_forward_param_3];
	ld.param.u32 	%r125, [fused_qkv_attention_forward_param_4];
	ld.param.u32 	%r121, [fused_qkv_attention_forward_param_5];
	ld.param.u32 	%r122, [fused_qkv_attention_forward_param_6];
	ld.param.u32 	%r123, [fused_qkv_attention_forward_param_7];
	ld.param.u32 	%r124, [fused_qkv_attention_forward_param_8];
	cvta.to.global.u64 	%rd1, %rd65;
	cvta.to.global.u64 	%rd2, %rd64;
	cvta.to.global.u64 	%rd3, %rd66;
	.loc	1 35 19
	add.u64 	%rd4, %SPL, 0;
	mov.u32 	%r1, %tid.x;
	.loc	1 36 24
	add.s32 	%r126, %r121, 15;
	shr.s32 	%r127, %r126, 31;
	shr.u32 	%r128, %r127, 28;
	add.s32 	%r129, %r126, %r128;
	shr.s32 	%r2, %r129, 4;
	.loc	1 37 28
	mul.lo.s32 	%r130, %r123, %r125;
	mul.lo.s32 	%r131, %r130, %r2;
	.loc	1 38 25
	mov.u32 	%r3, %ctaid.x;
	.loc	1 40 5
	setp.ge.s32 	%p3, %r3, %r131;
	@%p3 bra 	$L__BB0_109;

	.loc	1 44 22
	div.s32 	%r132, %r3, %r2;
	.loc	1 45 23
	mul.lo.s32 	%r133, %r132, %r2;
	sub.s32 	%r134, %r3, %r133;
	.loc	1 46 17
	div.s32 	%r135, %r132, %r123;
	.loc	1 47 17
	mul.lo.s32 	%r4, %r135, %r123;
	sub.s32 	%r5, %r132, %r4;
	.loc	1 49 23
	shl.b32 	%r6, %r134, 4;
	.loc	1 50 34
	mul.lo.s32 	%r136, %r122, %r121;
	.loc	1 51 29
	mul.lo.s32 	%r137, %r136, %r135;
	cvt.s64.s32 	%rd5, %r137;
	.loc	1 53 34
	mul.lo.s32 	%r138, %r124, %r122;
	.loc	1 54 33
	mul.lo.s32 	%r139, %r138, %r123;
	.loc	1 56 22
	mul.lo.s32 	%r140, %r5, %r138;
	cvt.s64.s32 	%rd6, %r140;
	.loc	1 57 22
	cvt.s64.s32 	%rd70, %r139;
	add.s64 	%rd7, %rd6, %rd70;
	.loc	1 58 22
	shl.b32 	%r141, %r139, 1;
	cvt.s64.s32 	%rd71, %r141;
	add.s64 	%rd8, %rd6, %rd71;
	.loc	1 60 22
	mul.lo.s32 	%r142, %r5, %r124;
	cvta.to.global.u64 	%rd72, %rd63;
	mul.wide.s32 	%rd73, %r142, 4;
	add.s64 	%rd9, %rd72, %rd73;
	add.s64 	%rd10, %rd63, %rd73;
	setp.eq.s64 	%p1, %rd63, 0;
	mov.u64 	%rd173, 0;
	.loc	1 61 22
	mov.u64 	%rd171, %rd173;
	mov.u64 	%rd172, %rd173;
	@%p1 bra 	$L__BB0_3;

	mul.lo.s32 	%r143, %r124, %r123;
	mul.wide.s32 	%rd74, %r143, 4;
	add.s64 	%rd171, %rd9, %rd74;
	add.s64 	%rd172, %rd10, %rd74;

$L__BB0_3:
	.loc	1 62 22
	mov.u64 	%rd174, %rd173;
	@%p1 bra 	$L__BB0_5;

	mul.lo.s32 	%r144, %r123, %r124;
	shl.b32 	%r145, %r144, 1;
	mul.wide.s32 	%rd77, %r145, 4;
	add.s64 	%rd173, %rd9, %rd77;
	add.s64 	%rd174, %rd10, %rd77;

$L__BB0_5:
	.loc	1 65 19
	shl.b32 	%r7, %r124, 4;
	.loc	1 69 5
	setp.ge.s32 	%p5, %r1, %r7;
	.loc	1 60 22
	selp.b64 	%rd19, 0, %rd9, %p1;
	.loc	1 69 5
	@%p5 bra 	$L__BB0_35;

	.loc	1 0 5
	setp.eq.s64 	%p7, %rd10, 0;
	or.pred  	%p8, %p1, %p7;
	.loc	1 69 42
	mov.u32 	%r8, %ntid.x;
	.loc	1 75 9
	@%p8 bra 	$L__BB0_18;
	bra.uni 	$L__BB0_7;

$L__BB0_18:
	.loc	1 0 9
	setp.gt.s32 	%p17, %r122, 0;
	.loc	1 75 9
	@%p17 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_19;

$L__BB0_25:
	add.s32 	%r34, %r122, -1;
	and.b32  	%r35, %r122, 3;
	sub.s32 	%r36, %r122, %r35;
	mov.u32 	%r278, %r1;

$L__BB0_26:
	.loc	1 70 21
	div.s32 	%r38, %r278, %r124;
	.loc	1 72 23
	add.s32 	%r39, %r38, %r6;
	.loc	1 78 9
	setp.ge.s32 	%p22, %r39, %r121;
	mov.f32 	%f300, 0f00000000;
	@%p22 bra 	$L__BB0_34;

	.loc	1 0 9
	setp.lt.u32 	%p23, %r34, 3;
	.loc	1 79 33
	mul.lo.s32 	%r172, %r39, %r122;
	cvt.s64.s32 	%rd94, %r172;
	add.s64 	%rd24, %rd94, %rd5;
	.loc	1 71 21
	mul.lo.s32 	%r173, %r38, %r124;
	sub.s32 	%r174, %r278, %r173;
	.loc	1 80 32
	mul.lo.s32 	%r175, %r174, %r122;
	cvt.s64.s32 	%rd95, %r175;
	add.s64 	%rd25, %rd95, %rd6;
	mov.f32 	%f300, 0f00000000;
	mov.u32 	%r281, 0;
	.loc	1 81 13
	@%p23 bra 	$L__BB0_30;

	.loc	1 0 13
	mov.u32 	%r280, %r36;

$L__BB0_29:
	.loc	1 82 17
	cvt.s64.s32 	%rd96, %r281;
	add.s64 	%rd97, %rd24, %rd96;
	shl.b64 	%rd98, %rd97, 2;
	add.s64 	%rd99, %rd2, %rd98;
	add.s64 	%rd100, %rd25, %rd96;
	shl.b64 	%rd101, %rd100, 2;
	add.s64 	%rd102, %rd1, %rd101;
	ld.global.nc.f32 	%f114, [%rd102];
	ld.global.nc.f32 	%f115, [%rd99];
	fma.rn.ftz.f32 	%f116, %f115, %f114, %f300;
	ld.global.nc.f32 	%f117, [%rd102+4];
	ld.global.nc.f32 	%f118, [%rd99+4];
	fma.rn.ftz.f32 	%f119, %f118, %f117, %f116;
	ld.global.nc.f32 	%f120, [%rd102+8];
	ld.global.nc.f32 	%f121, [%rd99+8];
	fma.rn.ftz.f32 	%f122, %f121, %f120, %f119;
	ld.global.nc.f32 	%f123, [%rd102+12];
	ld.global.nc.f32 	%f124, [%rd99+12];
	fma.rn.ftz.f32 	%f300, %f124, %f123, %f122;
	.loc	1 81 45
	add.s32 	%r281, %r281, 4;
	.loc	1 81 13
	add.s32 	%r280, %r280, -4;
	setp.ne.s32 	%p24, %r280, 0;
	@%p24 bra 	$L__BB0_29;

$L__BB0_30:
	.loc	1 0 13
	setp.eq.s32 	%p25, %r35, 0;
	.loc	1 81 13
	@%p25 bra 	$L__BB0_34;

	.loc	1 0 13
	setp.eq.s32 	%p26, %r35, 1;
	.loc	1 82 17
	cvt.s64.s32 	%rd103, %r281;
	add.s64 	%rd104, %rd24, %rd103;
	shl.b64 	%rd105, %rd104, 2;
	add.s64 	%rd26, %rd2, %rd105;
	add.s64 	%rd106, %rd25, %rd103;
	shl.b64 	%rd107, %rd106, 2;
	add.s64 	%rd27, %rd1, %rd107;
	ld.global.nc.f32 	%f125, [%rd27];
	ld.global.nc.f32 	%f126, [%rd26];
	fma.rn.ftz.f32 	%f300, %f126, %f125, %f300;
	.loc	1 81 13
	@%p26 bra 	$L__BB0_34;

	.loc	1 0 13
	setp.eq.s32 	%p27, %r35, 2;
	.loc	1 82 17
	ld.global.nc.f32 	%f127, [%rd27+4];
	ld.global.nc.f32 	%f128, [%rd26+4];
	fma.rn.ftz.f32 	%f300, %f128, %f127, %f300;
	.loc	1 81 13
	@%p27 bra 	$L__BB0_34;

	.loc	1 82 17
	ld.global.nc.f32 	%f129, [%rd27+8];
	ld.global.nc.f32 	%f130, [%rd26+8];
	fma.rn.ftz.f32 	%f300, %f130, %f129, %f300;

$L__BB0_34:
	.loc	1 85 9
	shl.b32 	%r177, %r278, 2;
	mov.u32 	%r178, smem;
	add.s32 	%r179, %r178, %r177;
	st.shared.f32 	[%r179], %f300;
	.loc	1 69 42
	add.s32 	%r278, %r278, %r8;
	.loc	1 69 5
	setp.lt.s32 	%p28, %r278, %r7;
	@%p28 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_35;

$L__BB0_7:
	.loc	1 75 9
	add.s32 	%r9, %r122, -1;
	and.b32  	%r10, %r122, 3;
	sub.s32 	%r11, %r122, %r10;
	mov.u32 	%r269, %r1;

$L__BB0_8:
	.loc	1 70 21
	div.s32 	%r146, %r269, %r124;
	.loc	1 71 21
	mul.lo.s32 	%r147, %r146, %r124;
	sub.s32 	%r13, %r269, %r147;
	.loc	1 72 23
	add.s32 	%r14, %r146, %r6;
	.loc	1 76 13
	mul.wide.s32 	%rd78, %r13, 4;
	add.s64 	%rd79, %rd19, %rd78;
	ld.global.nc.f32 	%f296, [%rd79];
	.loc	1 78 9
	setp.ge.s32 	%p9, %r14, %r121;
	@%p9 bra 	$L__BB0_17;

	.loc	1 0 9
	setp.lt.s32 	%p10, %r122, 1;
	.loc	1 79 33
	mul.lo.s32 	%r148, %r14, %r122;
	cvt.s64.s32 	%rd80, %r148;
	add.s64 	%rd20, %rd80, %rd5;
	.loc	1 80 32
	mul.lo.s32 	%r149, %r13, %r122;
	cvt.s64.s32 	%rd81, %r149;
	add.s64 	%rd21, %rd81, %rd6;
	.loc	1 81 13
	@%p10 bra 	$L__BB0_17;

	.loc	1 0 13
	setp.lt.u32 	%p11, %r9, 3;
	mov.u32 	%r272, 0;
	.loc	1 81 13
	@%p11 bra 	$L__BB0_13;

	.loc	1 0 13
	mov.u32 	%r271, %r11;

$L__BB0_12:
	.loc	1 82 17
	cvt.s64.s32 	%rd82, %r272;
	add.s64 	%rd83, %rd20, %rd82;
	shl.b64 	%rd84, %rd83, 2;
	add.s64 	%rd85, %rd2, %rd84;
	add.s64 	%rd86, %rd21, %rd82;
	shl.b64 	%rd87, %rd86, 2;
	add.s64 	%rd88, %rd1, %rd87;
	ld.global.nc.f32 	%f93, [%rd88];
	ld.global.nc.f32 	%f94, [%rd85];
	fma.rn.ftz.f32 	%f95, %f94, %f93, %f296;
	ld.global.nc.f32 	%f96, [%rd88+4];
	ld.global.nc.f32 	%f97, [%rd85+4];
	fma.rn.ftz.f32 	%f98, %f97, %f96, %f95;
	ld.global.nc.f32 	%f99, [%rd88+8];
	ld.global.nc.f32 	%f100, [%rd85+8];
	fma.rn.ftz.f32 	%f101, %f100, %f99, %f98;
	ld.global.nc.f32 	%f102, [%rd88+12];
	ld.global.nc.f32 	%f103, [%rd85+12];
	fma.rn.ftz.f32 	%f296, %f103, %f102, %f101;
	.loc	1 81 45
	add.s32 	%r272, %r272, 4;
	.loc	1 81 13
	add.s32 	%r271, %r271, -4;
	setp.ne.s32 	%p12, %r271, 0;
	@%p12 bra 	$L__BB0_12;

$L__BB0_13:
	.loc	1 0 13
	setp.eq.s32 	%p13, %r10, 0;
	.loc	1 81 13
	@%p13 bra 	$L__BB0_17;

	.loc	1 0 13
	setp.eq.s32 	%p14, %r10, 1;
	.loc	1 82 17
	cvt.s64.s32 	%rd89, %r272;
	add.s64 	%rd90, %rd20, %rd89;
	shl.b64 	%rd91, %rd90, 2;
	add.s64 	%rd22, %rd2, %rd91;
	add.s64 	%rd92, %rd21, %rd89;
	shl.b64 	%rd93, %rd92, 2;
	add.s64 	%rd23, %rd1, %rd93;
	ld.global.nc.f32 	%f104, [%rd23];
	ld.global.nc.f32 	%f105, [%rd22];
	fma.rn.ftz.f32 	%f296, %f105, %f104, %f296;
	.loc	1 81 13
	@%p14 bra 	$L__BB0_17;

	.loc	1 0 13
	setp.eq.s32 	%p15, %r10, 2;
	.loc	1 82 17
	ld.global.nc.f32 	%f106, [%rd23+4];
	ld.global.nc.f32 	%f107, [%rd22+4];
	fma.rn.ftz.f32 	%f296, %f107, %f106, %f296;
	.loc	1 81 13
	@%p15 bra 	$L__BB0_17;

	.loc	1 82 17
	ld.global.nc.f32 	%f108, [%rd23+8];
	ld.global.nc.f32 	%f109, [%rd22+8];
	fma.rn.ftz.f32 	%f296, %f109, %f108, %f296;

$L__BB0_17:
	.loc	1 85 9
	shl.b32 	%r152, %r269, 2;
	mov.u32 	%r153, smem;
	add.s32 	%r154, %r153, %r152;
	st.shared.f32 	[%r154], %f296;
	.loc	1 69 42
	add.s32 	%r269, %r269, %r8;
	.loc	1 69 5
	setp.lt.s32 	%p16, %r269, %r7;
	@%p16 bra 	$L__BB0_8;

$L__BB0_35:
	.loc	1 88 5
	bar.sync 	0;
	.loc	1 90 21
	add.s32 	%r46, %r6, %r1;
	.loc	1 91 23
	setp.lt.s32 	%p29, %r46, %r121;
	setp.lt.s32 	%p30, %r1, 16;
	and.pred  	%p2, %p30, %p29;
	not.pred 	%p31, %p2;
	.loc	1 95 23
	cvt.rn.f32.s32 	%f131, %r124;
	.loc	1 95 25
	rsqrt.approx.ftz.f32 	%f18, %f131;
	.loc	1 96 24
	mul.lo.s32 	%r180, %r1, %r124;
	shl.b32 	%r181, %r180, 2;
	mov.u32 	%r182, smem;
	add.s32 	%r183, %r182, %r181;
	selp.b32 	%r47, %r183, 0, %p2;
	.loc	1 99 9
	setp.lt.s32 	%p32, %r124, 1;
	.loc	1 98 5
	or.pred  	%p33, %p31, %p32;
	@%p33 bra 	$L__BB0_42;

	.loc	1 99 9
	add.s32 	%r185, %r124, -1;
	and.b32  	%r286, %r124, 3;
	setp.lt.u32 	%p34, %r185, 3;
	mov.u32 	%r284, 0;
	@%p34 bra 	$L__BB0_39;

	sub.s32 	%r283, %r124, %r286;

$L__BB0_38:
	.loc	1 100 13
	mul.wide.s32 	%rd108, %r284, 4;
	add.s64 	%rd109, %rd4, %rd108;
	mov.f32 	%f132, 0f00000000;
	st.local.v4.f32 	[%rd109], {%f132, %f132, %f132, %f132};
	.loc	1 99 39
	add.s32 	%r284, %r284, 4;
	.loc	1 99 9
	add.s32 	%r283, %r283, -4;
	setp.ne.s32 	%p35, %r283, 0;
	@%p35 bra 	$L__BB0_38;

$L__BB0_39:
	setp.eq.s32 	%p36, %r286, 0;
	@%p36 bra 	$L__BB0_42;

$L__BB0_41:
	.pragma "nounroll";
	.loc	1 100 13
	mul.wide.s32 	%rd110, %r284, 4;
	add.s64 	%rd111, %rd4, %rd110;
	mov.u32 	%r187, 0;
	st.local.u32 	[%rd111], %r187;
	.loc	1 99 39
	add.s32 	%r284, %r284, 1;
	.loc	1 99 9
	add.s32 	%r286, %r286, -1;
	setp.ne.s32 	%p37, %r286, 0;
	@%p37 bra 	$L__BB0_41;

$L__BB0_42:
	.loc	1 104 5
	setp.lt.s32 	%p38, %r121, 1;
	mov.f32 	%f334, 0f00000000;
	@%p38 bra 	$L__BB0_99;

	.loc	1 106 46
	mov.u32 	%r59, %ntid.x;
	.loc	1 106 9
	add.s32 	%r60, %r122, -1;
	not.b32 	%r61, %r121;
	add.s32 	%r62, %r124, -1;
	and.b32  	%r63, %r122, 3;
	sub.s32 	%r64, %r122, %r63;
	and.b32  	%r65, %r124, 3;
	sub.s32 	%r66, %r124, %r65;
	mul.ftz.f32 	%f19, %f18, 0f00000000;
	shl.b64 	%rd112, %rd7, 2;
	add.s64 	%rd113, %rd1, %rd112;
	add.s64 	%rd28, %rd113, 8;
	shl.b64 	%rd114, %rd5, 2;
	add.s64 	%rd115, %rd2, %rd114;
	add.s64 	%rd29, %rd115, 8;
	shl.b64 	%rd116, %rd8, 2;
	add.s64 	%rd117, %rd1, %rd116;
	add.s64 	%rd30, %rd117, 8;
	mov.f32 	%f333, 0fFF7FFFFF;
	mov.u32 	%r287, 0;
	mov.u32 	%r288, %r287;
	bra.uni 	$L__BB0_44;

$L__BB0_75:
	shl.b32 	%r256, %r287, 4;
	add.s32 	%r255, %r256, %r61;
	max.s32 	%r254, %r255, -17;
	not.b32 	%r253, %r254;
	max.s32 	%r252, %r253, 1;
	.loc	1 142 17
	and.b32  	%r88, %r252, 3;
	.loc	1 106 9
	add.s32 	%r220, %r252, -1;
	.loc	1 142 17
	setp.lt.u32 	%p62, %r220, 3;
	@%p62 bra 	$L__BB0_78;

	.loc	1 106 9
	shl.b32 	%r261, %r287, 4;
	add.s32 	%r260, %r261, %r61;
	max.s32 	%r259, %r260, -17;
	not.b32 	%r258, %r259;
	max.s32 	%r257, %r258, 1;
	.loc	1 142 17
	sub.s32 	%r297, %r257, %r88;
	mov.f32 	%f322, %f333;

$L__BB0_77:
	.loc	1 147 37
	max.ftz.f32 	%f333, %f322, %f19;
	.loc	1 148 37
	sub.ftz.f32 	%f199, %f322, %f333;
	.loc	1 148 39
	mul.ftz.f32 	%f200, %f199, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f201, %f200;
	.loc	1 149 37
	sub.ftz.f32 	%f202, %f19, %f333;
	.loc	1 149 39
	mul.ftz.f32 	%f203, %f202, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f204, %f203;
	.loc	1 151 17
	fma.rn.ftz.f32 	%f205, %f334, %f201, %f204;
	.loc	1 148 37
	sub.ftz.f32 	%f206, %f333, %f333;
	.loc	1 148 39
	mul.ftz.f32 	%f207, %f206, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f208, %f207;
	.loc	1 151 17
	fma.rn.ftz.f32 	%f209, %f205, %f208, %f204;
	fma.rn.ftz.f32 	%f210, %f209, %f208, %f204;
	fma.rn.ftz.f32 	%f334, %f210, %f208, %f204;
	.loc	1 137 13
	add.s32 	%r297, %r297, -4;
	setp.ne.s32 	%p63, %r297, 0;
	mov.f32 	%f322, %f333;
	@%p63 bra 	$L__BB0_77;

$L__BB0_78:
	.loc	1 142 17
	setp.eq.s32 	%p64, %r88, 0;
	@%p64 bra 	$L__BB0_98;

	.loc	1 147 37
	max.ftz.f32 	%f67, %f333, %f19;
	.loc	1 148 37
	sub.ftz.f32 	%f211, %f333, %f67;
	.loc	1 148 39
	mul.ftz.f32 	%f212, %f211, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f213, %f212;
	.loc	1 149 37
	sub.ftz.f32 	%f214, %f19, %f67;
	.loc	1 149 39
	mul.ftz.f32 	%f215, %f214, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f68, %f215;
	.loc	1 151 17
	fma.rn.ftz.f32 	%f334, %f334, %f213, %f68;
	.loc	1 137 13
	setp.eq.s32 	%p65, %r88, 1;
	mov.f32 	%f333, %f67;
	@%p65 bra 	$L__BB0_98;

	.loc	1 148 37
	sub.ftz.f32 	%f216, %f67, %f67;
	.loc	1 148 39
	mul.ftz.f32 	%f217, %f216, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f70, %f217;
	.loc	1 151 17
	fma.rn.ftz.f32 	%f334, %f334, %f70, %f68;
	.loc	1 137 13
	setp.eq.s32 	%p66, %r88, 2;
	mov.f32 	%f333, %f67;
	@%p66 bra 	$L__BB0_98;

	.loc	1 151 17
	fma.rn.ftz.f32 	%f334, %f334, %f70, %f68;
	mov.f32 	%f333, %f67;
	bra.uni 	$L__BB0_98;

$L__BB0_44:
	.loc	1 106 9
	@%p5 bra 	$L__BB0_72;

	.loc	1 0 9
	setp.eq.s64 	%p40, %rd172, 0;
	.loc	1 113 13
	@%p40 bra 	$L__BB0_59;

	.loc	1 0 13
	mov.u32 	%r289, %r1;

$L__BB0_47:
	.loc	1 107 25
	div.s32 	%r194, %r289, %r124;
	.loc	1 108 25
	mul.lo.s32 	%r195, %r194, %r124;
	sub.s32 	%r196, %r289, %r195;
	.loc	1 109 27
	add.s32 	%r71, %r194, %r288;
	.loc	1 114 17
	cvt.s64.s32 	%rd31, %r196;
	mul.wide.s32 	%rd118, %r196, 4;
	add.s64 	%rd119, %rd171, %rd118;
	ld.global.nc.f32 	%f310, [%rd119];
	setp.eq.s64 	%p41, %rd174, 0;
	mov.f32 	%f311, 0f00000000;
	.loc	1 116 13
	@%p41 bra 	$L__BB0_49;

	.loc	1 117 17
	shl.b64 	%rd120, %rd31, 2;
	add.s64 	%rd121, %rd173, %rd120;
	ld.global.nc.f32 	%f311, [%rd121];

$L__BB0_49:
	.loc	1 119 13
	setp.ge.s32 	%p42, %r71, %r121;
	@%p42 bra 	$L__BB0_58;

	.loc	1 0 13
	cvt.u32.u64 	%r197, %rd31;
	.loc	1 120 37
	mul.lo.s32 	%r198, %r71, %r122;
	cvt.s64.s32 	%rd32, %r198;
	.loc	1 121 37
	mul.lo.s32 	%r199, %r197, %r122;
	cvt.s64.s32 	%rd33, %r199;
	setp.lt.s32 	%p43, %r122, 1;
	.loc	1 123 17
	@%p43 bra 	$L__BB0_58;

	.loc	1 0 17
	setp.lt.u32 	%p44, %r60, 3;
	mov.u32 	%r292, 0;
	.loc	1 123 17
	@%p44 bra 	$L__BB0_54;

	shl.b64 	%rd122, %rd33, 2;
	add.s64 	%rd177, %rd28, %rd122;
	shl.b64 	%rd123, %rd32, 2;
	add.s64 	%rd176, %rd29, %rd123;
	add.s64 	%rd175, %rd30, %rd122;
	mov.u32 	%r291, %r64;

$L__BB0_53:
	.loc	1 125 21
	ld.global.nc.f32 	%f138, [%rd177+-8];
	.loc	1 124 40
	ld.global.nc.f32 	%f139, [%rd176+-8];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f140, %f139, %f138, %f310;
	.loc	1 126 21
	ld.global.nc.f32 	%f141, [%rd175+-8];
	fma.rn.ftz.f32 	%f142, %f139, %f141, %f311;
	.loc	1 125 21
	ld.global.nc.f32 	%f143, [%rd177+-4];
	.loc	1 124 40
	ld.global.nc.f32 	%f144, [%rd176+-4];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f145, %f144, %f143, %f140;
	.loc	1 126 21
	ld.global.nc.f32 	%f146, [%rd175+-4];
	fma.rn.ftz.f32 	%f147, %f144, %f146, %f142;
	.loc	1 125 21
	ld.global.nc.f32 	%f148, [%rd177];
	.loc	1 124 40
	ld.global.nc.f32 	%f149, [%rd176];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f150, %f149, %f148, %f145;
	.loc	1 126 21
	ld.global.nc.f32 	%f151, [%rd175];
	fma.rn.ftz.f32 	%f152, %f149, %f151, %f147;
	.loc	1 125 21
	ld.global.nc.f32 	%f153, [%rd177+4];
	.loc	1 124 40
	ld.global.nc.f32 	%f154, [%rd176+4];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f310, %f154, %f153, %f150;
	.loc	1 126 21
	ld.global.nc.f32 	%f155, [%rd175+4];
	fma.rn.ftz.f32 	%f311, %f154, %f155, %f152;
	.loc	1 123 49
	add.s32 	%r292, %r292, 4;
	.loc	1 123 17
	add.s64 	%rd177, %rd177, 16;
	add.s64 	%rd176, %rd176, 16;
	add.s64 	%rd175, %rd175, 16;
	add.s32 	%r291, %r291, -4;
	setp.ne.s32 	%p45, %r291, 0;
	@%p45 bra 	$L__BB0_53;

$L__BB0_54:
	.loc	1 0 17
	setp.eq.s32 	%p46, %r63, 0;
	.loc	1 123 17
	@%p46 bra 	$L__BB0_58;

	.loc	1 0 17
	setp.eq.s32 	%p47, %r63, 1;
	.loc	1 124 40
	cvt.s64.s32 	%rd124, %r292;
	.loc	1 120 37
	add.s64 	%rd125, %rd32, %rd5;
	.loc	1 124 40
	add.s64 	%rd126, %rd125, %rd124;
	shl.b64 	%rd127, %rd126, 2;
	add.s64 	%rd43, %rd2, %rd127;
	.loc	1 121 37
	add.s64 	%rd128, %rd7, %rd33;
	.loc	1 125 21
	add.s64 	%rd129, %rd128, %rd124;
	shl.b64 	%rd130, %rd129, 2;
	add.s64 	%rd44, %rd1, %rd130;
	ld.global.nc.f32 	%f156, [%rd44];
	.loc	1 124 40
	ld.global.nc.f32 	%f157, [%rd43];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f310, %f157, %f156, %f310;
	.loc	1 122 37
	add.s64 	%rd131, %rd8, %rd33;
	.loc	1 126 21
	add.s64 	%rd132, %rd131, %rd124;
	shl.b64 	%rd133, %rd132, 2;
	add.s64 	%rd45, %rd1, %rd133;
	ld.global.nc.f32 	%f158, [%rd45];
	fma.rn.ftz.f32 	%f311, %f157, %f158, %f311;
	.loc	1 123 17
	@%p47 bra 	$L__BB0_58;

	.loc	1 0 17
	setp.eq.s32 	%p48, %r63, 2;
	.loc	1 125 21
	ld.global.nc.f32 	%f159, [%rd44+4];
	.loc	1 124 40
	ld.global.nc.f32 	%f160, [%rd43+4];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f310, %f160, %f159, %f310;
	.loc	1 126 21
	ld.global.nc.f32 	%f161, [%rd45+4];
	fma.rn.ftz.f32 	%f311, %f160, %f161, %f311;
	.loc	1 123 17
	@%p48 bra 	$L__BB0_58;

	.loc	1 125 21
	ld.global.nc.f32 	%f162, [%rd44+8];
	.loc	1 124 40
	ld.global.nc.f32 	%f163, [%rd43+8];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f310, %f163, %f162, %f310;
	.loc	1 126 21
	ld.global.nc.f32 	%f164, [%rd45+8];
	fma.rn.ftz.f32 	%f311, %f163, %f164, %f311;

$L__BB0_58:
	.loc	1 129 13
	add.s32 	%r202, %r289, %r7;
	shl.b32 	%r203, %r202, 2;
	add.s32 	%r205, %r182, %r203;
	st.shared.f32 	[%r205], %f310;
	.loc	1 130 13
	shl.b32 	%r206, %r7, 2;
	add.s32 	%r207, %r205, %r206;
	st.shared.f32 	[%r207], %f311;
	.loc	1 106 46
	add.s32 	%r289, %r289, %r59;
	.loc	1 106 9
	setp.lt.s32 	%p49, %r289, %r7;
	@%p49 bra 	$L__BB0_47;
	bra.uni 	$L__BB0_72;

$L__BB0_59:
	.loc	1 0 9
	mov.u32 	%r293, %r1;

$L__BB0_60:
	.loc	1 107 25
	div.s32 	%r208, %r293, %r124;
	.loc	1 108 25
	mul.lo.s32 	%r209, %r208, %r124;
	sub.s32 	%r79, %r293, %r209;
	.loc	1 109 27
	add.s32 	%r80, %r208, %r288;
	setp.eq.s64 	%p50, %rd174, 0;
	mov.f32 	%f320, 0f00000000;
	.loc	1 116 13
	@%p50 bra 	$L__BB0_62;

	.loc	1 117 17
	mul.wide.s32 	%rd134, %r79, 4;
	add.s64 	%rd135, %rd173, %rd134;
	ld.global.nc.f32 	%f320, [%rd135];

$L__BB0_62:
	.loc	1 0 17
	mov.f32 	%f319, 0f00000000;
	.loc	1 119 13
	setp.ge.s32 	%p51, %r80, %r121;
	@%p51 bra 	$L__BB0_71;

	.loc	1 0 13
	mov.f32 	%f319, 0f00000000;
	setp.lt.s32 	%p52, %r122, 1;
	.loc	1 120 37
	mul.lo.s32 	%r210, %r80, %r122;
	cvt.s64.s32 	%rd136, %r210;
	add.s64 	%rd46, %rd136, %rd5;
	.loc	1 121 37
	mul.lo.s32 	%r211, %r79, %r122;
	cvt.s64.s32 	%rd137, %r211;
	add.s64 	%rd47, %rd7, %rd137;
	.loc	1 122 37
	add.s64 	%rd48, %rd8, %rd137;
	.loc	1 123 17
	@%p52 bra 	$L__BB0_71;

	.loc	1 0 17
	setp.lt.u32 	%p53, %r60, 3;
	mov.f32 	%f319, 0f00000000;
	mov.u32 	%r296, 0;
	.loc	1 123 17
	@%p53 bra 	$L__BB0_67;

	.loc	1 0 17
	mov.u32 	%r295, %r64;

$L__BB0_66:
	.loc	1 124 40
	cvt.s64.s32 	%rd138, %r296;
	add.s64 	%rd139, %rd46, %rd138;
	shl.b64 	%rd140, %rd139, 2;
	add.s64 	%rd141, %rd2, %rd140;
	.loc	1 125 21
	add.s64 	%rd142, %rd47, %rd138;
	shl.b64 	%rd143, %rd142, 2;
	add.s64 	%rd144, %rd1, %rd143;
	ld.global.nc.f32 	%f171, [%rd144];
	.loc	1 124 40
	ld.global.nc.f32 	%f172, [%rd141];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f173, %f172, %f171, %f319;
	.loc	1 126 21
	add.s64 	%rd145, %rd48, %rd138;
	shl.b64 	%rd146, %rd145, 2;
	add.s64 	%rd147, %rd1, %rd146;
	ld.global.nc.f32 	%f174, [%rd147];
	fma.rn.ftz.f32 	%f175, %f172, %f174, %f320;
	.loc	1 125 21
	ld.global.nc.f32 	%f176, [%rd144+4];
	.loc	1 124 40
	ld.global.nc.f32 	%f177, [%rd141+4];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f178, %f177, %f176, %f173;
	.loc	1 126 21
	ld.global.nc.f32 	%f179, [%rd147+4];
	fma.rn.ftz.f32 	%f180, %f177, %f179, %f175;
	.loc	1 125 21
	ld.global.nc.f32 	%f181, [%rd144+8];
	.loc	1 124 40
	ld.global.nc.f32 	%f182, [%rd141+8];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f183, %f182, %f181, %f178;
	.loc	1 126 21
	ld.global.nc.f32 	%f184, [%rd147+8];
	fma.rn.ftz.f32 	%f185, %f182, %f184, %f180;
	.loc	1 125 21
	ld.global.nc.f32 	%f186, [%rd144+12];
	.loc	1 124 40
	ld.global.nc.f32 	%f187, [%rd141+12];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f319, %f187, %f186, %f183;
	.loc	1 126 21
	ld.global.nc.f32 	%f188, [%rd147+12];
	fma.rn.ftz.f32 	%f320, %f187, %f188, %f185;
	.loc	1 123 49
	add.s32 	%r296, %r296, 4;
	.loc	1 123 17
	add.s32 	%r295, %r295, -4;
	setp.ne.s32 	%p54, %r295, 0;
	@%p54 bra 	$L__BB0_66;

$L__BB0_67:
	.loc	1 0 17
	setp.eq.s32 	%p55, %r63, 0;
	.loc	1 123 17
	@%p55 bra 	$L__BB0_71;

	.loc	1 0 17
	setp.eq.s32 	%p56, %r63, 1;
	.loc	1 124 40
	cvt.s64.s32 	%rd148, %r296;
	add.s64 	%rd149, %rd46, %rd148;
	shl.b64 	%rd150, %rd149, 2;
	add.s64 	%rd49, %rd2, %rd150;
	.loc	1 125 21
	add.s64 	%rd151, %rd47, %rd148;
	shl.b64 	%rd152, %rd151, 2;
	add.s64 	%rd50, %rd1, %rd152;
	ld.global.nc.f32 	%f189, [%rd50];
	.loc	1 124 40
	ld.global.nc.f32 	%f190, [%rd49];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f319, %f190, %f189, %f319;
	.loc	1 126 21
	add.s64 	%rd153, %rd48, %rd148;
	shl.b64 	%rd154, %rd153, 2;
	add.s64 	%rd51, %rd1, %rd154;
	ld.global.nc.f32 	%f191, [%rd51];
	fma.rn.ftz.f32 	%f320, %f190, %f191, %f320;
	.loc	1 123 17
	@%p56 bra 	$L__BB0_71;

	.loc	1 0 17
	setp.eq.s32 	%p57, %r63, 2;
	.loc	1 125 21
	ld.global.nc.f32 	%f192, [%rd50+4];
	.loc	1 124 40
	ld.global.nc.f32 	%f193, [%rd49+4];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f319, %f193, %f192, %f319;
	.loc	1 126 21
	ld.global.nc.f32 	%f194, [%rd51+4];
	fma.rn.ftz.f32 	%f320, %f193, %f194, %f320;
	.loc	1 123 17
	@%p57 bra 	$L__BB0_71;

	.loc	1 125 21
	ld.global.nc.f32 	%f195, [%rd50+8];
	.loc	1 124 40
	ld.global.nc.f32 	%f196, [%rd49+8];
	.loc	1 125 21
	fma.rn.ftz.f32 	%f319, %f196, %f195, %f319;
	.loc	1 126 21
	ld.global.nc.f32 	%f197, [%rd51+8];
	fma.rn.ftz.f32 	%f320, %f196, %f197, %f320;

$L__BB0_71:
	.loc	1 129 13
	add.s32 	%r214, %r293, %r7;
	shl.b32 	%r215, %r214, 2;
	add.s32 	%r217, %r182, %r215;
	st.shared.f32 	[%r217], %f319;
	.loc	1 130 13
	shl.b32 	%r218, %r7, 2;
	add.s32 	%r219, %r217, %r218;
	st.shared.f32 	[%r219], %f320;
	.loc	1 106 46
	add.s32 	%r293, %r293, %r59;
	.loc	1 106 9
	setp.lt.s32 	%p58, %r293, %r7;
	@%p58 bra 	$L__BB0_60;

$L__BB0_72:
	.loc	1 133 9
	bar.sync 	0;
	.loc	1 135 9
	@%p31 bra 	$L__BB0_98;

	.loc	1 136 32
	sub.s32 	%r87, %r121, %r288;
	.loc	1 137 13
	setp.lt.s32 	%p60, %r87, 1;
	@%p60 bra 	$L__BB0_98;

	.loc	1 99 9
	setp.gt.s32 	%p61, %r124, 0;
	.loc	1 142 17
	@%p61 bra 	$L__BB0_82;
	bra.uni 	$L__BB0_75;

$L__BB0_82:
	.loc	1 0 17
	mov.u32 	%r298, 0;

$L__BB0_83:
	mov.f32 	%f74, %f333;
	mov.u32 	%r301, 0;
	.loc	1 138 36
	mad.lo.s32 	%r94, %r298, %r124, %r7;
	setp.lt.u32 	%p67, %r62, 3;
	mov.f32 	%f332, 0f00000000;
	.loc	1 142 17
	@%p67 bra 	$L__BB0_86;

	.loc	1 0 17
	mov.u32 	%r301, 0;
	mov.u32 	%r300, %r66;

$L__BB0_85:
	.loc	1 143 21
	add.s32 	%r224, %r94, %r301;
	shl.b32 	%r225, %r224, 2;
	add.s32 	%r227, %r182, %r225;
	ld.shared.f32 	%f221, [%r227];
	shl.b32 	%r228, %r301, 2;
	add.s32 	%r229, %r47, %r228;
	ld.shared.f32 	%f222, [%r229];
	fma.rn.ftz.f32 	%f223, %f222, %f221, %f332;
	ld.shared.f32 	%f224, [%r227+4];
	ld.shared.f32 	%f225, [%r229+4];
	fma.rn.ftz.f32 	%f226, %f225, %f224, %f223;
	ld.shared.f32 	%f227, [%r227+8];
	ld.shared.f32 	%f228, [%r229+8];
	fma.rn.ftz.f32 	%f229, %f228, %f227, %f226;
	ld.shared.f32 	%f230, [%r227+12];
	ld.shared.f32 	%f231, [%r229+12];
	fma.rn.ftz.f32 	%f332, %f231, %f230, %f229;
	.loc	1 142 47
	add.s32 	%r301, %r301, 4;
	.loc	1 142 17
	add.s32 	%r300, %r300, -4;
	setp.ne.s32 	%p68, %r300, 0;
	@%p68 bra 	$L__BB0_85;

$L__BB0_86:
	.loc	1 0 17
	setp.eq.s32 	%p69, %r65, 0;
	.loc	1 142 17
	@%p69 bra 	$L__BB0_90;

	.loc	1 0 17
	setp.eq.s32 	%p70, %r65, 1;
	.loc	1 143 21
	add.s32 	%r230, %r94, %r301;
	shl.b32 	%r231, %r230, 2;
	add.s32 	%r100, %r182, %r231;
	ld.shared.f32 	%f232, [%r100];
	shl.b32 	%r233, %r301, 2;
	add.s32 	%r101, %r47, %r233;
	ld.shared.f32 	%f233, [%r101];
	fma.rn.ftz.f32 	%f332, %f233, %f232, %f332;
	.loc	1 142 17
	@%p70 bra 	$L__BB0_90;

	.loc	1 0 17
	setp.eq.s32 	%p71, %r65, 2;
	.loc	1 143 21
	ld.shared.f32 	%f234, [%r100+4];
	ld.shared.f32 	%f235, [%r101+4];
	fma.rn.ftz.f32 	%f332, %f235, %f234, %f332;
	.loc	1 142 17
	@%p71 bra 	$L__BB0_90;

	.loc	1 143 21
	ld.shared.f32 	%f236, [%r100+8];
	ld.shared.f32 	%f237, [%r101+8];
	fma.rn.ftz.f32 	%f332, %f237, %f236, %f332;

$L__BB0_90:
	.loc	1 0 21
	setp.lt.u32 	%p87, %r62, 3;
	.loc	1 146 35
	mul.ftz.f32 	%f238, %f18, %f332;
	.loc	1 147 37
	max.ftz.f32 	%f333, %f74, %f238;
	.loc	1 148 37
	sub.ftz.f32 	%f239, %f74, %f333;
	.loc	1 148 39
	mul.ftz.f32 	%f240, %f239, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f84, %f240;
	.loc	1 149 37
	sub.ftz.f32 	%f241, %f238, %f333;
	.loc	1 149 39
	mul.ftz.f32 	%f242, %f241, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f85, %f242;
	.loc	1 151 17
	fma.rn.ftz.f32 	%f334, %f334, %f84, %f85;
	mov.u32 	%r304, 0;
	.loc	1 152 17
	@%p87 bra 	$L__BB0_93;

	.loc	1 0 17
	mov.u32 	%r303, %r66;

$L__BB0_92:
	.loc	1 138 36
	mad.lo.s32 	%r266, %r298, %r124, %r7;
	add.s32 	%r265, %r266, %r7;
	.loc	1 153 21
	mul.wide.s32 	%rd155, %r304, 4;
	add.s64 	%rd156, %rd4, %rd155;
	ld.local.v4.f32 	{%f243, %f244, %f245, %f246}, [%rd156];
	add.s32 	%r236, %r265, %r304;
	shl.b32 	%r237, %r236, 2;
	add.s32 	%r239, %r182, %r237;
	ld.shared.f32 	%f251, [%r239];
	mul.ftz.f32 	%f252, %f85, %f251;
	ld.shared.f32 	%f253, [%r239+4];
	mul.ftz.f32 	%f254, %f85, %f253;
	ld.shared.f32 	%f255, [%r239+8];
	mul.ftz.f32 	%f256, %f85, %f255;
	ld.shared.f32 	%f257, [%r239+12];
	mul.ftz.f32 	%f258, %f85, %f257;
	fma.rn.ftz.f32 	%f259, %f84, %f246, %f258;
	fma.rn.ftz.f32 	%f260, %f84, %f245, %f256;
	fma.rn.ftz.f32 	%f261, %f84, %f244, %f254;
	fma.rn.ftz.f32 	%f262, %f84, %f243, %f252;
	st.local.v4.f32 	[%rd156], {%f262, %f261, %f260, %f259};
	.loc	1 152 47
	add.s32 	%r304, %r304, 4;
	.loc	1 152 17
	add.s32 	%r303, %r303, -4;
	setp.ne.s32 	%p73, %r303, 0;
	@%p73 bra 	$L__BB0_92;

$L__BB0_93:
	.loc	1 0 17
	setp.eq.s32 	%p88, %r65, 0;
	.loc	1 152 17
	@%p88 bra 	$L__BB0_97;

	.loc	1 138 36
	mad.lo.s32 	%r268, %r298, %r124, %r7;
	add.s32 	%r267, %r268, %r7;
	setp.eq.s32 	%p75, %r65, 1;
	.loc	1 153 21
	mul.wide.s32 	%rd157, %r304, 4;
	add.s64 	%rd52, %rd4, %rd157;
	ld.local.f32 	%f263, [%rd52];
	add.s32 	%r240, %r267, %r304;
	shl.b32 	%r241, %r240, 2;
	add.s32 	%r108, %r182, %r241;
	ld.shared.f32 	%f264, [%r108];
	mul.ftz.f32 	%f265, %f85, %f264;
	fma.rn.ftz.f32 	%f266, %f84, %f263, %f265;
	st.local.f32 	[%rd52], %f266;
	.loc	1 152 17
	@%p75 bra 	$L__BB0_97;

	.loc	1 0 17
	setp.eq.s32 	%p76, %r65, 2;
	.loc	1 153 21
	ld.local.f32 	%f267, [%rd52+4];
	ld.shared.f32 	%f268, [%r108+4];
	mul.ftz.f32 	%f269, %f85, %f268;
	fma.rn.ftz.f32 	%f270, %f84, %f267, %f269;
	st.local.f32 	[%rd52+4], %f270;
	.loc	1 152 17
	@%p76 bra 	$L__BB0_97;

	.loc	1 153 21
	ld.local.f32 	%f271, [%rd52+8];
	ld.shared.f32 	%f272, [%r108+8];
	mul.ftz.f32 	%f273, %f85, %f272;
	fma.rn.ftz.f32 	%f274, %f84, %f271, %f273;
	st.local.f32 	[%rd52+8], %f274;

$L__BB0_97:
	.loc	1 136 32
	sub.s32 	%r263, %r121, %r288;
	.loc	1 136 34
	min.s32 	%r262, %r263, 16;
	.loc	1 137 43
	add.s32 	%r298, %r298, 1;
	.loc	1 137 13
	setp.lt.s32 	%p77, %r298, %r262;
	@%p77 bra 	$L__BB0_83;

$L__BB0_98:
	.loc	1 159 9
	bar.sync 	0;
	.loc	1 104 48
	add.s32 	%r288, %r288, 16;
	.loc	1 104 5
	setp.lt.s32 	%p78, %r288, %r121;
	add.s32 	%r287, %r287, 1;
	@%p78 bra 	$L__BB0_44;

$L__BB0_99:
	.loc	1 162 5
	@%p31 bra 	$L__BB0_109;

	.loc	1 163 27
	setp.leu.ftz.f32 	%p80, %f334, 0f00000000;
	mov.f32 	%f336, 0f00000000;
	@%p80 bra 	$L__BB0_102;

	rcp.approx.ftz.f32 	%f336, %f334;

$L__BB0_102:
	.loc	1 0 27
	ld.param.u32 	%r251, [fused_qkv_attention_forward_param_7];
	.loc	1 47 17
	mul.lo.s32 	%r250, %r135, %r251;
	.loc	1 99 9
	setp.lt.s32 	%p86, %r124, 1;
	.loc	1 164 31
	mul.lo.s32 	%r243, %r124, %r121;
	mul.lo.s32 	%r244, %r250, %r243;
	.loc	1 166 24
	cvt.s64.s32 	%rd53, %r244;
	mul.lo.s32 	%r245, %r5, %r243;
	cvt.s64.s32 	%rd54, %r245;
	mul.lo.s32 	%r246, %r46, %r124;
	cvt.s64.s32 	%rd55, %r246;
	.loc	1 168 9
	@%p86 bra 	$L__BB0_109;

	add.s32 	%r248, %r124, -1;
	and.b32  	%r308, %r124, 3;
	setp.lt.u32 	%p82, %r248, 3;
	mov.u32 	%r307, 0;
	@%p82 bra 	$L__BB0_106;

	sub.s32 	%r306, %r124, %r308;
	.loc	1 166 24
	add.s64 	%rd158, %rd54, %rd53;
	add.s64 	%rd56, %rd158, %rd55;

$L__BB0_105:
	.loc	1 169 13
	cvt.s64.s32 	%rd159, %r307;
	mul.wide.s32 	%rd160, %r307, 4;
	add.s64 	%rd161, %rd4, %rd160;
	ld.local.v4.f32 	{%f276, %f277, %f278, %f279}, [%rd161];
	mul.ftz.f32 	%f284, %f336, %f276;
	add.s64 	%rd162, %rd56, %rd159;
	shl.b64 	%rd163, %rd162, 2;
	add.s64 	%rd164, %rd3, %rd163;
	st.global.f32 	[%rd164], %f284;
	mul.ftz.f32 	%f285, %f336, %f277;
	st.global.f32 	[%rd164+4], %f285;
	mul.ftz.f32 	%f286, %f336, %f278;
	st.global.f32 	[%rd164+8], %f286;
	mul.ftz.f32 	%f287, %f336, %f279;
	st.global.f32 	[%rd164+12], %f287;
	.loc	1 168 39
	add.s32 	%r307, %r307, 4;
	.loc	1 168 9
	add.s32 	%r306, %r306, -4;
	setp.ne.s32 	%p83, %r306, 0;
	@%p83 bra 	$L__BB0_105;

$L__BB0_106:
	setp.eq.s32 	%p84, %r308, 0;
	@%p84 bra 	$L__BB0_109;

	cvt.s64.s32 	%rd165, %r307;
	add.s64 	%rd166, %rd165, %rd53;
	add.s64 	%rd167, %rd166, %rd54;
	add.s64 	%rd168, %rd167, %rd55;
	shl.b64 	%rd169, %rd168, 2;
	add.s64 	%rd179, %rd3, %rd169;
	mul.wide.s32 	%rd170, %r307, 4;
	add.s64 	%rd178, %rd4, %rd170;

$L__BB0_108:
	.pragma "nounroll";
	.loc	1 169 13
	ld.local.f32 	%f288, [%rd178];
	mul.ftz.f32 	%f289, %f336, %f288;
	st.global.f32 	[%rd179], %f289;
	.loc	1 168 9
	add.s64 	%rd179, %rd179, 4;
	add.s64 	%rd178, %rd178, 4;
	add.s32 	%r308, %r308, -1;
	setp.ne.s32 	%p85, %r308, 0;
	@%p85 bra 	$L__BB0_108;

$L__BB0_109:
	.loc	1 172 1
	ret;

$L__BB0_19:
	.loc	1 75 9
	not.b32 	%r155, %r1;
	add.s32 	%r156, %r7, %r155;
	div.u32 	%r21, %r156, %r8;
	add.s32 	%r157, %r21, 1;
	and.b32  	%r274, %r157, 3;
	setp.eq.s32 	%p18, %r274, 0;
	mov.u32 	%r275, %r1;
	@%p18 bra 	$L__BB0_22;

	.loc	1 0 9
	mov.u32 	%r275, %r1;

$L__BB0_21:
	.pragma "nounroll";
	.loc	1 85 9
	shl.b32 	%r158, %r275, 2;
	mov.u32 	%r159, smem;
	add.s32 	%r160, %r159, %r158;
	mov.u32 	%r161, 0;
	st.shared.u32 	[%r160], %r161;
	.loc	1 69 42
	add.s32 	%r275, %r275, %r8;
	.loc	1 69 5
	add.s32 	%r274, %r274, -1;
	setp.ne.s32 	%p19, %r274, 0;
	@%p19 bra 	$L__BB0_21;

$L__BB0_22:
	.loc	1 75 9
	setp.lt.u32 	%p20, %r21, 3;
	@%p20 bra 	$L__BB0_35;

	.loc	1 69 5
	shl.b32 	%r162, %r275, 2;
	mov.u32 	%r163, smem;
	add.s32 	%r277, %r163, %r162;
	shl.b32 	%r29, %r8, 2;

$L__BB0_24:
	.loc	1 85 9
	mov.u32 	%r164, 0;
	st.shared.u32 	[%r277], %r164;
	add.s32 	%r165, %r277, %r29;
	st.shared.u32 	[%r165], %r164;
	.loc	1 69 42
	add.s32 	%r166, %r275, %r8;
	add.s32 	%r167, %r166, %r8;
	.loc	1 85 9
	add.s32 	%r168, %r165, %r29;
	st.shared.u32 	[%r168], %r164;
	.loc	1 69 42
	add.s32 	%r169, %r167, %r8;
	.loc	1 85 9
	add.s32 	%r170, %r168, %r29;
	add.s32 	%r277, %r170, %r29;
	st.shared.u32 	[%r170], %r164;
	.loc	1 69 42
	add.s32 	%r275, %r169, %r8;
	.loc	1 69 5
	setp.lt.s32 	%p21, %r275, %r7;
	@%p21 bra 	$L__BB0_24;
	bra.uni 	$L__BB0_35;

}
	// .globl	fused_qkv_attention_forward_f16
.visible .entry fused_qkv_attention_forward_f16(
	.param .u64 fused_qkv_attention_forward_f16_param_0,
	.param .u64 fused_qkv_attention_forward_f16_param_1,
	.param .u64 fused_qkv_attention_forward_f16_param_2,
	.param .u64 fused_qkv_attention_forward_f16_param_3,
	.param .u32 fused_qkv_attention_forward_f16_param_4,
	.param .u32 fused_qkv_attention_forward_f16_param_5,
	.param .u32 fused_qkv_attention_forward_f16_param_6,
	.param .u32 fused_qkv_attention_forward_f16_param_7,
	.param .u32 fused_qkv_attention_forward_f16_param_8
)
{
	.local .align 16 .b8 	__local_depot1[1024];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<89>;
	.reg .b16 	%rs<80>;
	.reg .f32 	%f<337>;
	.reg .b32 	%r<309>;
	.reg .b64 	%rd<180>;
	.loc	1 174 0


	mov.u64 	%SPL, __local_depot1;
	ld.param.u64 	%rd64, [fused_qkv_attention_forward_f16_param_0];
	ld.param.u64 	%rd65, [fused_qkv_attention_forward_f16_param_1];
	ld.param.u64 	%rd63, [fused_qkv_attention_forward_f16_param_2];
	ld.param.u64 	%rd66, [fused_qkv_attention_forward_f16_param_3];
	ld.param.u32 	%r125, [fused_qkv_attention_forward_f16_param_4];
	ld.param.u32 	%r121, [fused_qkv_attention_forward_f16_param_5];
	ld.param.u32 	%r122, [fused_qkv_attention_forward_f16_param_6];
	ld.param.u32 	%r123, [fused_qkv_attention_forward_f16_param_7];
	ld.param.u32 	%r124, [fused_qkv_attention_forward_f16_param_8];
	cvta.to.global.u64 	%rd1, %rd65;
	cvta.to.global.u64 	%rd2, %rd64;
	cvta.to.global.u64 	%rd3, %rd66;
	.loc	1 187 19
	add.u64 	%rd4, %SPL, 0;
	mov.u32 	%r1, %tid.x;
	.loc	1 188 24
	add.s32 	%r126, %r121, 15;
	shr.s32 	%r127, %r126, 31;
	shr.u32 	%r128, %r127, 28;
	add.s32 	%r129, %r126, %r128;
	shr.s32 	%r2, %r129, 4;
	.loc	1 189 28
	mul.lo.s32 	%r130, %r123, %r125;
	mul.lo.s32 	%r131, %r130, %r2;
	.loc	1 190 25
	mov.u32 	%r3, %ctaid.x;
	.loc	1 192 5
	setp.ge.s32 	%p3, %r3, %r131;
	@%p3 bra 	$L__BB1_109;

	.loc	1 196 22
	div.s32 	%r132, %r3, %r2;
	.loc	1 197 23
	mul.lo.s32 	%r133, %r132, %r2;
	sub.s32 	%r134, %r3, %r133;
	.loc	1 198 17
	div.s32 	%r135, %r132, %r123;
	.loc	1 199 17
	mul.lo.s32 	%r4, %r135, %r123;
	sub.s32 	%r5, %r132, %r4;
	.loc	1 201 23
	shl.b32 	%r6, %r134, 4;
	.loc	1 202 34
	mul.lo.s32 	%r136, %r122, %r121;
	.loc	1 203 28
	mul.lo.s32 	%r137, %r136, %r135;
	cvt.s64.s32 	%rd5, %r137;
	.loc	1 205 34
	mul.lo.s32 	%r138, %r124, %r122;
	.loc	1 206 33
	mul.lo.s32 	%r139, %r138, %r123;
	.loc	1 208 21
	mul.lo.s32 	%r140, %r5, %r138;
	cvt.s64.s32 	%rd6, %r140;
	.loc	1 209 21
	cvt.s64.s32 	%rd70, %r139;
	add.s64 	%rd7, %rd6, %rd70;
	.loc	1 210 21
	shl.b32 	%r141, %r139, 1;
	cvt.s64.s32 	%rd71, %r141;
	add.s64 	%rd8, %rd6, %rd71;
	.loc	1 212 21
	mul.lo.s32 	%r142, %r5, %r124;
	cvta.to.global.u64 	%rd72, %rd63;
	mul.wide.s32 	%rd73, %r142, 2;
	add.s64 	%rd9, %rd72, %rd73;
	add.s64 	%rd10, %rd63, %rd73;
	setp.eq.s64 	%p1, %rd63, 0;
	mov.u64 	%rd173, 0;
	.loc	1 213 21
	mov.u64 	%rd171, %rd173;
	mov.u64 	%rd172, %rd173;
	@%p1 bra 	$L__BB1_3;

	mul.lo.s32 	%r143, %r124, %r123;
	mul.wide.s32 	%rd74, %r143, 2;
	add.s64 	%rd171, %rd9, %rd74;
	add.s64 	%rd172, %rd10, %rd74;

$L__BB1_3:
	.loc	1 214 21
	mov.u64 	%rd174, %rd173;
	@%p1 bra 	$L__BB1_5;

	mul.lo.s32 	%r144, %r123, %r124;
	shl.b32 	%r145, %r144, 1;
	mul.wide.s32 	%rd77, %r145, 2;
	add.s64 	%rd173, %rd9, %rd77;
	add.s64 	%rd174, %rd10, %rd77;

$L__BB1_5:
	.loc	1 217 19
	shl.b32 	%r7, %r124, 4;
	.loc	1 221 5
	setp.ge.s32 	%p5, %r1, %r7;
	.loc	1 212 21
	selp.b64 	%rd19, 0, %rd9, %p1;
	.loc	1 221 5
	@%p5 bra 	$L__BB1_35;

	.loc	1 0 5
	setp.eq.s64 	%p7, %rd10, 0;
	or.pred  	%p8, %p1, %p7;
	.loc	1 221 42
	mov.u32 	%r8, %ntid.x;
	.loc	1 227 9
	@%p8 bra 	$L__BB1_18;
	bra.uni 	$L__BB1_7;

$L__BB1_18:
	.loc	1 0 9
	setp.gt.s32 	%p17, %r122, 0;
	.loc	1 227 9
	@%p17 bra 	$L__BB1_25;
	bra.uni 	$L__BB1_19;

$L__BB1_25:
	add.s32 	%r34, %r122, -1;
	and.b32  	%r35, %r122, 3;
	sub.s32 	%r36, %r122, %r35;
	mov.u32 	%r278, %r1;

$L__BB1_26:
	.loc	1 222 21
	div.s32 	%r38, %r278, %r124;
	.loc	1 224 23
	add.s32 	%r39, %r38, %r6;
	.loc	1 230 9
	setp.ge.s32 	%p22, %r39, %r121;
	mov.f32 	%f300, 0f00000000;
	@%p22 bra 	$L__BB1_34;

	.loc	1 0 9
	setp.lt.u32 	%p23, %r34, 3;
	.loc	1 231 32
	mul.lo.s32 	%r172, %r39, %r122;
	cvt.s64.s32 	%rd94, %r172;
	add.s64 	%rd24, %rd94, %rd5;
	.loc	1 223 21
	mul.lo.s32 	%r173, %r38, %r124;
	sub.s32 	%r174, %r278, %r173;
	.loc	1 232 31
	mul.lo.s32 	%r175, %r174, %r122;
	cvt.s64.s32 	%rd95, %r175;
	add.s64 	%rd25, %rd95, %rd6;
	mov.f32 	%f300, 0f00000000;
	mov.u32 	%r281, 0;
	.loc	1 233 13
	@%p23 bra 	$L__BB1_30;

	.loc	1 0 13
	mov.u32 	%r280, %r36;

$L__BB1_29:
	.loc	1 234 17
	cvt.s64.s32 	%rd96, %r281;
	add.s64 	%rd97, %rd24, %rd96;
	shl.b64 	%rd98, %rd97, 1;
	add.s64 	%rd99, %rd2, %rd98;
	ld.global.nc.u16 	%rs16, [%rd99];
	.loc	1 234 24
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f115, %rs16;}

	// end inline asm
	.loc	1 234 24
	add.s64 	%rd100, %rd25, %rd96;
	shl.b64 	%rd101, %rd100, 1;
	add.s64 	%rd102, %rd1, %rd101;
	ld.global.nc.u16 	%rs17, [%rd102];
	.loc	1 234 50
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f116, %rs17;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f123, %f115, %f116, %f300;
	.loc	1 234 17
	ld.global.nc.u16 	%rs18, [%rd99+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f117, %rs18;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs19, [%rd102+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f118, %rs19;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f124, %f117, %f118, %f123;
	.loc	1 234 17
	ld.global.nc.u16 	%rs20, [%rd99+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f119, %rs20;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs21, [%rd102+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f120, %rs21;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f125, %f119, %f120, %f124;
	.loc	1 234 17
	ld.global.nc.u16 	%rs22, [%rd99+6];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f121, %rs22;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs23, [%rd102+6];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f122, %rs23;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f300, %f121, %f122, %f125;
	.loc	1 233 45
	add.s32 	%r281, %r281, 4;
	.loc	1 233 13
	add.s32 	%r280, %r280, -4;
	setp.ne.s32 	%p24, %r280, 0;
	@%p24 bra 	$L__BB1_29;

$L__BB1_30:
	.loc	1 0 13
	setp.eq.s32 	%p25, %r35, 0;
	.loc	1 233 13
	@%p25 bra 	$L__BB1_34;

	.loc	1 0 13
	setp.eq.s32 	%p26, %r35, 1;
	.loc	1 234 17
	cvt.s64.s32 	%rd103, %r281;
	add.s64 	%rd104, %rd24, %rd103;
	shl.b64 	%rd105, %rd104, 1;
	add.s64 	%rd26, %rd2, %rd105;
	ld.global.nc.u16 	%rs24, [%rd26];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f126, %rs24;}

	// end inline asm
	.loc	1 234 24
	add.s64 	%rd106, %rd25, %rd103;
	shl.b64 	%rd107, %rd106, 1;
	add.s64 	%rd27, %rd1, %rd107;
	ld.global.nc.u16 	%rs25, [%rd27];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f127, %rs25;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f300, %f126, %f127, %f300;
	.loc	1 233 13
	@%p26 bra 	$L__BB1_34;

	.loc	1 0 13
	setp.eq.s32 	%p27, %r35, 2;
	.loc	1 234 17
	ld.global.nc.u16 	%rs26, [%rd26+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f128, %rs26;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs27, [%rd27+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f129, %rs27;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f300, %f128, %f129, %f300;
	.loc	1 233 13
	@%p27 bra 	$L__BB1_34;

	.loc	1 234 17
	ld.global.nc.u16 	%rs28, [%rd26+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f130, %rs28;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs29, [%rd27+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f131, %rs29;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f300, %f130, %f131, %f300;

$L__BB1_34:
	.loc	1 237 9
	shl.b32 	%r177, %r278, 2;
	mov.u32 	%r178, smem;
	add.s32 	%r179, %r178, %r177;
	st.shared.f32 	[%r179], %f300;
	.loc	1 221 42
	add.s32 	%r278, %r278, %r8;
	.loc	1 221 5
	setp.lt.s32 	%p28, %r278, %r7;
	@%p28 bra 	$L__BB1_26;
	bra.uni 	$L__BB1_35;

$L__BB1_7:
	.loc	1 227 9
	add.s32 	%r9, %r122, -1;
	and.b32  	%r10, %r122, 3;
	sub.s32 	%r11, %r122, %r10;
	mov.u32 	%r269, %r1;

$L__BB1_8:
	.loc	1 222 21
	div.s32 	%r146, %r269, %r124;
	.loc	1 223 21
	mul.lo.s32 	%r147, %r146, %r124;
	sub.s32 	%r13, %r269, %r147;
	.loc	1 224 23
	add.s32 	%r14, %r146, %r6;
	.loc	1 228 13
	mul.wide.s32 	%rd78, %r13, 2;
	add.s64 	%rd79, %rd19, %rd78;
	ld.global.nc.u16 	%rs1, [%rd79];
	.loc	1 228 19
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 228 19
	// begin inline asm
	{  cvt.f32.f16 %f296, %rs1;}

	// end inline asm
	.loc	1 230 9
	setp.ge.s32 	%p9, %r14, %r121;
	@%p9 bra 	$L__BB1_17;

	.loc	1 0 9
	setp.lt.s32 	%p10, %r122, 1;
	.loc	1 231 32
	mul.lo.s32 	%r148, %r14, %r122;
	cvt.s64.s32 	%rd80, %r148;
	add.s64 	%rd20, %rd80, %rd5;
	.loc	1 232 31
	mul.lo.s32 	%r149, %r13, %r122;
	cvt.s64.s32 	%rd81, %r149;
	add.s64 	%rd21, %rd81, %rd6;
	.loc	1 233 13
	@%p10 bra 	$L__BB1_17;

	.loc	1 0 13
	setp.lt.u32 	%p11, %r9, 3;
	mov.u32 	%r272, 0;
	.loc	1 233 13
	@%p11 bra 	$L__BB1_13;

	.loc	1 0 13
	mov.u32 	%r271, %r11;

$L__BB1_12:
	.loc	1 234 17
	cvt.s64.s32 	%rd82, %r272;
	add.s64 	%rd83, %rd20, %rd82;
	shl.b64 	%rd84, %rd83, 1;
	add.s64 	%rd85, %rd2, %rd84;
	ld.global.nc.u16 	%rs2, [%rd85];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f94, %rs2;}

	// end inline asm
	.loc	1 234 24
	add.s64 	%rd86, %rd21, %rd82;
	shl.b64 	%rd87, %rd86, 1;
	add.s64 	%rd88, %rd1, %rd87;
	ld.global.nc.u16 	%rs3, [%rd88];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f95, %rs3;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f102, %f94, %f95, %f296;
	.loc	1 234 17
	ld.global.nc.u16 	%rs4, [%rd85+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f96, %rs4;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs5, [%rd88+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f97, %rs5;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f103, %f96, %f97, %f102;
	.loc	1 234 17
	ld.global.nc.u16 	%rs6, [%rd85+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f98, %rs6;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs7, [%rd88+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f99, %rs7;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f104, %f98, %f99, %f103;
	.loc	1 234 17
	ld.global.nc.u16 	%rs8, [%rd85+6];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f100, %rs8;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs9, [%rd88+6];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f101, %rs9;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f296, %f100, %f101, %f104;
	.loc	1 233 45
	add.s32 	%r272, %r272, 4;
	.loc	1 233 13
	add.s32 	%r271, %r271, -4;
	setp.ne.s32 	%p12, %r271, 0;
	@%p12 bra 	$L__BB1_12;

$L__BB1_13:
	.loc	1 0 13
	setp.eq.s32 	%p13, %r10, 0;
	.loc	1 233 13
	@%p13 bra 	$L__BB1_17;

	.loc	1 0 13
	setp.eq.s32 	%p14, %r10, 1;
	.loc	1 234 17
	cvt.s64.s32 	%rd89, %r272;
	add.s64 	%rd90, %rd20, %rd89;
	shl.b64 	%rd91, %rd90, 1;
	add.s64 	%rd22, %rd2, %rd91;
	ld.global.nc.u16 	%rs10, [%rd22];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f105, %rs10;}

	// end inline asm
	.loc	1 234 24
	add.s64 	%rd92, %rd21, %rd89;
	shl.b64 	%rd93, %rd92, 1;
	add.s64 	%rd23, %rd1, %rd93;
	ld.global.nc.u16 	%rs11, [%rd23];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f106, %rs11;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f296, %f105, %f106, %f296;
	.loc	1 233 13
	@%p14 bra 	$L__BB1_17;

	.loc	1 0 13
	setp.eq.s32 	%p15, %r10, 2;
	.loc	1 234 17
	ld.global.nc.u16 	%rs12, [%rd22+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f107, %rs12;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs13, [%rd23+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f108, %rs13;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f296, %f107, %f108, %f296;
	.loc	1 233 13
	@%p15 bra 	$L__BB1_17;

	.loc	1 234 17
	ld.global.nc.u16 	%rs14, [%rd22+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 24
	// begin inline asm
	{  cvt.f32.f16 %f109, %rs14;}

	// end inline asm
	.loc	1 234 24
	ld.global.nc.u16 	%rs15, [%rd23+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 234 50
	// begin inline asm
	{  cvt.f32.f16 %f110, %rs15;}

	// end inline asm
	.loc	1 234 50
	fma.rn.ftz.f32 	%f296, %f109, %f110, %f296;

$L__BB1_17:
	.loc	1 237 9
	shl.b32 	%r152, %r269, 2;
	mov.u32 	%r153, smem;
	add.s32 	%r154, %r153, %r152;
	st.shared.f32 	[%r154], %f296;
	.loc	1 221 42
	add.s32 	%r269, %r269, %r8;
	.loc	1 221 5
	setp.lt.s32 	%p16, %r269, %r7;
	@%p16 bra 	$L__BB1_8;

$L__BB1_35:
	.loc	1 240 5
	bar.sync 	0;
	.loc	1 242 21
	add.s32 	%r46, %r6, %r1;
	.loc	1 243 23
	setp.lt.s32 	%p29, %r46, %r121;
	setp.lt.s32 	%p30, %r1, 16;
	and.pred  	%p2, %p30, %p29;
	not.pred 	%p31, %p2;
	.loc	1 247 23
	cvt.rn.f32.s32 	%f132, %r124;
	.loc	1 247 25
	rsqrt.approx.ftz.f32 	%f18, %f132;
	.loc	1 248 24
	mul.lo.s32 	%r180, %r1, %r124;
	shl.b32 	%r181, %r180, 2;
	mov.u32 	%r182, smem;
	add.s32 	%r183, %r182, %r181;
	selp.b32 	%r47, %r183, 0, %p2;
	.loc	1 251 9
	setp.lt.s32 	%p32, %r124, 1;
	.loc	1 250 5
	or.pred  	%p33, %p31, %p32;
	@%p33 bra 	$L__BB1_42;

	.loc	1 251 9
	add.s32 	%r185, %r124, -1;
	and.b32  	%r286, %r124, 3;
	setp.lt.u32 	%p34, %r185, 3;
	mov.u32 	%r284, 0;
	@%p34 bra 	$L__BB1_39;

	sub.s32 	%r283, %r124, %r286;

$L__BB1_38:
	.loc	1 252 13
	mul.wide.s32 	%rd108, %r284, 4;
	add.s64 	%rd109, %rd4, %rd108;
	mov.f32 	%f133, 0f00000000;
	st.local.v4.f32 	[%rd109], {%f133, %f133, %f133, %f133};
	.loc	1 251 39
	add.s32 	%r284, %r284, 4;
	.loc	1 251 9
	add.s32 	%r283, %r283, -4;
	setp.ne.s32 	%p35, %r283, 0;
	@%p35 bra 	$L__BB1_38;

$L__BB1_39:
	setp.eq.s32 	%p36, %r286, 0;
	@%p36 bra 	$L__BB1_42;

$L__BB1_41:
	.pragma "nounroll";
	.loc	1 252 13
	mul.wide.s32 	%rd110, %r284, 4;
	add.s64 	%rd111, %rd4, %rd110;
	mov.u32 	%r187, 0;
	st.local.u32 	[%rd111], %r187;
	.loc	1 251 39
	add.s32 	%r284, %r284, 1;
	.loc	1 251 9
	add.s32 	%r286, %r286, -1;
	setp.ne.s32 	%p37, %r286, 0;
	@%p37 bra 	$L__BB1_41;

$L__BB1_42:
	.loc	1 256 5
	setp.lt.s32 	%p38, %r121, 1;
	mov.f32 	%f334, 0f00000000;
	@%p38 bra 	$L__BB1_99;

	.loc	1 258 46
	mov.u32 	%r59, %ntid.x;
	.loc	1 258 9
	add.s32 	%r60, %r122, -1;
	not.b32 	%r61, %r121;
	add.s32 	%r62, %r124, -1;
	and.b32  	%r63, %r122, 3;
	sub.s32 	%r64, %r122, %r63;
	and.b32  	%r65, %r124, 3;
	sub.s32 	%r66, %r124, %r65;
	mul.ftz.f32 	%f19, %f18, 0f00000000;
	shl.b64 	%rd112, %rd7, 1;
	add.s64 	%rd113, %rd1, %rd112;
	add.s64 	%rd28, %rd113, 4;
	shl.b64 	%rd114, %rd5, 1;
	add.s64 	%rd115, %rd2, %rd114;
	add.s64 	%rd29, %rd115, 4;
	shl.b64 	%rd116, %rd8, 1;
	add.s64 	%rd117, %rd1, %rd116;
	add.s64 	%rd30, %rd117, 4;
	mov.f32 	%f333, 0fFF7FFFFF;
	mov.u32 	%r287, 0;
	mov.u32 	%r288, %r287;
	bra.uni 	$L__BB1_44;

$L__BB1_75:
	shl.b32 	%r256, %r287, 4;
	add.s32 	%r255, %r256, %r61;
	max.s32 	%r254, %r255, -17;
	not.b32 	%r253, %r254;
	max.s32 	%r252, %r253, 1;
	.loc	1 294 17
	and.b32  	%r88, %r252, 3;
	.loc	1 258 9
	add.s32 	%r220, %r252, -1;
	.loc	1 294 17
	setp.lt.u32 	%p62, %r220, 3;
	@%p62 bra 	$L__BB1_78;

	.loc	1 258 9
	shl.b32 	%r261, %r287, 4;
	add.s32 	%r260, %r261, %r61;
	max.s32 	%r259, %r260, -17;
	not.b32 	%r258, %r259;
	max.s32 	%r257, %r258, 1;
	.loc	1 294 17
	sub.s32 	%r297, %r257, %r88;
	mov.f32 	%f322, %f333;

$L__BB1_77:
	.loc	1 299 37
	max.ftz.f32 	%f333, %f322, %f19;
	.loc	1 300 37
	sub.ftz.f32 	%f203, %f322, %f333;
	.loc	1 300 39
	mul.ftz.f32 	%f204, %f203, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f205, %f204;
	.loc	1 301 37
	sub.ftz.f32 	%f206, %f19, %f333;
	.loc	1 301 39
	mul.ftz.f32 	%f207, %f206, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f208, %f207;
	.loc	1 303 17
	fma.rn.ftz.f32 	%f209, %f334, %f205, %f208;
	.loc	1 300 37
	sub.ftz.f32 	%f210, %f333, %f333;
	.loc	1 300 39
	mul.ftz.f32 	%f211, %f210, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f212, %f211;
	.loc	1 303 17
	fma.rn.ftz.f32 	%f213, %f209, %f212, %f208;
	fma.rn.ftz.f32 	%f214, %f213, %f212, %f208;
	fma.rn.ftz.f32 	%f334, %f214, %f212, %f208;
	.loc	1 289 13
	add.s32 	%r297, %r297, -4;
	setp.ne.s32 	%p63, %r297, 0;
	mov.f32 	%f322, %f333;
	@%p63 bra 	$L__BB1_77;

$L__BB1_78:
	.loc	1 294 17
	setp.eq.s32 	%p64, %r88, 0;
	@%p64 bra 	$L__BB1_98;

	.loc	1 299 37
	max.ftz.f32 	%f67, %f333, %f19;
	.loc	1 300 37
	sub.ftz.f32 	%f215, %f333, %f67;
	.loc	1 300 39
	mul.ftz.f32 	%f216, %f215, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f217, %f216;
	.loc	1 301 37
	sub.ftz.f32 	%f218, %f19, %f67;
	.loc	1 301 39
	mul.ftz.f32 	%f219, %f218, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f68, %f219;
	.loc	1 303 17
	fma.rn.ftz.f32 	%f334, %f334, %f217, %f68;
	.loc	1 289 13
	setp.eq.s32 	%p65, %r88, 1;
	mov.f32 	%f333, %f67;
	@%p65 bra 	$L__BB1_98;

	.loc	1 300 37
	sub.ftz.f32 	%f220, %f67, %f67;
	.loc	1 300 39
	mul.ftz.f32 	%f221, %f220, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f70, %f221;
	.loc	1 303 17
	fma.rn.ftz.f32 	%f334, %f334, %f70, %f68;
	.loc	1 289 13
	setp.eq.s32 	%p66, %r88, 2;
	mov.f32 	%f333, %f67;
	@%p66 bra 	$L__BB1_98;

	.loc	1 303 17
	fma.rn.ftz.f32 	%f334, %f334, %f70, %f68;
	mov.f32 	%f333, %f67;
	bra.uni 	$L__BB1_98;

$L__BB1_44:
	.loc	1 258 9
	@%p5 bra 	$L__BB1_72;

	.loc	1 0 9
	setp.eq.s64 	%p40, %rd172, 0;
	.loc	1 265 13
	@%p40 bra 	$L__BB1_59;

	.loc	1 0 13
	mov.u32 	%r289, %r1;

$L__BB1_47:
	.loc	1 259 25
	div.s32 	%r194, %r289, %r124;
	.loc	1 260 25
	mul.lo.s32 	%r195, %r194, %r124;
	sub.s32 	%r196, %r289, %r195;
	.loc	1 261 27
	add.s32 	%r71, %r194, %r288;
	.loc	1 266 17
	cvt.s64.s32 	%rd31, %r196;
	mul.wide.s32 	%rd118, %r196, 2;
	add.s64 	%rd119, %rd171, %rd118;
	ld.global.nc.u16 	%rs30, [%rd119];
	.loc	1 266 25
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 266 25
	// begin inline asm
	{  cvt.f32.f16 %f310, %rs30;}

	// end inline asm
	setp.eq.s64 	%p41, %rd174, 0;
	mov.f32 	%f311, 0f00000000;
	.loc	1 268 13
	@%p41 bra 	$L__BB1_49;

	.loc	1 269 17
	shl.b64 	%rd120, %rd31, 1;
	add.s64 	%rd121, %rd173, %rd120;
	ld.global.nc.u16 	%rs31, [%rd121];
	.loc	1 269 25
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 269 25
	// begin inline asm
	{  cvt.f32.f16 %f311, %rs31;}

	// end inline asm

$L__BB1_49:
	.loc	1 271 13
	setp.ge.s32 	%p42, %r71, %r121;
	@%p42 bra 	$L__BB1_58;

	.loc	1 0 13
	cvt.u32.u64 	%r197, %rd31;
	.loc	1 272 36
	mul.lo.s32 	%r198, %r71, %r122;
	cvt.s64.s32 	%rd32, %r198;
	.loc	1 273 36
	mul.lo.s32 	%r199, %r197, %r122;
	cvt.s64.s32 	%rd33, %r199;
	setp.lt.s32 	%p43, %r122, 1;
	.loc	1 275 17
	@%p43 bra 	$L__BB1_58;

	.loc	1 0 17
	setp.lt.u32 	%p44, %r60, 3;
	mov.u32 	%r292, 0;
	.loc	1 275 17
	@%p44 bra 	$L__BB1_54;

	shl.b64 	%rd122, %rd33, 1;
	add.s64 	%rd177, %rd28, %rd122;
	shl.b64 	%rd123, %rd32, 1;
	add.s64 	%rd176, %rd29, %rd123;
	add.s64 	%rd175, %rd30, %rd122;
	mov.u32 	%r291, %r64;

$L__BB1_53:
	.loc	1 276 40
	ld.global.nc.u16 	%rs32, [%rd176+-4];
	.loc	1 276 42
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f141, %rs32;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs33, [%rd177+-4];
	.loc	1 277 39
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f142, %rs33;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f153, %f141, %f142, %f310;
	.loc	1 278 21
	ld.global.nc.u16 	%rs34, [%rd175+-4];
	.loc	1 278 39
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f143, %rs34;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f154, %f141, %f143, %f311;
	.loc	1 276 40
	ld.global.nc.u16 	%rs35, [%rd176+-2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f144, %rs35;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs36, [%rd177+-2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f145, %rs36;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f155, %f144, %f145, %f153;
	.loc	1 278 21
	ld.global.nc.u16 	%rs37, [%rd175+-2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f146, %rs37;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f156, %f144, %f146, %f154;
	.loc	1 276 40
	ld.global.nc.u16 	%rs38, [%rd176];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f147, %rs38;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs39, [%rd177];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f148, %rs39;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f157, %f147, %f148, %f155;
	.loc	1 278 21
	ld.global.nc.u16 	%rs40, [%rd175];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f149, %rs40;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f158, %f147, %f149, %f156;
	.loc	1 276 40
	ld.global.nc.u16 	%rs41, [%rd176+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f150, %rs41;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs42, [%rd177+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f151, %rs42;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f310, %f150, %f151, %f157;
	.loc	1 278 21
	ld.global.nc.u16 	%rs43, [%rd175+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f152, %rs43;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f311, %f150, %f152, %f158;
	.loc	1 275 49
	add.s32 	%r292, %r292, 4;
	.loc	1 275 17
	add.s64 	%rd177, %rd177, 8;
	add.s64 	%rd176, %rd176, 8;
	add.s64 	%rd175, %rd175, 8;
	add.s32 	%r291, %r291, -4;
	setp.ne.s32 	%p45, %r291, 0;
	@%p45 bra 	$L__BB1_53;

$L__BB1_54:
	.loc	1 0 17
	setp.eq.s32 	%p46, %r63, 0;
	.loc	1 275 17
	@%p46 bra 	$L__BB1_58;

	.loc	1 0 17
	setp.eq.s32 	%p47, %r63, 1;
	.loc	1 276 40
	cvt.s64.s32 	%rd124, %r292;
	.loc	1 272 36
	add.s64 	%rd125, %rd32, %rd5;
	.loc	1 276 40
	add.s64 	%rd126, %rd125, %rd124;
	shl.b64 	%rd127, %rd126, 1;
	add.s64 	%rd43, %rd2, %rd127;
	ld.global.nc.u16 	%rs44, [%rd43];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f159, %rs44;}

	// end inline asm
	.loc	1 273 36
	add.s64 	%rd128, %rd7, %rd33;
	.loc	1 277 21
	add.s64 	%rd129, %rd128, %rd124;
	shl.b64 	%rd130, %rd129, 1;
	add.s64 	%rd44, %rd1, %rd130;
	ld.global.nc.u16 	%rs45, [%rd44];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f160, %rs45;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f310, %f159, %f160, %f310;
	.loc	1 274 36
	add.s64 	%rd131, %rd8, %rd33;
	.loc	1 278 21
	add.s64 	%rd132, %rd131, %rd124;
	shl.b64 	%rd133, %rd132, 1;
	add.s64 	%rd45, %rd1, %rd133;
	ld.global.nc.u16 	%rs46, [%rd45];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f161, %rs46;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f311, %f159, %f161, %f311;
	.loc	1 275 17
	@%p47 bra 	$L__BB1_58;

	.loc	1 0 17
	setp.eq.s32 	%p48, %r63, 2;
	.loc	1 276 40
	ld.global.nc.u16 	%rs47, [%rd43+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f162, %rs47;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs48, [%rd44+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f163, %rs48;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f310, %f162, %f163, %f310;
	.loc	1 278 21
	ld.global.nc.u16 	%rs49, [%rd45+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f164, %rs49;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f311, %f162, %f164, %f311;
	.loc	1 275 17
	@%p48 bra 	$L__BB1_58;

	.loc	1 276 40
	ld.global.nc.u16 	%rs50, [%rd43+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f165, %rs50;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs51, [%rd44+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f166, %rs51;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f310, %f165, %f166, %f310;
	.loc	1 278 21
	ld.global.nc.u16 	%rs52, [%rd45+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f167, %rs52;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f311, %f165, %f167, %f311;

$L__BB1_58:
	.loc	1 281 13
	add.s32 	%r202, %r289, %r7;
	shl.b32 	%r203, %r202, 2;
	add.s32 	%r205, %r182, %r203;
	st.shared.f32 	[%r205], %f310;
	.loc	1 282 13
	shl.b32 	%r206, %r7, 2;
	add.s32 	%r207, %r205, %r206;
	st.shared.f32 	[%r207], %f311;
	.loc	1 258 46
	add.s32 	%r289, %r289, %r59;
	.loc	1 258 9
	setp.lt.s32 	%p49, %r289, %r7;
	@%p49 bra 	$L__BB1_47;
	bra.uni 	$L__BB1_72;

$L__BB1_59:
	.loc	1 0 9
	mov.u32 	%r293, %r1;

$L__BB1_60:
	.loc	1 259 25
	div.s32 	%r208, %r293, %r124;
	.loc	1 260 25
	mul.lo.s32 	%r209, %r208, %r124;
	sub.s32 	%r79, %r293, %r209;
	.loc	1 261 27
	add.s32 	%r80, %r208, %r288;
	setp.eq.s64 	%p50, %rd174, 0;
	mov.f32 	%f320, 0f00000000;
	.loc	1 268 13
	@%p50 bra 	$L__BB1_62;

	.loc	1 269 17
	mul.wide.s32 	%rd134, %r79, 2;
	add.s64 	%rd135, %rd173, %rd134;
	ld.global.nc.u16 	%rs53, [%rd135];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 269 25
	// begin inline asm
	{  cvt.f32.f16 %f320, %rs53;}

	// end inline asm

$L__BB1_62:
	.loc	2 0 3
	mov.f32 	%f319, 0f00000000;
	.loc	1 271 13
	setp.ge.s32 	%p51, %r80, %r121;
	@%p51 bra 	$L__BB1_71;

	.loc	1 0 13
	mov.f32 	%f319, 0f00000000;
	setp.lt.s32 	%p52, %r122, 1;
	.loc	1 272 36
	mul.lo.s32 	%r210, %r80, %r122;
	cvt.s64.s32 	%rd136, %r210;
	add.s64 	%rd46, %rd136, %rd5;
	.loc	1 273 36
	mul.lo.s32 	%r211, %r79, %r122;
	cvt.s64.s32 	%rd137, %r211;
	add.s64 	%rd47, %rd7, %rd137;
	.loc	1 274 36
	add.s64 	%rd48, %rd8, %rd137;
	.loc	1 275 17
	@%p52 bra 	$L__BB1_71;

	.loc	1 0 17
	setp.lt.u32 	%p53, %r60, 3;
	mov.f32 	%f319, 0f00000000;
	mov.u32 	%r296, 0;
	.loc	1 275 17
	@%p53 bra 	$L__BB1_67;

	.loc	1 0 17
	mov.u32 	%r295, %r64;

$L__BB1_66:
	.loc	1 276 40
	cvt.s64.s32 	%rd138, %r296;
	add.s64 	%rd139, %rd46, %rd138;
	shl.b64 	%rd140, %rd139, 1;
	add.s64 	%rd141, %rd2, %rd140;
	ld.global.nc.u16 	%rs54, [%rd141];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f175, %rs54;}

	// end inline asm
	.loc	1 277 21
	add.s64 	%rd142, %rd47, %rd138;
	shl.b64 	%rd143, %rd142, 1;
	add.s64 	%rd144, %rd1, %rd143;
	ld.global.nc.u16 	%rs55, [%rd144];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f176, %rs55;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f187, %f175, %f176, %f319;
	.loc	1 278 21
	add.s64 	%rd145, %rd48, %rd138;
	shl.b64 	%rd146, %rd145, 1;
	add.s64 	%rd147, %rd1, %rd146;
	ld.global.nc.u16 	%rs56, [%rd147];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f177, %rs56;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f188, %f175, %f177, %f320;
	.loc	1 276 40
	ld.global.nc.u16 	%rs57, [%rd141+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f178, %rs57;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs58, [%rd144+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f179, %rs58;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f189, %f178, %f179, %f187;
	.loc	1 278 21
	ld.global.nc.u16 	%rs59, [%rd147+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f180, %rs59;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f190, %f178, %f180, %f188;
	.loc	1 276 40
	ld.global.nc.u16 	%rs60, [%rd141+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f181, %rs60;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs61, [%rd144+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f182, %rs61;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f191, %f181, %f182, %f189;
	.loc	1 278 21
	ld.global.nc.u16 	%rs62, [%rd147+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f183, %rs62;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f192, %f181, %f183, %f190;
	.loc	1 276 40
	ld.global.nc.u16 	%rs63, [%rd141+6];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f184, %rs63;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs64, [%rd144+6];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f185, %rs64;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f319, %f184, %f185, %f191;
	.loc	1 278 21
	ld.global.nc.u16 	%rs65, [%rd147+6];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f186, %rs65;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f320, %f184, %f186, %f192;
	.loc	1 275 49
	add.s32 	%r296, %r296, 4;
	.loc	1 275 17
	add.s32 	%r295, %r295, -4;
	setp.ne.s32 	%p54, %r295, 0;
	@%p54 bra 	$L__BB1_66;

$L__BB1_67:
	.loc	1 0 17
	setp.eq.s32 	%p55, %r63, 0;
	.loc	1 275 17
	@%p55 bra 	$L__BB1_71;

	.loc	1 0 17
	setp.eq.s32 	%p56, %r63, 1;
	.loc	1 276 40
	cvt.s64.s32 	%rd148, %r296;
	add.s64 	%rd149, %rd46, %rd148;
	shl.b64 	%rd150, %rd149, 1;
	add.s64 	%rd49, %rd2, %rd150;
	ld.global.nc.u16 	%rs66, [%rd49];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f193, %rs66;}

	// end inline asm
	.loc	1 277 21
	add.s64 	%rd151, %rd47, %rd148;
	shl.b64 	%rd152, %rd151, 1;
	add.s64 	%rd50, %rd1, %rd152;
	ld.global.nc.u16 	%rs67, [%rd50];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f194, %rs67;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f319, %f193, %f194, %f319;
	.loc	1 278 21
	add.s64 	%rd153, %rd48, %rd148;
	shl.b64 	%rd154, %rd153, 1;
	add.s64 	%rd51, %rd1, %rd154;
	ld.global.nc.u16 	%rs68, [%rd51];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f195, %rs68;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f320, %f193, %f195, %f320;
	.loc	1 275 17
	@%p56 bra 	$L__BB1_71;

	.loc	1 0 17
	setp.eq.s32 	%p57, %r63, 2;
	.loc	1 276 40
	ld.global.nc.u16 	%rs69, [%rd49+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f196, %rs69;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs70, [%rd50+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f197, %rs70;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f319, %f196, %f197, %f319;
	.loc	1 278 21
	ld.global.nc.u16 	%rs71, [%rd51+2];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f198, %rs71;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f320, %f196, %f198, %f320;
	.loc	1 275 17
	@%p57 bra 	$L__BB1_71;

	.loc	1 276 40
	ld.global.nc.u16 	%rs72, [%rd49+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 276 42
	// begin inline asm
	{  cvt.f32.f16 %f199, %rs72;}

	// end inline asm
	.loc	1 277 21
	ld.global.nc.u16 	%rs73, [%rd50+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 277 39
	// begin inline asm
	{  cvt.f32.f16 %f200, %rs73;}

	// end inline asm
	.loc	1 277 39
	fma.rn.ftz.f32 	%f319, %f199, %f200, %f319;
	.loc	1 278 21
	ld.global.nc.u16 	%rs74, [%rd51+4];
	.loc	2 756 3, function_name $L__info_string0, inlined_at 1 278 39
	// begin inline asm
	{  cvt.f32.f16 %f201, %rs74;}

	// end inline asm
	.loc	1 278 39
	fma.rn.ftz.f32 	%f320, %f199, %f201, %f320;

$L__BB1_71:
	.loc	1 281 13
	add.s32 	%r214, %r293, %r7;
	shl.b32 	%r215, %r214, 2;
	add.s32 	%r217, %r182, %r215;
	st.shared.f32 	[%r217], %f319;
	.loc	1 282 13
	shl.b32 	%r218, %r7, 2;
	add.s32 	%r219, %r217, %r218;
	st.shared.f32 	[%r219], %f320;
	.loc	1 258 46
	add.s32 	%r293, %r293, %r59;
	.loc	1 258 9
	setp.lt.s32 	%p58, %r293, %r7;
	@%p58 bra 	$L__BB1_60;

$L__BB1_72:
	.loc	1 285 9
	bar.sync 	0;
	.loc	1 287 9
	@%p31 bra 	$L__BB1_98;

	.loc	1 288 32
	sub.s32 	%r87, %r121, %r288;
	.loc	1 289 13
	setp.lt.s32 	%p60, %r87, 1;
	@%p60 bra 	$L__BB1_98;

	.loc	1 251 9
	setp.gt.s32 	%p61, %r124, 0;
	.loc	1 294 17
	@%p61 bra 	$L__BB1_82;
	bra.uni 	$L__BB1_75;

$L__BB1_82:
	.loc	1 0 17
	mov.u32 	%r298, 0;

$L__BB1_83:
	mov.f32 	%f74, %f333;
	mov.u32 	%r301, 0;
	.loc	1 290 36
	mad.lo.s32 	%r94, %r298, %r124, %r7;
	setp.lt.u32 	%p67, %r62, 3;
	mov.f32 	%f332, 0f00000000;
	.loc	1 294 17
	@%p67 bra 	$L__BB1_86;

	.loc	1 0 17
	mov.u32 	%r301, 0;
	mov.u32 	%r300, %r66;

$L__BB1_85:
	.loc	1 295 21
	add.s32 	%r224, %r94, %r301;
	shl.b32 	%r225, %r224, 2;
	add.s32 	%r227, %r182, %r225;
	ld.shared.f32 	%f225, [%r227];
	shl.b32 	%r228, %r301, 2;
	add.s32 	%r229, %r47, %r228;
	ld.shared.f32 	%f226, [%r229];
	fma.rn.ftz.f32 	%f227, %f226, %f225, %f332;
	ld.shared.f32 	%f228, [%r227+4];
	ld.shared.f32 	%f229, [%r229+4];
	fma.rn.ftz.f32 	%f230, %f229, %f228, %f227;
	ld.shared.f32 	%f231, [%r227+8];
	ld.shared.f32 	%f232, [%r229+8];
	fma.rn.ftz.f32 	%f233, %f232, %f231, %f230;
	ld.shared.f32 	%f234, [%r227+12];
	ld.shared.f32 	%f235, [%r229+12];
	fma.rn.ftz.f32 	%f332, %f235, %f234, %f233;
	.loc	1 294 47
	add.s32 	%r301, %r301, 4;
	.loc	1 294 17
	add.s32 	%r300, %r300, -4;
	setp.ne.s32 	%p68, %r300, 0;
	@%p68 bra 	$L__BB1_85;

$L__BB1_86:
	.loc	1 0 17
	setp.eq.s32 	%p69, %r65, 0;
	.loc	1 294 17
	@%p69 bra 	$L__BB1_90;

	.loc	1 0 17
	setp.eq.s32 	%p70, %r65, 1;
	.loc	1 295 21
	add.s32 	%r230, %r94, %r301;
	shl.b32 	%r231, %r230, 2;
	add.s32 	%r100, %r182, %r231;
	ld.shared.f32 	%f236, [%r100];
	shl.b32 	%r233, %r301, 2;
	add.s32 	%r101, %r47, %r233;
	ld.shared.f32 	%f237, [%r101];
	fma.rn.ftz.f32 	%f332, %f237, %f236, %f332;
	.loc	1 294 17
	@%p70 bra 	$L__BB1_90;

	.loc	1 0 17
	setp.eq.s32 	%p71, %r65, 2;
	.loc	1 295 21
	ld.shared.f32 	%f238, [%r100+4];
	ld.shared.f32 	%f239, [%r101+4];
	fma.rn.ftz.f32 	%f332, %f239, %f238, %f332;
	.loc	1 294 17
	@%p71 bra 	$L__BB1_90;

	.loc	1 295 21
	ld.shared.f32 	%f240, [%r100+8];
	ld.shared.f32 	%f241, [%r101+8];
	fma.rn.ftz.f32 	%f332, %f241, %f240, %f332;

$L__BB1_90:
	.loc	1 0 21
	setp.lt.u32 	%p87, %r62, 3;
	.loc	1 298 35
	mul.ftz.f32 	%f242, %f18, %f332;
	.loc	1 299 37
	max.ftz.f32 	%f333, %f74, %f242;
	.loc	1 300 37
	sub.ftz.f32 	%f243, %f74, %f333;
	.loc	1 300 39
	mul.ftz.f32 	%f244, %f243, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f84, %f244;
	.loc	1 301 37
	sub.ftz.f32 	%f245, %f242, %f333;
	.loc	1 301 39
	mul.ftz.f32 	%f246, %f245, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f85, %f246;
	.loc	1 303 17
	fma.rn.ftz.f32 	%f334, %f334, %f84, %f85;
	mov.u32 	%r304, 0;
	.loc	1 304 17
	@%p87 bra 	$L__BB1_93;

	.loc	1 0 17
	mov.u32 	%r303, %r66;

$L__BB1_92:
	.loc	1 290 36
	mad.lo.s32 	%r266, %r298, %r124, %r7;
	add.s32 	%r265, %r266, %r7;
	.loc	1 305 21
	mul.wide.s32 	%rd155, %r304, 4;
	add.s64 	%rd156, %rd4, %rd155;
	ld.local.v4.f32 	{%f247, %f248, %f249, %f250}, [%rd156];
	add.s32 	%r236, %r265, %r304;
	shl.b32 	%r237, %r236, 2;
	add.s32 	%r239, %r182, %r237;
	ld.shared.f32 	%f255, [%r239];
	mul.ftz.f32 	%f256, %f85, %f255;
	ld.shared.f32 	%f257, [%r239+4];
	mul.ftz.f32 	%f258, %f85, %f257;
	ld.shared.f32 	%f259, [%r239+8];
	mul.ftz.f32 	%f260, %f85, %f259;
	ld.shared.f32 	%f261, [%r239+12];
	mul.ftz.f32 	%f262, %f85, %f261;
	fma.rn.ftz.f32 	%f263, %f84, %f250, %f262;
	fma.rn.ftz.f32 	%f264, %f84, %f249, %f260;
	fma.rn.ftz.f32 	%f265, %f84, %f248, %f258;
	fma.rn.ftz.f32 	%f266, %f84, %f247, %f256;
	st.local.v4.f32 	[%rd156], {%f266, %f265, %f264, %f263};
	.loc	1 304 47
	add.s32 	%r304, %r304, 4;
	.loc	1 304 17
	add.s32 	%r303, %r303, -4;
	setp.ne.s32 	%p73, %r303, 0;
	@%p73 bra 	$L__BB1_92;

$L__BB1_93:
	.loc	1 0 17
	setp.eq.s32 	%p88, %r65, 0;
	.loc	1 304 17
	@%p88 bra 	$L__BB1_97;

	.loc	1 290 36
	mad.lo.s32 	%r268, %r298, %r124, %r7;
	add.s32 	%r267, %r268, %r7;
	setp.eq.s32 	%p75, %r65, 1;
	.loc	1 305 21
	mul.wide.s32 	%rd157, %r304, 4;
	add.s64 	%rd52, %rd4, %rd157;
	ld.local.f32 	%f267, [%rd52];
	add.s32 	%r240, %r267, %r304;
	shl.b32 	%r241, %r240, 2;
	add.s32 	%r108, %r182, %r241;
	ld.shared.f32 	%f268, [%r108];
	mul.ftz.f32 	%f269, %f85, %f268;
	fma.rn.ftz.f32 	%f270, %f84, %f267, %f269;
	st.local.f32 	[%rd52], %f270;
	.loc	1 304 17
	@%p75 bra 	$L__BB1_97;

	.loc	1 0 17
	setp.eq.s32 	%p76, %r65, 2;
	.loc	1 305 21
	ld.local.f32 	%f271, [%rd52+4];
	ld.shared.f32 	%f272, [%r108+4];
	mul.ftz.f32 	%f273, %f85, %f272;
	fma.rn.ftz.f32 	%f274, %f84, %f271, %f273;
	st.local.f32 	[%rd52+4], %f274;
	.loc	1 304 17
	@%p76 bra 	$L__BB1_97;

	.loc	1 305 21
	ld.local.f32 	%f275, [%rd52+8];
	ld.shared.f32 	%f276, [%r108+8];
	mul.ftz.f32 	%f277, %f85, %f276;
	fma.rn.ftz.f32 	%f278, %f84, %f275, %f277;
	st.local.f32 	[%rd52+8], %f278;

$L__BB1_97:
	.loc	1 288 32
	sub.s32 	%r263, %r121, %r288;
	.loc	1 288 34
	min.s32 	%r262, %r263, 16;
	.loc	1 289 43
	add.s32 	%r298, %r298, 1;
	.loc	1 289 13
	setp.lt.s32 	%p77, %r298, %r262;
	@%p77 bra 	$L__BB1_83;

$L__BB1_98:
	.loc	1 311 9
	bar.sync 	0;
	.loc	1 256 48
	add.s32 	%r288, %r288, 16;
	.loc	1 256 5
	setp.lt.s32 	%p78, %r288, %r121;
	add.s32 	%r287, %r287, 1;
	@%p78 bra 	$L__BB1_44;

$L__BB1_99:
	.loc	1 314 5
	@%p31 bra 	$L__BB1_109;

	.loc	1 315 27
	setp.leu.ftz.f32 	%p80, %f334, 0f00000000;
	mov.f32 	%f336, 0f00000000;
	@%p80 bra 	$L__BB1_102;

	rcp.approx.ftz.f32 	%f336, %f334;

$L__BB1_102:
	.loc	1 0 27
	ld.param.u32 	%r251, [fused_qkv_attention_forward_f16_param_7];
	.loc	1 199 17
	mul.lo.s32 	%r250, %r135, %r251;
	.loc	1 251 9
	setp.lt.s32 	%p86, %r124, 1;
	.loc	1 316 31
	mul.lo.s32 	%r243, %r124, %r121;
	mul.lo.s32 	%r244, %r250, %r243;
	.loc	1 318 23
	cvt.s64.s32 	%rd53, %r244;
	mul.lo.s32 	%r245, %r5, %r243;
	cvt.s64.s32 	%rd54, %r245;
	mul.lo.s32 	%r246, %r46, %r124;
	cvt.s64.s32 	%rd55, %r246;
	.loc	1 320 9
	@%p86 bra 	$L__BB1_109;

	add.s32 	%r248, %r124, -1;
	and.b32  	%r308, %r124, 3;
	setp.lt.u32 	%p82, %r248, 3;
	mov.u32 	%r307, 0;
	@%p82 bra 	$L__BB1_106;

	sub.s32 	%r306, %r124, %r308;
	.loc	1 318 23
	add.s64 	%rd158, %rd54, %rd53;
	add.s64 	%rd56, %rd158, %rd55;

$L__BB1_105:
	.loc	1 321 13
	cvt.s64.s32 	%rd159, %r307;
	mul.wide.s32 	%rd160, %r307, 4;
	add.s64 	%rd161, %rd4, %rd160;
	ld.local.f32 	%f284, [%rd161];
	mul.ftz.f32 	%f280, %f336, %f284;
	.loc	1 321 26
	.loc	2 613 3, function_name $L__info_string1, inlined_at 1 321 26
	// begin inline asm
	{  cvt.rn.f16.f32 %rs75, %f280;}

	// end inline asm
	.loc	1 321 26
	add.s64 	%rd162, %rd56, %rd159;
	shl.b64 	%rd163, %rd162, 1;
	add.s64 	%rd164, %rd3, %rd163;
	st.global.u16 	[%rd164], %rs75;
	.loc	1 321 13
	ld.local.f32 	%f285, [%rd161+4];
	mul.ftz.f32 	%f281, %f336, %f285;
	.loc	2 613 3, function_name $L__info_string1, inlined_at 1 321 26
	// begin inline asm
	{  cvt.rn.f16.f32 %rs76, %f281;}

	// end inline asm
	.loc	1 321 26
	st.global.u16 	[%rd164+2], %rs76;
	.loc	1 321 13
	ld.local.f32 	%f286, [%rd161+8];
	mul.ftz.f32 	%f282, %f336, %f286;
	.loc	2 613 3, function_name $L__info_string1, inlined_at 1 321 26
	// begin inline asm
	{  cvt.rn.f16.f32 %rs77, %f282;}

	// end inline asm
	.loc	1 321 26
	st.global.u16 	[%rd164+4], %rs77;
	.loc	1 321 13
	ld.local.f32 	%f287, [%rd161+12];
	mul.ftz.f32 	%f283, %f336, %f287;
	.loc	2 613 3, function_name $L__info_string1, inlined_at 1 321 26
	// begin inline asm
	{  cvt.rn.f16.f32 %rs78, %f283;}

	// end inline asm
	.loc	1 321 26
	st.global.u16 	[%rd164+6], %rs78;
	.loc	1 320 39
	add.s32 	%r307, %r307, 4;
	.loc	1 320 9
	add.s32 	%r306, %r306, -4;
	setp.ne.s32 	%p83, %r306, 0;
	@%p83 bra 	$L__BB1_105;

$L__BB1_106:
	setp.eq.s32 	%p84, %r308, 0;
	@%p84 bra 	$L__BB1_109;

	cvt.s64.s32 	%rd165, %r307;
	add.s64 	%rd166, %rd165, %rd53;
	add.s64 	%rd167, %rd166, %rd54;
	add.s64 	%rd168, %rd167, %rd55;
	shl.b64 	%rd169, %rd168, 1;
	add.s64 	%rd179, %rd3, %rd169;
	mul.wide.s32 	%rd170, %r307, 4;
	add.s64 	%rd178, %rd4, %rd170;

$L__BB1_108:
	.pragma "nounroll";
	.loc	1 321 13
	ld.local.f32 	%f289, [%rd178];
	mul.ftz.f32 	%f288, %f336, %f289;
	.loc	2 613 3, function_name $L__info_string1, inlined_at 1 321 26
	// begin inline asm
	{  cvt.rn.f16.f32 %rs79, %f288;}

	// end inline asm
	.loc	1 321 26
	st.global.u16 	[%rd179], %rs79;
	.loc	1 320 9
	add.s64 	%rd179, %rd179, 2;
	add.s64 	%rd178, %rd178, 4;
	add.s32 	%r308, %r308, -1;
	setp.ne.s32 	%p85, %r308, 0;
	@%p85 bra 	$L__BB1_108;

$L__BB1_109:
	.loc	1 324 1
	ret;

$L__BB1_19:
	.loc	1 227 9
	not.b32 	%r155, %r1;
	add.s32 	%r156, %r7, %r155;
	div.u32 	%r21, %r156, %r8;
	add.s32 	%r157, %r21, 1;
	and.b32  	%r274, %r157, 3;
	setp.eq.s32 	%p18, %r274, 0;
	mov.u32 	%r275, %r1;
	@%p18 bra 	$L__BB1_22;

	.loc	1 0 9
	mov.u32 	%r275, %r1;

$L__BB1_21:
	.pragma "nounroll";
	.loc	1 237 9
	shl.b32 	%r158, %r275, 2;
	mov.u32 	%r159, smem;
	add.s32 	%r160, %r159, %r158;
	mov.u32 	%r161, 0;
	st.shared.u32 	[%r160], %r161;
	.loc	1 221 42
	add.s32 	%r275, %r275, %r8;
	.loc	1 221 5
	add.s32 	%r274, %r274, -1;
	setp.ne.s32 	%p19, %r274, 0;
	@%p19 bra 	$L__BB1_21;

$L__BB1_22:
	.loc	1 227 9
	setp.lt.u32 	%p20, %r21, 3;
	@%p20 bra 	$L__BB1_35;

	.loc	1 221 5
	shl.b32 	%r162, %r275, 2;
	mov.u32 	%r163, smem;
	add.s32 	%r277, %r163, %r162;
	shl.b32 	%r29, %r8, 2;

$L__BB1_24:
	.loc	1 237 9
	mov.u32 	%r164, 0;
	st.shared.u32 	[%r277], %r164;
	add.s32 	%r165, %r277, %r29;
	st.shared.u32 	[%r165], %r164;
	.loc	1 221 42
	add.s32 	%r166, %r275, %r8;
	add.s32 	%r167, %r166, %r8;
	.loc	1 237 9
	add.s32 	%r168, %r165, %r29;
	st.shared.u32 	[%r168], %r164;
	.loc	1 221 42
	add.s32 	%r169, %r167, %r8;
	.loc	1 237 9
	add.s32 	%r170, %r168, %r29;
	add.s32 	%r277, %r170, %r29;
	st.shared.u32 	[%r170], %r164;
	.loc	1 221 42
	add.s32 	%r275, %r169, %r8;
	.loc	1 221 5
	setp.lt.s32 	%p21, %r275, %r7;
	@%p21 bra 	$L__BB1_24;
	bra.uni 	$L__BB1_35;

}
	.file	1 "/home/putao/code/rust/gllm-kernels/src/cuda_kernels/kernels/fused_qkv_attention.cu"
	.file	2 "/usr/include/cuda_fp16.hpp"
	.section	.debug_str
	{
$L__info_string0:
.b8 95,90,78,53,51,95,73,78,84,69,82,78,65,76,95,102,52,50,48,52,100,48,54,95,50,50,95,102,117,115,101,100,95,113,107,118,95,97,116,116
.b8 101,110,116,105,111,110,95,99,117,95,57,54,50,51,54,100,101,56,49,50,95,95,104,97,108,102,50,102,108,111,97,116,69,54,95,95,104,97,108,102
.b8 0
$L__info_string1:
.b8 95,90,78,53,51,95,73,78,84,69,82,78,65,76,95,102,52,50,48,52,100,48,54,95,50,50,95,102,117,115,101,100,95,113,107,118,95,97,116,116
.b8 101,110,116,105,111,110,95,99,117,95,57,54,50,51,54,100,101,56,49,53,95,95,102,108,111,97,116,50,104,97,108,102,95,114,110,69,102,0

	}
