//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_75
.address_size 64

	// .globl	embedding_gather_f32

.visible .entry embedding_gather_f32(
	.param .u64 embedding_gather_f32_param_0,
	.param .u64 embedding_gather_f32_param_1,
	.param .u64 embedding_gather_f32_param_2,
	.param .u32 embedding_gather_f32_param_3,
	.param .u32 embedding_gather_f32_param_4
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<13>;
	.loc	1 4 0


	ld.param.u64 	%rd1, [embedding_gather_f32_param_0];
	ld.param.u64 	%rd2, [embedding_gather_f32_param_1];
	ld.param.u64 	%rd3, [embedding_gather_f32_param_2];
	ld.param.u32 	%r3, [embedding_gather_f32_param_3];
	ld.param.u32 	%r2, [embedding_gather_f32_param_4];
	.loc	1 11 13
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r4, %r5, %r6;
	.loc	1 12 15
	mul.lo.s32 	%r7, %r2, %r3;
	.loc	1 13 5
	setp.ge.s32 	%p1, %r1, %r7;
	@%p1 bra 	$L__BB0_2;

	.loc	1 11 13
	cvta.to.global.u64 	%rd4, %rd1;
	.loc	1 17 19
	div.s32 	%r8, %r1, %r2;
	.loc	1 19 20
	mul.wide.s32 	%rd5, %r8, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.nc.u32 	%r9, [%rd6];
	sub.s32 	%r10, %r9, %r8;
	.loc	1 20 5
	mad.lo.s32 	%r11, %r10, %r2, %r1;
	.loc	1 11 13
	cvta.to.global.u64 	%rd7, %rd2;
	.loc	1 20 5
	mul.wide.s32 	%rd8, %r11, 4;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.nc.f32 	%f1, [%rd9];
	.loc	1 11 13
	cvta.to.global.u64 	%rd10, %rd3;
	.loc	1 20 5
	mul.wide.s32 	%rd11, %r1, 4;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.f32 	[%rd12], %f1;

$L__BB0_2:
	.loc	1 21 1
	ret;

}
	// .globl	mean_pooling_f32
.visible .entry mean_pooling_f32(
	.param .u64 mean_pooling_f32_param_0,
	.param .u64 mean_pooling_f32_param_1,
	.param .u64 mean_pooling_f32_param_2,
	.param .u32 mean_pooling_f32_param_3,
	.param .u32 mean_pooling_f32_param_4,
	.param .u32 mean_pooling_f32_param_5,
	.param .u32 mean_pooling_f32_param_6
)
{
	.reg .pred 	%p<18>;
	.reg .f32 	%f<108>;
	.reg .b32 	%r<80>;
	.reg .b64 	%rd<37>;
	.loc	1 23 0


	ld.param.u64 	%rd11, [mean_pooling_f32_param_0];
	ld.param.u64 	%rd12, [mean_pooling_f32_param_1];
	ld.param.u64 	%rd10, [mean_pooling_f32_param_2];
	ld.param.u32 	%r45, [mean_pooling_f32_param_3];
	ld.param.u32 	%r42, [mean_pooling_f32_param_4];
	ld.param.u32 	%r43, [mean_pooling_f32_param_5];
	ld.param.u32 	%r44, [mean_pooling_f32_param_6];
	.loc	1 32 13
	cvta.to.global.u64 	%rd1, %rd11;
	cvta.to.global.u64 	%rd2, %rd12;
	mov.u32 	%r46, %ntid.x;
	mov.u32 	%r47, %ctaid.x;
	mul.lo.s32 	%r1, %r47, %r46;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r3, %r1, %r2;
	.loc	1 33 15
	mul.lo.s32 	%r48, %r43, %r45;
	.loc	1 34 5
	setp.ge.s32 	%p1, %r3, %r48;
	@%p1 bra 	$L__BB1_28;

	.loc	1 38 11
	div.s32 	%r4, %r3, %r43;
	.loc	1 45 5
	setp.lt.s32 	%p2, %r42, 1;
	mov.f32 	%f107, 0f00000000;
	mov.f32 	%f81, %f107;
	mov.f32 	%f82, %f107;
	@%p2 bra 	$L__BB1_25;

	.loc	1 0 5
	setp.eq.s32 	%p3, %r44, 0;
	.loc	1 46 24
	add.s32 	%r5, %r42, -1;
	and.b32  	%r74, %r42, 3;
	@%p3 bra 	$L__BB1_19;

	setp.lt.u32 	%p4, %r5, 3;
	mov.f32 	%f82, 0f00000000;
	mov.u32 	%r72, 0;
	mov.f32 	%f81, %f82;
	@%p4 bra 	$L__BB1_14;

	mul.lo.s32 	%r51, %r4, %r5;
	add.s32 	%r52, %r51, 3;
	mad.lo.s32 	%r70, %r43, %r52, %r3;
	shl.b32 	%r8, %r43, 2;
	mul.lo.s32 	%r53, %r4, %r42;
	add.s32 	%r54, %r51, 2;
	mad.lo.s32 	%r69, %r43, %r54, %r3;
	add.s32 	%r55, %r51, 1;
	mad.lo.s32 	%r68, %r43, %r55, %r3;
	mul.lo.s32 	%r56, %r4, %r43;
	mad.lo.s32 	%r57, %r56, %r5, %r2;
	add.s32 	%r67, %r57, %r1;
	sub.s32 	%r12, %r74, %r42;
	mul.wide.s32 	%rd13, %r53, 4;
	add.s64 	%rd35, %rd2, %rd13;

$L__BB1_5:
	ld.global.nc.f32 	%f3, [%rd35];
	.loc	1 47 9
	setp.leu.ftz.f32 	%p5, %f3, 0f00000000;
	@%p5 bra 	$L__BB1_7;

	.loc	1 48 13
	mul.wide.s32 	%rd14, %r67, 4;
	add.s64 	%rd15, %rd1, %rd14;
	ld.global.nc.f32 	%f57, [%rd15];
	fma.rn.ftz.f32 	%f81, %f3, %f57, %f81;
	.loc	1 49 13
	add.ftz.f32 	%f82, %f82, %f3;

$L__BB1_7:
	.loc	1 46 24
	ld.global.nc.f32 	%f8, [%rd35+4];
	.loc	1 47 9
	setp.leu.ftz.f32 	%p6, %f8, 0f00000000;
	@%p6 bra 	$L__BB1_9;

	.loc	1 48 13
	mul.wide.s32 	%rd16, %r68, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.nc.f32 	%f58, [%rd17];
	fma.rn.ftz.f32 	%f81, %f8, %f58, %f81;
	.loc	1 49 13
	add.ftz.f32 	%f82, %f82, %f8;

$L__BB1_9:
	.loc	1 46 24
	ld.global.nc.f32 	%f13, [%rd35+8];
	.loc	1 47 9
	setp.leu.ftz.f32 	%p7, %f13, 0f00000000;
	@%p7 bra 	$L__BB1_11;

	.loc	1 48 13
	mul.wide.s32 	%rd18, %r69, 4;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.nc.f32 	%f59, [%rd19];
	fma.rn.ftz.f32 	%f81, %f13, %f59, %f81;
	.loc	1 49 13
	add.ftz.f32 	%f82, %f82, %f13;

$L__BB1_11:
	.loc	1 46 24
	ld.global.nc.f32 	%f18, [%rd35+12];
	.loc	1 47 9
	setp.leu.ftz.f32 	%p8, %f18, 0f00000000;
	@%p8 bra 	$L__BB1_13;

	.loc	1 48 13
	mul.wide.s32 	%rd20, %r70, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.nc.f32 	%f60, [%rd21];
	fma.rn.ftz.f32 	%f81, %f18, %f60, %f81;
	.loc	1 49 13
	add.ftz.f32 	%f82, %f82, %f18;

$L__BB1_13:
	.loc	1 45 5
	add.s32 	%r70, %r70, %r8;
	add.s32 	%r69, %r69, %r8;
	add.s32 	%r68, %r68, %r8;
	add.s32 	%r67, %r67, %r8;
	.loc	1 45 30
	add.s32 	%r72, %r72, 4;
	.loc	1 45 5
	add.s32 	%r58, %r12, %r72;
	setp.ne.s32 	%p9, %r58, 0;
	add.s64 	%rd35, %rd35, 16;
	@%p9 bra 	$L__BB1_5;

$L__BB1_14:
	.loc	1 46 24
	setp.eq.s32 	%p10, %r74, 0;
	@%p10 bra 	$L__BB1_25;

	.loc	1 47 9
	mad.lo.s32 	%r59, %r4, %r5, %r72;
	mad.lo.s32 	%r73, %r43, %r59, %r3;
	mad.lo.s32 	%r60, %r4, %r42, %r72;
	mul.wide.s32 	%rd22, %r60, 4;
	add.s64 	%rd36, %rd2, %rd22;

$L__BB1_16:
	.pragma "nounroll";
	.loc	1 46 24
	ld.global.nc.f32 	%f29, [%rd36];
	.loc	1 47 9
	setp.leu.ftz.f32 	%p11, %f29, 0f00000000;
	@%p11 bra 	$L__BB1_18;

	.loc	1 48 13
	mul.wide.s32 	%rd23, %r73, 4;
	add.s64 	%rd24, %rd1, %rd23;
	ld.global.nc.f32 	%f61, [%rd24];
	fma.rn.ftz.f32 	%f81, %f29, %f61, %f81;
	.loc	1 49 13
	add.ftz.f32 	%f82, %f82, %f29;

$L__BB1_18:
	.loc	1 45 5
	add.s32 	%r73, %r73, %r43;
	add.s64 	%rd36, %rd36, 4;
	add.s32 	%r74, %r74, -1;
	setp.eq.s32 	%p12, %r74, 0;
	@%p12 bra 	$L__BB1_25;
	bra.uni 	$L__BB1_16;

$L__BB1_19:
	.loc	1 46 24
	setp.lt.u32 	%p13, %r5, 3;
	mov.f32 	%f82, 0f00000000;
	mov.u32 	%r77, 0;
	mov.f32 	%f81, %f82;
	@%p13 bra 	$L__BB1_22;

	shl.b32 	%r29, %r43, 2;
	mul.lo.s32 	%r63, %r4, %r43;
	mad.lo.s32 	%r64, %r63, %r5, %r2;
	add.s32 	%r75, %r64, %r1;
	sub.s32 	%r31, %r74, %r42;
	mul.wide.s32 	%rd9, %r43, 4;

$L__BB1_21:
	.loc	1 48 13
	mul.wide.s32 	%rd25, %r75, 4;
	add.s64 	%rd26, %rd1, %rd25;
	ld.global.nc.f32 	%f67, [%rd26];
	add.ftz.f32 	%f68, %f81, %f67;
	add.s64 	%rd27, %rd26, %rd9;
	ld.global.nc.f32 	%f69, [%rd27];
	add.ftz.f32 	%f70, %f68, %f69;
	.loc	1 49 13
	add.ftz.f32 	%f71, %f82, 0f3F800000;
	add.ftz.f32 	%f72, %f71, 0f3F800000;
	.loc	1 48 13
	add.s64 	%rd28, %rd27, %rd9;
	ld.global.nc.f32 	%f73, [%rd28];
	add.ftz.f32 	%f74, %f70, %f73;
	.loc	1 49 13
	add.ftz.f32 	%f75, %f72, 0f3F800000;
	.loc	1 48 13
	add.s64 	%rd29, %rd28, %rd9;
	ld.global.nc.f32 	%f76, [%rd29];
	add.ftz.f32 	%f81, %f74, %f76;
	.loc	1 49 13
	add.ftz.f32 	%f82, %f75, 0f3F800000;
	.loc	1 45 5
	add.s32 	%r75, %r75, %r29;
	.loc	1 45 30
	add.s32 	%r77, %r77, 4;
	.loc	1 45 5
	add.s32 	%r65, %r31, %r77;
	setp.ne.s32 	%p14, %r65, 0;
	@%p14 bra 	$L__BB1_21;

$L__BB1_22:
	.loc	1 46 24
	setp.eq.s32 	%p15, %r74, 0;
	@%p15 bra 	$L__BB1_25;

	.loc	1 45 5
	mad.lo.s32 	%r66, %r4, %r5, %r77;
	mad.lo.s32 	%r78, %r43, %r66, %r3;

$L__BB1_24:
	.pragma "nounroll";
	.loc	1 48 13
	mul.wide.s32 	%rd30, %r78, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.global.nc.f32 	%f77, [%rd31];
	add.ftz.f32 	%f81, %f81, %f77;
	.loc	1 49 13
	add.ftz.f32 	%f82, %f82, 0f3F800000;
	.loc	1 45 5
	add.s32 	%r78, %r78, %r43;
	add.s32 	%r74, %r74, -1;
	setp.ne.s32 	%p16, %r74, 0;
	@%p16 bra 	$L__BB1_24;

$L__BB1_25:
	.loc	1 53 5
	setp.leu.ftz.f32 	%p17, %f82, 0f00000000;
	@%p17 bra 	$L__BB1_27;

	div.approx.ftz.f32 	%f107, %f81, %f82;

$L__BB1_27:
	.loc	1 32 13
	cvta.to.global.u64 	%rd32, %rd10;
	.loc	1 53 5
	mul.wide.s32 	%rd33, %r3, 4;
	add.s64 	%rd34, %rd32, %rd33;
	st.global.f32 	[%rd34], %f107;

$L__BB1_28:
	.loc	1 54 1
	ret;

}
	// .globl	l2_normalize_f32
.visible .entry l2_normalize_f32(
	.param .u64 l2_normalize_f32_param_0,
	.param .u32 l2_normalize_f32_param_1,
	.param .u32 l2_normalize_f32_param_2,
	.param .f32 l2_normalize_f32_param_3
)
{
	.reg .pred 	%p<13>;
	.reg .f32 	%f<42>;
	.reg .b32 	%r<43>;
	.reg .b64 	%rd<25>;
	.loc	1 56 0


	ld.param.u64 	%rd14, [l2_normalize_f32_param_0];
	ld.param.u32 	%r21, [l2_normalize_f32_param_1];
	ld.param.u32 	%r20, [l2_normalize_f32_param_2];
	ld.param.f32 	%f11, [l2_normalize_f32_param_3];
	.loc	1 62 11
	cvta.to.global.u64 	%rd1, %rd14;
	mov.u32 	%r22, %ntid.x;
	mov.u32 	%r23, %ctaid.x;
	mov.u32 	%r24, %tid.x;
	mad.lo.s32 	%r1, %r23, %r22, %r24;
	.loc	1 63 5
	setp.ge.s32 	%p1, %r1, %r21;
	@%p1 bra 	$L__BB2_17;

	.loc	1 69 5
	setp.lt.s32 	%p2, %r20, 1;
	mov.f32 	%f41, 0f00000000;
	mov.f32 	%f40, %f41;
	@%p2 bra 	$L__BB2_8;

	add.s32 	%r26, %r20, -1;
	and.b32  	%r38, %r20, 3;
	setp.lt.u32 	%p3, %r26, 3;
	mov.f32 	%f40, 0f00000000;
	mov.u32 	%r37, 0;
	@%p3 bra 	$L__BB2_5;

	sub.s32 	%r36, %r20, %r38;
	mul.lo.s32 	%r28, %r20, %r1;
	mul.wide.s32 	%rd15, %r28, 4;
	add.s64 	%rd16, %rd1, %rd15;
	add.s64 	%rd21, %rd16, 8;

$L__BB2_4:
	.loc	1 70 17
	ld.global.f32 	%f16, [%rd21+-8];
	.loc	1 71 9
	fma.rn.ftz.f32 	%f17, %f16, %f16, %f40;
	.loc	1 70 17
	ld.global.f32 	%f18, [%rd21+-4];
	.loc	1 71 9
	fma.rn.ftz.f32 	%f19, %f18, %f18, %f17;
	.loc	1 70 17
	ld.global.f32 	%f20, [%rd21];
	.loc	1 71 9
	fma.rn.ftz.f32 	%f21, %f20, %f20, %f19;
	.loc	1 70 17
	ld.global.f32 	%f22, [%rd21+4];
	.loc	1 71 9
	fma.rn.ftz.f32 	%f40, %f22, %f22, %f21;
	.loc	1 69 37
	add.s32 	%r37, %r37, 4;
	.loc	1 69 5
	add.s64 	%rd21, %rd21, 16;
	add.s32 	%r36, %r36, -4;
	setp.ne.s32 	%p4, %r36, 0;
	@%p4 bra 	$L__BB2_4;

$L__BB2_5:
	setp.eq.s32 	%p5, %r38, 0;
	@%p5 bra 	$L__BB2_8;

	mad.lo.s32 	%r29, %r20, %r1, %r37;
	mul.wide.s32 	%rd17, %r29, 4;
	add.s64 	%rd22, %rd1, %rd17;

$L__BB2_7:
	.pragma "nounroll";
	.loc	1 70 17
	ld.global.f32 	%f23, [%rd22];
	.loc	1 71 9
	fma.rn.ftz.f32 	%f40, %f23, %f23, %f40;
	.loc	1 69 5
	add.s64 	%rd22, %rd22, 4;
	add.s32 	%r38, %r38, -1;
	setp.ne.s32 	%p6, %r38, 0;
	@%p6 bra 	$L__BB2_7;

$L__BB2_8:
	.loc	1 73 16
	add.ftz.f32 	%f25, %f40, %f11;
	.loc	1 73 18
	sqrt.approx.ftz.f32 	%f8, %f25;
	.loc	1 74 15
	setp.leu.ftz.f32 	%p7, %f8, 0f00000000;
	@%p7 bra 	$L__BB2_10;

	rcp.approx.ftz.f32 	%f41, %f8;

$L__BB2_10:
	.loc	1 76 5
	@%p2 bra 	$L__BB2_17;

	add.s32 	%r31, %r20, -1;
	and.b32  	%r42, %r20, 3;
	setp.lt.u32 	%p9, %r31, 3;
	mov.u32 	%r41, 0;
	@%p9 bra 	$L__BB2_14;

	sub.s32 	%r40, %r20, %r42;
	mul.lo.s32 	%r33, %r20, %r1;
	mul.wide.s32 	%rd18, %r33, 4;
	add.s64 	%rd19, %rd1, %rd18;
	add.s64 	%rd23, %rd19, 8;

$L__BB2_13:
	.loc	1 77 9
	ld.global.f32 	%f26, [%rd23+-8];
	mul.ftz.f32 	%f27, %f41, %f26;
	st.global.f32 	[%rd23+-8], %f27;
	ld.global.f32 	%f28, [%rd23+-4];
	mul.ftz.f32 	%f29, %f41, %f28;
	st.global.f32 	[%rd23+-4], %f29;
	ld.global.f32 	%f30, [%rd23];
	mul.ftz.f32 	%f31, %f41, %f30;
	st.global.f32 	[%rd23], %f31;
	ld.global.f32 	%f32, [%rd23+4];
	mul.ftz.f32 	%f33, %f41, %f32;
	st.global.f32 	[%rd23+4], %f33;
	.loc	1 76 37
	add.s32 	%r41, %r41, 4;
	.loc	1 76 5
	add.s64 	%rd23, %rd23, 16;
	add.s32 	%r40, %r40, -4;
	setp.ne.s32 	%p10, %r40, 0;
	@%p10 bra 	$L__BB2_13;

$L__BB2_14:
	setp.eq.s32 	%p11, %r42, 0;
	@%p11 bra 	$L__BB2_17;

	mad.lo.s32 	%r34, %r20, %r1, %r41;
	mul.wide.s32 	%rd20, %r34, 4;
	add.s64 	%rd24, %rd1, %rd20;

$L__BB2_16:
	.pragma "nounroll";
	.loc	1 77 9
	ld.global.f32 	%f34, [%rd24];
	mul.ftz.f32 	%f35, %f41, %f34;
	st.global.f32 	[%rd24], %f35;
	.loc	1 76 5
	add.s64 	%rd24, %rd24, 4;
	add.s32 	%r42, %r42, -1;
	setp.ne.s32 	%p12, %r42, 0;
	@%p12 bra 	$L__BB2_16;

$L__BB2_17:
	.loc	1 79 1
	ret;

}
	// .globl	cls_extract_f32
.visible .entry cls_extract_f32(
	.param .u64 cls_extract_f32_param_0,
	.param .u64 cls_extract_f32_param_1,
	.param .u32 cls_extract_f32_param_2,
	.param .u32 cls_extract_f32_param_3,
	.param .u32 cls_extract_f32_param_4,
	.param .u32 cls_extract_f32_param_5
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<14>;
	.reg .b64 	%rd<9>;
	.loc	1 81 0


	ld.param.u64 	%rd1, [cls_extract_f32_param_0];
	ld.param.u64 	%rd2, [cls_extract_f32_param_1];
	ld.param.u32 	%r5, [cls_extract_f32_param_2];
	ld.param.u32 	%r2, [cls_extract_f32_param_3];
	ld.param.u32 	%r3, [cls_extract_f32_param_4];
	ld.param.u32 	%r4, [cls_extract_f32_param_5];
	.loc	1 89 13
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	.loc	1 90 15
	mul.lo.s32 	%r9, %r3, %r5;
	.loc	1 91 5
	setp.ge.s32 	%p1, %r1, %r9;
	@%p1 bra 	$L__BB3_2;

	.loc	1 89 13
	cvta.to.global.u64 	%rd3, %rd1;
	add.s32 	%r10, %r2, -1;
	.loc	1 95 11
	div.s32 	%r11, %r1, %r3;
	mad.lo.s32 	%r12, %r11, %r10, %r4;
	.loc	1 97 13
	mad.lo.s32 	%r13, %r12, %r3, %r1;
	.loc	1 98 5
	mul.wide.s32 	%rd4, %r13, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5];
	.loc	1 89 13
	cvta.to.global.u64 	%rd6, %rd2;
	.loc	1 98 5
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB3_2:
	.loc	1 99 1
	ret;

}

	.file	1 "/home/putao/code/rust/gllm-kernels/src/cuda_kernels/kernels/pooling.cu"
