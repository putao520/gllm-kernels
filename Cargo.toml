[package]
name = "gllm-kernels"
version = "0.2.0"
edition = "2021"
authors = ["gllm contributors"]
license = "Apache-2.0"
description = "Low-level attention kernels with runtime backend selection (CUDA/ROCm/Metal/WGPU/CPU)"
repository = "https://github.com/putao520/gllm-kernels"
homepage = "https://github.com/putao520/gllm-kernels"
keywords = ["attention", "kernels", "llm", "gpu", "inference"]
categories = ["algorithms", "science"]

[lib]
name = "gllm_kernels"
path = "src/lib.rs"

[features]
# 默认：全后端支持，运行时动态选择
default = ["full"]

# 完整版：所有后端 + 所有 kernel（Fat Binary，全部预编译嵌入）
full = ["all-backends", "all-kernels"]

# 所有后端（运行时检测，动态加载）
all-backends = []

# 所有自定义 kernel
all-kernels = []

# Fusion 支持（已移除 Burn 依赖，保留 feature 以兼容）
fusion = []

# NCCL 多 GPU（需要 CUDA 环境）
nccl = ["cudarc/nccl"]

# RCCL 多 GPU（需要 ROCm 环境）
rccl = []

# Flash Attention v3 优化（Hopper+）
flash-attention-v3 = [
    "flash-attention-v3-wgmma",
    "flash-attention-v3-async",
    "flash-attention-v3-fp8",
    "flash-attention-v3-block-quant",
]
flash-attention-v3-wgmma = []
flash-attention-v3-async = []
flash-attention-v3-fp8 = []
flash-attention-v3-block-quant = []

# 精简版（仅 CPU，用于测试/CI）
minimal = []

# Fat Binary 预编译内核（嵌入 ~10MB）
embedded-kernels = []

# 运行时下载内核（首次使用时从 GitHub Release 下载）
download-kernels = []

# Backend-specific kernel features (for conditional compilation)
cpu = []
cuda = []
cuda-kernel = []
rocm-kernel = []
metal-kernel = []
wgpu-kernel = []
fused-kernel = []
paged-kernel = []
softmax-kernel = []

[dependencies]
# ADR-001: Burn 依赖已移除，统一使用 Backend trait + 原始切片 API

# CUDA 支持（动态加载，运行时检测）
cudarc = { version = "0.18", default-features = false, features = ["std", "driver", "nvrtc", "f16", "cuda-12090", "dynamic-loading"] }

# WGPU 支持（跨平台 GPU）
wgpu = { version = "26.0" }
pollster = { version = "0.4" }

# 通用依赖
log = "0.4"
crossbeam-channel = "0.5"
serde = { version = "1", features = ["derive"] }
serde_json = "1"
half = "2.7"
libloading = "0.8"  # 动态加载 HIP/ROCm 库
memmap2 = "0.9"     # Engram: memory-mapped embedding tables
bytemuck = { version = "1.24.0", features = ["derive"] }
dirs = "5.0"        # Fat Binary: cache directory for downloaded kernels

# 平台特定（条件编译，非 feature flag）
[target.'cfg(target_os = "macos")'.dependencies]
metal = { version = "0.29" }
objc = { version = "0.2" }

[dev-dependencies]
criterion = "0.5"

[[bench]]
name = "attention_bench"
harness = false

# GPU/CPU comparison tests (REQ-VERIFY-001)
[[test]]
name = "flash_attention_comparison"
path = "tests/gpu_cpu_comparison/flash_attention.rs"

[[test]]
name = "paged_attention_comparison"
path = "tests/gpu_cpu_comparison/paged_attention.rs"

# Numerical stability tests (REQ-VERIFY-002)
[[test]]
name = "log_softmax_stability"
path = "tests/numerical/log_softmax_stability.rs"
