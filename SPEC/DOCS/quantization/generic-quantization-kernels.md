# æ³›å‹é‡åŒ–å†…æ ¸æ¶æ„è®¾è®¡

> **å…³è”éœ€æ±‚**: REQ-QUANT-004 (æ¨¡æ¿åŒ–é‡åŒ–å†…æ ¸)
> **å…³è”çº¦æŸ**: CLAUDE.md ARCH-QUANT-TEMPLATE (FROZEN)
> **çŠ¶æ€**: ğŸŸ¡ è®¾è®¡ä¸­

---

## 1. æ¶æ„ç›®æ ‡

### 1.1 æ ¸å¿ƒé—®é¢˜

å½“å‰ `cpu_kernels/mod.rs` ä¸­çš„é‡åŒ–è®¡ç®—å®ç°å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

| é—®é¢˜ | å½“å‰å®ç° | å½±å“ |
|------|----------|------|
| **éæ³›å‹** | æ¯ä¸ªé‡åŒ–ä½å®½ç‹¬ç«‹å‡½æ•° (`matmul_int8`, `matmul_int4`, `matmul_int2`, `matmul_int1`) | ä»£ç é‡å¤ï¼Œç»´æŠ¤æˆæœ¬é«˜ |
| **f32 ç‰¹åŒ–** | `linear()` åªæ”¯æŒ f32 æƒé‡ | æ— æ³•åˆ©ç”¨é‡åŒ–åŠ é€Ÿ |
| **æ‰‹åŠ¨åˆ†æ´¾** | è°ƒç”¨æ–¹éœ€è¦æ ¹æ® dtype é€‰æ‹©å‡½æ•° | æ˜“å‡ºé”™ï¼Œæ‰©å±•æ€§å·® |

### 1.2 è®¾è®¡ç›®æ ‡

| ç›®æ ‡ | æè¿° | éªŒæ”¶æ ‡å‡† |
|------|------|----------|
| **æ³›å‹ MatMul** | å•ä¸€ trait æ¥å£æ”¯æŒæ‰€æœ‰ç²¾åº¦ç±»å‹ | `MatMul<T>` for T in {F32, F16, BF16, I8, I4, I2, I1} |
| **é›¶è¿è¡Œæ—¶å¼€é”€** | ç¼–è¯‘æ—¶å•æ€åŒ–ï¼Œæ— åŠ¨æ€åˆ†å‘ | æ€§èƒ½ç­‰åŒäºæ‰‹å†™ç‰¹åŒ–ç‰ˆæœ¬ |
| **ç»Ÿä¸€å­˜å‚¨æŠ½è±¡** | é‡åŒ–æƒé‡ç»Ÿä¸€ä½¿ç”¨ `u8` å®¹å™¨ | æ”¯æŒ `PackedU8(PackedBits)` |
| **è‡ªåŠ¨è·¯å¾„é€‰æ‹©** | æ ¹æ®æƒé‡æ ¼å¼è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¡ç®—è·¯å¾„ | åˆ†ç¦»æƒé‡ â†’ 3Ã—å°çŸ©é˜µä¹˜æ³•ï¼Œèåˆæƒé‡ â†’ 1Ã—å¤§çŸ©é˜µä¹˜æ³• |

---

## 2. Rust æ³›å‹æ¶æ„è®¾è®¡

### 2.1 æ ¸å¿ƒ Trait å®šä¹‰

```rust
/// é‡åŒ–çŸ©é˜µä¹˜æ³• Trait
///
/// æ³›å‹å‚æ•° T: æ•°æ®ç±»å‹ (f32, f16, bf16, i8, PackedI4, PackedI2, PackedI1)
pub trait QuantizedMatMul<T: DTypeTrait> {
    /// è®¡ç®— output = input @ weight + bias
    ///
    /// # å‚æ•°
    /// - `input`: [m, k] è¾“å…¥çŸ©é˜µ (å§‹ç»ˆä¸º f32)
    /// - `weight`: é‡åŒ–æƒé‡ [n, k] (å­˜å‚¨æ ¼å¼ç”± T å†³å®š)
    /// - `scales`: æ¯è¡Œ/æ¯å—çš„é‡åŒ– scale [n] æˆ– [n_blocks]
    /// - `output`: [m, n] è¾“å‡ºçŸ©é˜µ (å§‹ç»ˆä¸º f32)
    /// - `m`: batch/seq_len
    /// - `n`: output_dim
    /// - `k`: input_dim
    fn matmul(
        input: &[f32],
        weight: &[T::Storage],
        scales: &[f16],
        bias: Option<&[f32]>,
        output: &mut [f32],
        m: usize,
        n: usize,
        k: usize,
    ) -> Result<(), BackendError>;
}

/// æ•°æ®ç±»å‹ Trait
pub trait DTypeTrait: Sized + Copy + 'static {
    /// å­˜å‚¨ç±»å‹ (f32, f16, u8)
    type Storage: Copy;
    /// åé‡åŒ–åˆ° f32
    fn dequantize(scaled: Self::Storage, scale: f16) -> f32;
    /// æ¯ä¸ªå€¼å ç”¨çš„ bit æ•°
    const BITS: u8;
    /// æ˜¯å¦æ˜¯æ‰“åŒ…ç±»å‹ (int4/2/1)
    const IS_PACKED: bool;
}
```

### 2.2 Trait å®ç°æ¨¡æ¿

```rust
// F32 å®ç° (è‡ªç ” SIMD å†…æ ¸)
impl QuantizedMatMul<F32> for CpuBackend {
    fn matmul(...) {
        // è‡ªç ”åˆ†å— SIMD matmul (ç¦æ­¢ faer/OpenBLAS/MKL)
        matmul_tiled_simd(&mut dst, &lhs, &rhs, m, n, k);
    }
}

// Int8 å®ç°
impl QuantizedMatMul<I8> for CpuBackend {
    fn matmul(...) {
        // SIMD åŠ é€Ÿçš„ int8 åé‡åŒ– + FMA
        for i in 0..m {
            for j in 0..n {
                let mut sum = 0.0f32;
                // å±•å¼€å†…å±‚å¾ªç¯ï¼Œå¯ç”¨ SIMD
                for kk in (0..k).step_by(8) {
                    let w_vec = load_int8_weight(&weight[j * k + kk..]);
                    let x_vec = dequantize_to_f32(w_vec, scales[j]);
                    sum = simd_fma(x_vec, &input[i * k + kk..], sum);
                }
                output[i * n + j] = sum + bias.map_or(0.0, |b| b[j]);
            }
        }
    }
}

// Int4 å®ç° (ä½¿ç”¨ PackedBits)
impl QuantizedMatMul<PackedI4> for CpuBackend {
    fn matmul(...) {
        let values_per_byte = 2; // Int4
        for i in 0..m {
            for j in 0..n {
                let mut sum = 0.0f32;
                for kk in 0..k {
                    let byte_idx = j * k + kk / 2;
                    let nibble = if kk % 2 == 0 {
                        weight[byte_idx] & 0x0f
                    } else {
                        weight[byte_idx] >> 4
                    };
                    let w = unpack_int4(nibble) as f32 * scales[j] as f32;
                    sum += input[i * k + kk] * w;
                }
                output[i * n + j] = sum + bias.map_or(0.0, |b| b[j]);
            }
        }
    }
}
```

### 2.3 ç±»å‹ç³»ç»Ÿæ˜ å°„

```rust
// DType â†’ DTypeTrait æ˜ å°„
impl DTypeTrait for F32Type {
    type Storage = f32;
    fn dequantize(s: f32, _: f16) -> f32 { s }
    const BITS: u8 = 32;
    const IS_PACKED: bool = false;
}

impl DTypeTrait for I8Type {
    type Storage = i8;
    fn dequantize(s: i8, scale: f16) -> f32 { s as f32 * scale as f32 }
    const BITS: u8 = 8;
    const IS_PACKED: bool = false;
}

impl DTypeTrait for PackedI4Type {
    type Storage = u8;
    fn dequantize(p: u8, scale: f16) -> f32 {
        let value = if p & 0x08 != 0 { (p as i8) - 16 } else { p as i8 };
        value as f32 * scale as f32
    }
    const BITS: u8 = 4;
    const IS_PACKED: bool = true;
}

// ç±»ä¼¼å®šä¹‰ Int2, Int1
```

### 2.4 ç¼–è¯‘æ—¶å•æ€åŒ–

```rust
/// é€šç”¨ Linear å±‚
///
/// ç¼–è¯‘å™¨ä¸ºæ¯ä¸ª T ç”Ÿæˆç‹¬ç«‹ä»£ç ï¼Œé›¶è¿è¡Œæ—¶å¼€é”€
pub fn linear_generic<T: DTypeTrait>(
    backend: &CpuBackend,
    input: &[f32],
    weight: &[T::Storage],
    scales: &[f16],
    bias: Option<&[f32]>,
    output: &mut [f32],
    m: usize,
    n: usize,
    k: usize,
) -> Result<(), BackendError>
where
    CpuBackend: QuantizedMatMul<T>,
{
    <CpuBackend as QuantizedMatMul<T>>::matmul(input, weight, scales, bias, output, m, n, k)
}

// ä½¿ç”¨ç¤ºä¾‹ï¼š
// linear_generic::<F32>(...)     â†’ ç”Ÿæˆ f32 ä¸“ç”¨ç‰ˆæœ¬
// linear_generic::<I8>(...)      â†’ ç”Ÿæˆ int8 ä¸“ç”¨ç‰ˆæœ¬
// linear_generic::<PackedI4>(...) â†’ ç”Ÿæˆ int4 ä¸“ç”¨ç‰ˆæœ¬
```

---

## 3. QKV æŠ•å½±ç»Ÿä¸€ API

### 3.1 é€šç”¨ QKV æŠ•å½±æ¥å£

```rust
/// QKV æŠ•å½± + RoPE ç»Ÿä¸€æ¥å£
///
/// è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è·¯å¾„ï¼š
/// - åˆ†ç¦»æƒé‡ â†’ 3Ã—å°çŸ©é˜µä¹˜æ³• (æœ€ä¼˜ç¼“å­˜æ€§èƒ½)
/// - èåˆæƒé‡ â†’ 1Ã—å¤§çŸ©é˜µä¹˜æ³•
pub enum QkvWeightFormat<'a, T: DTypeTrait> {
    /// åˆ†ç¦»çš„ Q, K, V æƒé‡ (æœ€ä¼˜)
    Separated {
        q_weight: &'a [T::Storage],
        k_weight: &'a [T::Storage],
        v_weight: &'a [T::Storage],
        q_scales: Option<&'a [f16]>,
        k_scales: Option<&'a [f16]>,
        v_scales: Option<&'a [f16]>,
    },
    /// èåˆçš„ QKV æƒé‡
    Fused {
        qkv_weight: &'a [T::Storage],
        scales: Option<&'a [f16]>,
    },
}

pub fn qkv_projection_rope_generic<T: DTypeTrait>(
    backend: &CpuBackend,
    input: &[f32],
    qkv_weights: &QkvWeightFormat<T>,
    positions: &[i32],
    q_output: &mut [f32],
    k_output: &mut [f32],
    v_output: &mut [f32],
    seq_len: usize,
    hidden_size: usize,
    num_heads: usize,
    num_kv_heads: usize,
    head_dim: usize,
    rotary_dim: usize,
    rope_theta: f32,
    rope_scale: f32,
) -> Result<(), BackendError>
where
    CpuBackend: QuantizedMatMul<T>,
{
    match qkv_weights {
        QkvWeightFormat::Separated { q_weight, k_weight, v_weight, q_scales, k_scales, v_scales } => {
            // æœ€ä¼˜è·¯å¾„ï¼š3Ã—ç‹¬ç«‹å°çŸ©é˜µä¹˜æ³•
            let q_out = num_heads * head_dim;
            let kv_out = num_kv_heads * head_dim;

            linear_generic::<T>(
                backend,
                input,
                q_weight,
                q_scales.unwrap_or(&[]),
                None,
                q_output,
                seq_len,
                q_out,
                hidden_size,
            )?;

            linear_generic::<T>(
                backend,
                input,
                k_weight,
                k_scales.unwrap_or(&[]),
                None,
                k_output,
                seq_len,
                kv_out,
                hidden_size,
            )?;

            linear_generic::<T>(
                backend,
                input,
                v_weight,
                v_scales.unwrap_or(&[]),
                None,
                v_output,
                seq_len,
                kv_out,
                hidden_size,
            )?;

            apply_rope_separated(
                q_output, k_output, positions,
                seq_len, num_heads, num_kv_heads,
                head_dim, rotary_dim, rope_theta, rope_scale,
            )?;
        }
        QkvWeightFormat::Fused { qkv_weight, scales } => {
            // å›é€€è·¯å¾„ï¼š1Ã—å¤§çŸ©é˜µä¹˜æ³• (å…¼å®¹æ€§)
            let qkv_stride = num_heads * head_dim + 2 * num_kv_heads * head_dim;
            let mut qkv_buf = vec![0.0f32; seq_len * qkv_stride];

            linear_generic::<T>(
                backend,
                input,
                qkv_weight,
                scales.unwrap_or(&[]),
                None,
                &mut qkv_buf,
                seq_len,
                qkv_stride,
                hidden_size,
            )?;

            split_and_apply_rope(
                &qkv_buf, q_output, k_output, v_output,
                positions, seq_len, num_heads, num_kv_heads,
                head_dim, rotary_dim, rope_theta, rope_scale,
            )?;
        }
    }
    Ok(())
}
```

### 3.2 è‡ªåŠ¨æ ¼å¼æ£€æµ‹

```rust
impl CpuBackend {
    /// ä»æƒé‡åç§°è‡ªåŠ¨æ£€æµ‹ QKV æ ¼å¼
    pub fn detect_qkv_format<T: DTypeTrait>(
        &self,
        weights: &TensorMap,
        layer: usize,
    ) -> Result<QkvWeightFormat<T>, BackendError> {
        // ä¼˜å…ˆæ£€æµ‹åˆ†ç¦»æƒé‡
        let q_name = format!("model.layers.{}.self_attn.q_proj.weight", layer);
        let k_name = format!("model.layers.{}.self_attn.k_proj.weight", layer);
        let v_name = format!("model.layers.{}.self_attn.v_proj.weight", layer);

        if let (Some(q), Some(k), Some(v)) = (
            weights.get_tensor::<T>(&q_name),
            weights.get_tensor::<T>(&k_name),
            weights.get_tensor::<T>(&v_name),
        ) {
            return Ok(QkvWeightFormat::Separated {
                q_weight: q.data(),
                k_weight: k.data(),
                v_weight: v.data(),
                q_scales: q.scales(),
                k_scales: k.scales(),
                v_scales: v.scales(),
            });
        }

        // å›é€€åˆ°èåˆæƒé‡
        let qkv_name = format!("model.layers.{}.self_attn.qkv_proj.weight", layer);
        if let Some(qkv) = weights.get_tensor::<T>(&qkv_name) {
            return Ok(QkvWeightFormat::Fused {
                qkv_weight: qkv.data(),
                scales: qkv.scales(),
            });
        }

        Err(BackendError::MissingWeight(format!(
            "QKV weights not found for layer {}", layer
        )))
    }
}
```

---

## 4. CUDA ç«¯å®ç°æ˜ å°„

### 4.1 æ¨¡æ¿å®ä¾‹åŒ–ç­–ç•¥

| Rust æ³›å‹ | CUDA æ¨¡æ¿ | å®ä¾‹åŒ– |
|-----------|-----------|--------|
| `linear_generic::<F32>` | `matmul_f32` | æ— æ¨¡æ¿ |
| `linear_generic::<I8>` | `matmul_int8<BITS=8>` | `BITS=8` |
| `linear_generic::<PackedI4>` | `matmul_int4<BITS=4>` | `BITS=4` |
| `linear_generic::<PackedI2>` | `matmul_int2<BITS=2>` | `BITS=2` |
| `linear_generic::<PackedI1>` | `matmul_int1<BITS=1>` | `BITS=1` |

### 4.2 CUDA æ¨¡æ¿å®šä¹‰ (å‚è€ƒ)

```cpp
// ç»Ÿä¸€çš„é‡åŒ–çŸ©é˜µä¹˜æ¨¡æ¿
template <int BITS>
__global__ void quantized_matmul_kernel(
    const float* __restrict__ input,
    const uint8_t* __restrict__ weight,
    const half* __restrict__ scales,
    float* __restrict__ output,
    int m, int n, int k
);

// ç¼–è¯‘æ—¶å®ä¾‹åŒ– (æ¯ä¸ª GPU æ¶æ„)
template void quantized_matmul_kernel<1>(...);  // Int1
template void quantized_matmul_kernel<2>(...);  // Int2
template void quantized_matmul_kernel<4>(...);  // Int4
template void quantized_matmul_kernel<8>(...);  // Int8
```

### 4.3 Rust â†’ CUDA FFI æ¡¥æ¥

```rust
// cuda_backend.rs
extern "C" {
    fn quantized_matmul_int1(...) -> i32;
    fn quantized_matmul_int2(...) -> i32;
    fn quantized_matmul_int4(...) -> i32;
    fn quantized_matmul_int8(...) -> i32;
}

impl QuantizedMatMul<PackedI1> for CudaBackend {
    fn matmul(...) -> Result<()> {
        unsafe {
            quantized_matmul_int1(
                input.as_ptr(),
                weight.as_ptr(),
                scales.as_ptr(),
                output.as_mut_ptr(),
                m, n, k,
            );
        }
        Ok(())
    }
}
```

---

## 5. é›†æˆè®¡åˆ’

### 5.1 é˜¶æ®µ 1: Trait å®šä¹‰ (REQ-QUANT-004.1)

| æ–‡ä»¶ | ä¿®æ”¹ | çŠ¶æ€ |
|------|------|------|
| `src/cpu_kernels/traits.rs` | æ–°å¢ `DTypeTrait`, `QuantizedMatMul` | ğŸ”µ å¾…å®ç° |
| `src/cpu_kernels/mod.rs` | é‡æ–°å¯¼å‡º traits | ğŸ”µ å¾…å®ç° |

### 5.2 é˜¶æ®µ 2: Trait å®ç° (REQ-QUANT-004.2)

| æ–‡ä»¶ | ä¿®æ”¹ | çŠ¶æ€ |
|------|------|------|
| `src/cpu_kernels/f32_impl.rs` | `QuantizedMatMul<F32>` for `CpuBackend` | ğŸ”µ å¾…å®ç° |
| `src/cpu_kernels/i8_impl.rs` | `QuantizedMatMul<I8>` for `CpuBackend` | ğŸ”µ å¾…å®ç° |
| `src/cpu_kernels/i4_impl.rs` | `QuantizedMatMul<PackedI4>` for `CpuBackend` | ğŸ”µ å¾…å®ç° |
| `src/cpu_kernels/i2_impl.rs` | `QuantizedMatMul<PackedI2>` for `CpuBackend` | ğŸ”µ å¾…å®ç° |
| `src/cpu_kernels/i1_impl.rs` | `QuantizedMatMul<PackedI1>` for `CpuBackend` | ğŸ”µ å¾…å®ç° |

### 5.3 é˜¶æ®µ 3: QKV ç»Ÿä¸€ API (REQ-QUANT-004.3)

| æ–‡ä»¶ | ä¿®æ”¹ | çŠ¶æ€ |
|------|------|------|
| `src/cpu_kernels/qkv_generic.rs` | æ–°å¢ `qkv_projection_rope_generic` | ğŸ”µ å¾…å®ç° |
| `src/cpu_backend.rs` | æ›¿æ¢ `fused_qkv_rope` ä¸ºæ³›å‹ç‰ˆæœ¬ | ğŸ”µ å¾…å®ç° |

### 5.4 é˜¶æ®µ 4: CUDA ç«¯é›†æˆ (REQ-QUANT-004.4)

| æ–‡ä»¶ | ä¿®æ”¹ | çŠ¶æ€ |
|------|------|------|
| `src/cuda_kernels/quantized.cu` | å®ç° `template<int BITS>` å†…æ ¸ | ğŸ”µ å¾…å®ç° |
| `src/cuda_kernels/kernels/` | æ·»åŠ å„æ¶æ„çš„ `.cubin` | ğŸ”µ å¾…å®ç° |
| `src/cuda_backend.rs` | å®ç° `QuantizedMatMul<T>` for `CudaBackend` | ğŸ”µ å¾…å®ç° |

---

## 6. æ€§èƒ½çº¦æŸ

### 6.1 ç¼–è¯‘æ—¶ä¿è¯

| çº¦æŸ | éªŒè¯æ–¹æ³• |
|------|----------|
| **é›¶è¿è¡Œæ—¶å¼€é”€** | `cargo asm` éªŒè¯ç”Ÿæˆçš„æ±‡ç¼–ç­‰åŒäºæ‰‹å†™ç‰ˆæœ¬ |
| **å®Œå…¨å†…è”** | `#[inline(always)]` ç¡®ä¿å•æ€åŒ–ä»£ç å†…è” |
| **æ— åŠ¨æ€åˆ†å‘** | ç¦æ­¢ `dyn Trait`ï¼Œä»…ä½¿ç”¨æ³›å‹ |

### 6.2 SIMD ä¼˜åŒ–è¦æ±‚

| åç«¯ | SIMD æŒ‡ä»¤ | å®ç°è¦æ±‚ |
|------|-----------|----------|
| **x86_64 AVX2** | `_mm256_fma_ps` | 8Ã—f32 å¹¶è¡Œ |
| **x86_64 AVX-512** | `_mm512_fma_ps` | 16Ã—f32 å¹¶è¡Œ |
| **AArch64 NEON** | `vfmaq_f32` | 4Ã—f32 å¹¶è¡Œ |
| **é‡åŒ–åé‡åŒ–** | æ‰¹é‡è§£åŒ…åˆ° F32 å¯„å­˜å™¨ | é¿å…æ ‡é‡å¾ªç¯ |

---

## 7. éªŒæ”¶æ ‡å‡†

### 7.1 åŠŸèƒ½æ­£ç¡®æ€§

- [ ] æ‰€æœ‰é‡åŒ–ç±»å‹çš„ `matmul` è¾“å‡ºä¸ f32 å‚è€ƒè¯¯å·® < 0.1%
- [ ] QKV æŠ•å½±è¾“å‡ºä¸ HuggingFace å‚è€ƒåŒ¹é… (æµ‹è¯•: `test_k_values_real_weights.rs`)
- [ ] RoPE åº”ç”¨æ­£ç¡® (position 0 ä¸å˜ï¼Œposition > 0 æ—‹è½¬)

### 7.2 æ€§èƒ½éªŒè¯

- [ ] æ³›å‹ç‰ˆæœ¬æ€§èƒ½ â‰¥ æ‰‹å†™ç‰¹åŒ–ç‰ˆæœ¬ (åŸºå‡†æµ‹è¯•)
- [ ] åˆ†ç¦»æƒé‡è·¯å¾„ (3Ã—å°çŸ©é˜µ) æ€§èƒ½ > èåˆæƒé‡è·¯å¾„
- [ ] Int4/Int2/Int1 å†…å­˜å ç”¨ < F32 çš„ 25%

### 7.3 ç¼–è¯‘éªŒè¯

- [ ] `cargo check` é€šè¿‡ (æ— ç±»å‹é”™è¯¯)
- [ ] `cargo asm` ç¡®è®¤å®Œå…¨å•æ€åŒ– (æ— è™šè°ƒç”¨)
- [ ] å„ä¸ªé‡åŒ–ç±»å‹ç”Ÿæˆç‹¬ç«‹æ±‡ç¼–

---

## 8. å‚è€ƒæ–‡æ¡£

- **SPEC/02-ARCHITECTURE.md**: L3 GPU-Pure æ¶æ„å®šä¹‰
- **CLAUDE.md**: ARCH-QUANT-TEMPLATE çº¦æŸ
- **tests/test_k_values_real_weights.rs**: QKV æ­£ç¡®æ€§éªŒè¯
