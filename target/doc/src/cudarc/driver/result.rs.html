<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `/home/putao/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/cudarc-0.12.1/src/driver/result.rs`."><title>result.rs - source</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2"href="../../../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../../../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../../../static.files/rustdoc-e56847b5.css"><meta name="rustdoc-vars" data-root-path="../../../" data-static-root-path="../../../static.files/" data-current-crate="cudarc" data-themes="" data-resource-suffix="" data-rustdoc-version="1.91.1 (ed61e7d7e 2025-11-07)" data-channel="1.91.1" data-search-js="search-e256b49e.js" data-stringdex-js="stringdex-c3e638e9.js" data-settings-js="settings-c38705f0.js" ><script src="../../../static.files/storage-e2aeef58.js"></script><script defer src="../../../static.files/src-script-813739b1.js"></script><script defer src="../../../src-files.js"></script><script defer src="../../../static.files/main-6dc2a7f3.js"></script><noscript><link rel="stylesheet" href="../../../static.files/noscript-263c88ec.css"></noscript><link rel="alternate icon" type="image/png" href="../../../static.files/favicon-32x32-eab170b8.png"><link rel="icon" type="image/svg+xml" href="../../../static.files/favicon-044be391.svg"></head><body class="rustdoc src"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><div class="src-sidebar-title"><h2>Files</h2></div></nav><div class="sidebar-resizer" title="Drag to resize sidebar"></div><main><section id="main-content" class="content"><div class="main-heading"><h1><div class="sub-heading">cudarc/driver/</div>result.rs</h1><rustdoc-toolbar></rustdoc-toolbar></div><div class="example-wrap digits-4"><pre class="rust"><code><a href=#1 id=1 data-nosnippet>1</a><span class="doccomment">//! A thin wrapper around [sys].
<a href=#2 id=2 data-nosnippet>2</a>//!
<a href=#3 id=3 data-nosnippet>3</a>//! While all the functions here will return [Result], they are
<a href=#4 id=4 data-nosnippet>4</a>//! mostly all still unsafe because order of operations
<a href=#5 id=5 data-nosnippet>5</a>//! really matters.
<a href=#6 id=6 data-nosnippet>6</a>//!
<a href=#7 id=7 data-nosnippet>7</a>//! This also only exposes the `*_async` version of functions
<a href=#8 id=8 data-nosnippet>8</a>//! because mixing the two is confusing and even more unsafe.
<a href=#9 id=9 data-nosnippet>9</a>//!
<a href=#10 id=10 data-nosnippet>10</a>//! This module also groups functions into sub-modules
<a href=#11 id=11 data-nosnippet>11</a>//! to make naming easier. For example [sys::cuStreamCreate()]
<a href=#12 id=12 data-nosnippet>12</a>//! turns into [stream::create()], where [stream] is a module.
<a href=#13 id=13 data-nosnippet>13</a>
<a href=#14 id=14 data-nosnippet>14</a></span><span class="kw">use </span><span class="kw">super</span>::sys::{<span class="self">self</span>, lib};
<a href=#15 id=15 data-nosnippet>15</a><span class="kw">use </span>core::ffi::{c_uchar, c_uint, c_void, CStr};
<a href=#16 id=16 data-nosnippet>16</a><span class="kw">use </span>std::mem::MaybeUninit;
<a href=#17 id=17 data-nosnippet>17</a>
<a href=#18 id=18 data-nosnippet>18</a><span class="doccomment">/// Wrapper around [sys::CUresult]. See
<a href=#19 id=19 data-nosnippet>19</a>/// nvidia's [CUresult docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__TYPES.html#group__CUDA__TYPES_1gc6c391505e117393cc2558fff6bfc2e9)
<a href=#20 id=20 data-nosnippet>20</a></span><span class="attr">#[derive(Clone, Copy, PartialEq, Eq)]
<a href=#21 id=21 data-nosnippet>21</a></span><span class="kw">pub struct </span>DriverError(<span class="kw">pub </span>sys::CUresult);
<a href=#22 id=22 data-nosnippet>22</a>
<a href=#23 id=23 data-nosnippet>23</a><span class="kw">impl </span>sys::CUresult {
<a href=#24 id=24 data-nosnippet>24</a>    <span class="attr">#[inline]
<a href=#25 id=25 data-nosnippet>25</a>    </span><span class="kw">pub fn </span>result(<span class="self">self</span>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#26 id=26 data-nosnippet>26</a>        <span class="kw">match </span><span class="self">self </span>{
<a href=#27 id=27 data-nosnippet>27</a>            sys::CUresult::CUDA_SUCCESS =&gt; <span class="prelude-val">Ok</span>(()),
<a href=#28 id=28 data-nosnippet>28</a>            <span class="kw">_ </span>=&gt; <span class="prelude-val">Err</span>(DriverError(<span class="self">self</span>)),
<a href=#29 id=29 data-nosnippet>29</a>        }
<a href=#30 id=30 data-nosnippet>30</a>    }
<a href=#31 id=31 data-nosnippet>31</a>}
<a href=#32 id=32 data-nosnippet>32</a>
<a href=#33 id=33 data-nosnippet>33</a><span class="kw">impl </span>DriverError {
<a href=#34 id=34 data-nosnippet>34</a>    <span class="doccomment">/// Gets the name for this error.
<a href=#35 id=35 data-nosnippet>35</a>    ///
<a href=#36 id=36 data-nosnippet>36</a>    /// See [cuGetErrorName() docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__ERROR.html#group__CUDA__ERROR_1g2c4ac087113652bb3d1f95bf2513c468)
<a href=#37 id=37 data-nosnippet>37</a>    </span><span class="kw">pub fn </span>error_name(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="prelude-ty">Result</span>&lt;<span class="kw-2">&amp;</span>CStr, DriverError&gt; {
<a href=#38 id=38 data-nosnippet>38</a>        <span class="kw">let </span><span class="kw-2">mut </span>err_str = MaybeUninit::uninit();
<a href=#39 id=39 data-nosnippet>39</a>        <span class="kw">unsafe </span>{
<a href=#40 id=40 data-nosnippet>40</a>            lib()
<a href=#41 id=41 data-nosnippet>41</a>                .cuGetErrorName(<span class="self">self</span>.<span class="number">0</span>, err_str.as_mut_ptr())
<a href=#42 id=42 data-nosnippet>42</a>                .result()<span class="question-mark">?</span>;
<a href=#43 id=43 data-nosnippet>43</a>            <span class="prelude-val">Ok</span>(CStr::from_ptr(err_str.assume_init()))
<a href=#44 id=44 data-nosnippet>44</a>        }
<a href=#45 id=45 data-nosnippet>45</a>    }
<a href=#46 id=46 data-nosnippet>46</a>
<a href=#47 id=47 data-nosnippet>47</a>    <span class="doccomment">/// Gets the error string for this error.
<a href=#48 id=48 data-nosnippet>48</a>    ///
<a href=#49 id=49 data-nosnippet>49</a>    /// See [cuGetErrorString() docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__ERROR.html#group__CUDA__ERROR_1g72758fcaf05b5c7fac5c25ead9445ada)
<a href=#50 id=50 data-nosnippet>50</a>    </span><span class="kw">pub fn </span>error_string(<span class="kw-2">&amp;</span><span class="self">self</span>) -&gt; <span class="prelude-ty">Result</span>&lt;<span class="kw-2">&amp;</span>CStr, DriverError&gt; {
<a href=#51 id=51 data-nosnippet>51</a>        <span class="kw">let </span><span class="kw-2">mut </span>err_str = MaybeUninit::uninit();
<a href=#52 id=52 data-nosnippet>52</a>        <span class="kw">unsafe </span>{
<a href=#53 id=53 data-nosnippet>53</a>            lib()
<a href=#54 id=54 data-nosnippet>54</a>                .cuGetErrorString(<span class="self">self</span>.<span class="number">0</span>, err_str.as_mut_ptr())
<a href=#55 id=55 data-nosnippet>55</a>                .result()<span class="question-mark">?</span>;
<a href=#56 id=56 data-nosnippet>56</a>            <span class="prelude-val">Ok</span>(CStr::from_ptr(err_str.assume_init()))
<a href=#57 id=57 data-nosnippet>57</a>        }
<a href=#58 id=58 data-nosnippet>58</a>    }
<a href=#59 id=59 data-nosnippet>59</a>}
<a href=#60 id=60 data-nosnippet>60</a>
<a href=#61 id=61 data-nosnippet>61</a><span class="kw">impl </span>std::fmt::Debug <span class="kw">for </span>DriverError {
<a href=#62 id=62 data-nosnippet>62</a>    <span class="kw">fn </span>fmt(<span class="kw-2">&amp;</span><span class="self">self</span>, f: <span class="kw-2">&amp;mut </span>std::fmt::Formatter&lt;<span class="lifetime">'_</span>&gt;) -&gt; std::fmt::Result {
<a href=#63 id=63 data-nosnippet>63</a>        <span class="kw">match </span><span class="self">self</span>.error_string() {
<a href=#64 id=64 data-nosnippet>64</a>            <span class="prelude-val">Ok</span>(err_str) =&gt; f
<a href=#65 id=65 data-nosnippet>65</a>                .debug_tuple(<span class="string">"DriverError"</span>)
<a href=#66 id=66 data-nosnippet>66</a>                .field(<span class="kw-2">&amp;</span><span class="self">self</span>.<span class="number">0</span>)
<a href=#67 id=67 data-nosnippet>67</a>                .field(<span class="kw-2">&amp;</span>err_str)
<a href=#68 id=68 data-nosnippet>68</a>                .finish(),
<a href=#69 id=69 data-nosnippet>69</a>            <span class="prelude-val">Err</span>(<span class="kw">_</span>) =&gt; f
<a href=#70 id=70 data-nosnippet>70</a>                .debug_tuple(<span class="string">"DriverError"</span>)
<a href=#71 id=71 data-nosnippet>71</a>                .field(<span class="kw-2">&amp;</span><span class="self">self</span>.<span class="number">0</span>)
<a href=#72 id=72 data-nosnippet>72</a>                .field(<span class="kw-2">&amp;</span><span class="string">"&lt;Failure when calling cuGetErrorString()&gt;"</span>)
<a href=#73 id=73 data-nosnippet>73</a>                .finish(),
<a href=#74 id=74 data-nosnippet>74</a>        }
<a href=#75 id=75 data-nosnippet>75</a>    }
<a href=#76 id=76 data-nosnippet>76</a>}
<a href=#77 id=77 data-nosnippet>77</a>
<a href=#78 id=78 data-nosnippet>78</a><span class="attr">#[cfg(feature = <span class="string">"std"</span>)]
<a href=#79 id=79 data-nosnippet>79</a></span><span class="kw">impl </span>std::fmt::Display <span class="kw">for </span>DriverError {
<a href=#80 id=80 data-nosnippet>80</a>    <span class="kw">fn </span>fmt(<span class="kw-2">&amp;</span><span class="self">self</span>, f: <span class="kw-2">&amp;mut </span>std::fmt::Formatter&lt;<span class="lifetime">'_</span>&gt;) -&gt; std::fmt::Result {
<a href=#81 id=81 data-nosnippet>81</a>        <span class="macro">write!</span>(f, <span class="string">"{self:?}"</span>)
<a href=#82 id=82 data-nosnippet>82</a>    }
<a href=#83 id=83 data-nosnippet>83</a>}
<a href=#84 id=84 data-nosnippet>84</a>
<a href=#85 id=85 data-nosnippet>85</a><span class="attr">#[cfg(feature = <span class="string">"std"</span>)]
<a href=#86 id=86 data-nosnippet>86</a></span><span class="kw">impl </span>std::error::Error <span class="kw">for </span>DriverError {}
<a href=#87 id=87 data-nosnippet>87</a>
<a href=#88 id=88 data-nosnippet>88</a><span class="doccomment">/// Initializes the CUDA driver API.
<a href=#89 id=89 data-nosnippet>89</a>/// **MUST BE CALLED BEFORE ANYTHING ELSE**
<a href=#90 id=90 data-nosnippet>90</a>///
<a href=#91 id=91 data-nosnippet>91</a>/// See [cuInit() docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__INITIALIZE.html#group__CUDA__INITIALIZE_1g0a2f1517e1bd8502c7194c3a8c134bc3)
<a href=#92 id=92 data-nosnippet>92</a></span><span class="kw">pub fn </span>init() -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#93 id=93 data-nosnippet>93</a>    <span class="kw">unsafe </span>{ lib().cuInit(<span class="number">0</span>).result() }
<a href=#94 id=94 data-nosnippet>94</a>}
<a href=#95 id=95 data-nosnippet>95</a>
<a href=#96 id=96 data-nosnippet>96</a><span class="kw">pub mod </span>device {
<a href=#97 id=97 data-nosnippet>97</a>    <span class="doccomment">//! Device management functions (`cuDevice*`).
<a href=#98 id=98 data-nosnippet>98</a>    //!
<a href=#99 id=99 data-nosnippet>99</a>    //! See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE)
<a href=#100 id=100 data-nosnippet>100</a>
<a href=#101 id=101 data-nosnippet>101</a>    </span><span class="kw">use super</span>::{
<a href=#102 id=102 data-nosnippet>102</a>        sys::{<span class="self">self</span>, lib},
<a href=#103 id=103 data-nosnippet>103</a>        DriverError,
<a href=#104 id=104 data-nosnippet>104</a>    };
<a href=#105 id=105 data-nosnippet>105</a>    <span class="kw">use </span>std::{
<a href=#106 id=106 data-nosnippet>106</a>        ffi::{c_int, CStr},
<a href=#107 id=107 data-nosnippet>107</a>        mem::MaybeUninit,
<a href=#108 id=108 data-nosnippet>108</a>        string::String,
<a href=#109 id=109 data-nosnippet>109</a>    };
<a href=#110 id=110 data-nosnippet>110</a>
<a href=#111 id=111 data-nosnippet>111</a>    <span class="doccomment">/// Get a device for a specific ordinal.
<a href=#112 id=112 data-nosnippet>112</a>    /// See [cuDeviceGet() docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8bdd1cc7201304b01357b8034f6587cb).
<a href=#113 id=113 data-nosnippet>113</a>    </span><span class="kw">pub fn </span>get(ordinal: c_int) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUdevice, DriverError&gt; {
<a href=#114 id=114 data-nosnippet>114</a>        <span class="kw">let </span><span class="kw-2">mut </span>dev = MaybeUninit::uninit();
<a href=#115 id=115 data-nosnippet>115</a>        <span class="kw">unsafe </span>{
<a href=#116 id=116 data-nosnippet>116</a>            lib().cuDeviceGet(dev.as_mut_ptr(), ordinal).result()<span class="question-mark">?</span>;
<a href=#117 id=117 data-nosnippet>117</a>            <span class="prelude-val">Ok</span>(dev.assume_init())
<a href=#118 id=118 data-nosnippet>118</a>        }
<a href=#119 id=119 data-nosnippet>119</a>    }
<a href=#120 id=120 data-nosnippet>120</a>
<a href=#121 id=121 data-nosnippet>121</a>    <span class="doccomment">/// Gets the number of available devices.
<a href=#122 id=122 data-nosnippet>122</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g52b5ce05cb8c5fb6831b2c0ff2887c74)
<a href=#123 id=123 data-nosnippet>123</a>    </span><span class="kw">pub fn </span>get_count() -&gt; <span class="prelude-ty">Result</span>&lt;c_int, DriverError&gt; {
<a href=#124 id=124 data-nosnippet>124</a>        <span class="kw">let </span><span class="kw-2">mut </span>count = MaybeUninit::uninit();
<a href=#125 id=125 data-nosnippet>125</a>        <span class="kw">unsafe </span>{
<a href=#126 id=126 data-nosnippet>126</a>            lib().cuDeviceGetCount(count.as_mut_ptr()).result()<span class="question-mark">?</span>;
<a href=#127 id=127 data-nosnippet>127</a>            <span class="prelude-val">Ok</span>(count.assume_init())
<a href=#128 id=128 data-nosnippet>128</a>        }
<a href=#129 id=129 data-nosnippet>129</a>    }
<a href=#130 id=130 data-nosnippet>130</a>
<a href=#131 id=131 data-nosnippet>131</a>    <span class="doccomment">/// Returns the total amount of memory in bytes on the device.
<a href=#132 id=132 data-nosnippet>132</a>    ///
<a href=#133 id=133 data-nosnippet>133</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gc6a0d6551335a3780f9f3c967a0fde5d)
<a href=#134 id=134 data-nosnippet>134</a>    ///
<a href=#135 id=135 data-nosnippet>135</a>    /// # Safety
<a href=#136 id=136 data-nosnippet>136</a>    /// Must be a device returned from [get].
<a href=#137 id=137 data-nosnippet>137</a>    </span><span class="kw">pub unsafe fn </span>total_mem(dev: sys::CUdevice) -&gt; <span class="prelude-ty">Result</span>&lt;usize, DriverError&gt; {
<a href=#138 id=138 data-nosnippet>138</a>        <span class="kw">let </span><span class="kw-2">mut </span>bytes = MaybeUninit::uninit();
<a href=#139 id=139 data-nosnippet>139</a>        lib()
<a href=#140 id=140 data-nosnippet>140</a>            .cuDeviceTotalMem_v2(bytes.as_mut_ptr(), dev)
<a href=#141 id=141 data-nosnippet>141</a>            .result()<span class="question-mark">?</span>;
<a href=#142 id=142 data-nosnippet>142</a>        <span class="prelude-val">Ok</span>(bytes.assume_init())
<a href=#143 id=143 data-nosnippet>143</a>    }
<a href=#144 id=144 data-nosnippet>144</a>
<a href=#145 id=145 data-nosnippet>145</a>    <span class="doccomment">/// Get an attribute of a device.
<a href=#146 id=146 data-nosnippet>146</a>    ///
<a href=#147 id=147 data-nosnippet>147</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1g8c6e2c7b5c7c8b7e6f7f4c2b7f6d9c5d)
<a href=#148 id=148 data-nosnippet>148</a>    ///
<a href=#149 id=149 data-nosnippet>149</a>    /// # Safety
<a href=#150 id=150 data-nosnippet>150</a>    /// Must be a device returned from [get].
<a href=#151 id=151 data-nosnippet>151</a>    </span><span class="kw">pub unsafe fn </span>get_attribute(
<a href=#152 id=152 data-nosnippet>152</a>        dev: sys::CUdevice,
<a href=#153 id=153 data-nosnippet>153</a>        attrib: sys::CUdevice_attribute,
<a href=#154 id=154 data-nosnippet>154</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;i32, DriverError&gt; {
<a href=#155 id=155 data-nosnippet>155</a>        <span class="kw">let </span><span class="kw-2">mut </span>value = MaybeUninit::uninit();
<a href=#156 id=156 data-nosnippet>156</a>        lib()
<a href=#157 id=157 data-nosnippet>157</a>            .cuDeviceGetAttribute(value.as_mut_ptr(), attrib, dev)
<a href=#158 id=158 data-nosnippet>158</a>            .result()<span class="question-mark">?</span>;
<a href=#159 id=159 data-nosnippet>159</a>        <span class="prelude-val">Ok</span>(value.assume_init())
<a href=#160 id=160 data-nosnippet>160</a>    }
<a href=#161 id=161 data-nosnippet>161</a>
<a href=#162 id=162 data-nosnippet>162</a>    <span class="doccomment">/// Get name of the device.
<a href=#163 id=163 data-nosnippet>163</a>    ///
<a href=#164 id=164 data-nosnippet>164</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#group__CUDA__DEVICE_1gef75aa30df95446a845f2a7b9fffbb7f)
<a href=#165 id=165 data-nosnippet>165</a>    </span><span class="kw">pub fn </span>get_name(dev: sys::CUdevice) -&gt; <span class="prelude-ty">Result</span>&lt;String, DriverError&gt; {
<a href=#166 id=166 data-nosnippet>166</a>        <span class="kw">const </span>BUF_SIZE: usize = <span class="number">128</span>;
<a href=#167 id=167 data-nosnippet>167</a>        <span class="kw">let </span><span class="kw-2">mut </span>buf = [<span class="number">0u8</span>; BUF_SIZE];
<a href=#168 id=168 data-nosnippet>168</a>        <span class="kw">unsafe </span>{
<a href=#169 id=169 data-nosnippet>169</a>            lib()
<a href=#170 id=170 data-nosnippet>170</a>                .cuDeviceGetName(buf.as_mut_ptr() <span class="kw">as _</span>, BUF_SIZE <span class="kw">as _</span>, dev)
<a href=#171 id=171 data-nosnippet>171</a>                .result()<span class="question-mark">?</span>;
<a href=#172 id=172 data-nosnippet>172</a>        }
<a href=#173 id=173 data-nosnippet>173</a>        <span class="kw">let </span>name = CStr::from_bytes_until_nul(<span class="kw-2">&amp;</span>buf).expect(<span class="string">"No null byte was present"</span>);
<a href=#174 id=174 data-nosnippet>174</a>        <span class="prelude-val">Ok</span>(String::from_utf8_lossy(name.to_bytes()).into())
<a href=#175 id=175 data-nosnippet>175</a>    }
<a href=#176 id=176 data-nosnippet>176</a>}
<a href=#177 id=177 data-nosnippet>177</a>
<a href=#178 id=178 data-nosnippet>178</a><span class="kw">pub mod </span>function {
<a href=#179 id=179 data-nosnippet>179</a>    <span class="kw">use </span><span class="kw">super</span>::sys::{<span class="self">self</span>, lib, CUfunction_attribute_enum};
<a href=#180 id=180 data-nosnippet>180</a>
<a href=#181 id=181 data-nosnippet>181</a>    <span class="doccomment">/// Sets the specific attribute of a cuda function.
<a href=#182 id=182 data-nosnippet>182</a>    ///
<a href=#183 id=183 data-nosnippet>183</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__EXECUTION.html#group__CUDART__EXECUTION_1g317e77d2657abf915fd9ed03e75f3eb0)
<a href=#184 id=184 data-nosnippet>184</a>    ///
<a href=#185 id=185 data-nosnippet>185</a>    /// # Safety
<a href=#186 id=186 data-nosnippet>186</a>    /// Function must exist.
<a href=#187 id=187 data-nosnippet>187</a>    </span><span class="kw">pub unsafe fn </span>set_function_attribute(
<a href=#188 id=188 data-nosnippet>188</a>        f: sys::CUfunction,
<a href=#189 id=189 data-nosnippet>189</a>        attribute: CUfunction_attribute_enum,
<a href=#190 id=190 data-nosnippet>190</a>        value: i32,
<a href=#191 id=191 data-nosnippet>191</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;(), <span class="kw">super</span>::DriverError&gt; {
<a href=#192 id=192 data-nosnippet>192</a>        <span class="kw">unsafe </span>{
<a href=#193 id=193 data-nosnippet>193</a>            lib().cuFuncSetAttribute(f, attribute, value).result()<span class="question-mark">?</span>;
<a href=#194 id=194 data-nosnippet>194</a>        }
<a href=#195 id=195 data-nosnippet>195</a>
<a href=#196 id=196 data-nosnippet>196</a>        <span class="prelude-val">Ok</span>(())
<a href=#197 id=197 data-nosnippet>197</a>    }
<a href=#198 id=198 data-nosnippet>198</a>}
<a href=#199 id=199 data-nosnippet>199</a>
<a href=#200 id=200 data-nosnippet>200</a><span class="kw">pub mod </span>occupancy {
<a href=#201 id=201 data-nosnippet>201</a>
<a href=#202 id=202 data-nosnippet>202</a>    <span class="kw">use </span>core::{
<a href=#203 id=203 data-nosnippet>203</a>        ffi::{c_int, c_uint},
<a href=#204 id=204 data-nosnippet>204</a>        mem::MaybeUninit,
<a href=#205 id=205 data-nosnippet>205</a>    };
<a href=#206 id=206 data-nosnippet>206</a>
<a href=#207 id=207 data-nosnippet>207</a>    <span class="kw">use super</span>::{
<a href=#208 id=208 data-nosnippet>208</a>        sys::{<span class="self">self</span>, lib},
<a href=#209 id=209 data-nosnippet>209</a>        DriverError,
<a href=#210 id=210 data-nosnippet>210</a>    };
<a href=#211 id=211 data-nosnippet>211</a>
<a href=#212 id=212 data-nosnippet>212</a>    <span class="doccomment">/// Returns dynamic shared memory available per block when launching numBlocks blocks on SM.
<a href=#213 id=213 data-nosnippet>213</a>    ///
<a href=#214 id=214 data-nosnippet>214</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1gae02af6a9df9e1bbd51941af631bce69)
<a href=#215 id=215 data-nosnippet>215</a>    ///
<a href=#216 id=216 data-nosnippet>216</a>    /// # Safety
<a href=#217 id=217 data-nosnippet>217</a>    /// Function must exist.
<a href=#218 id=218 data-nosnippet>218</a>    </span><span class="kw">pub unsafe fn </span>available_dynamic_shared_mem_per_block(
<a href=#219 id=219 data-nosnippet>219</a>        f: sys::CUfunction,
<a href=#220 id=220 data-nosnippet>220</a>        num_blocks: c_int,
<a href=#221 id=221 data-nosnippet>221</a>        block_size: c_int,
<a href=#222 id=222 data-nosnippet>222</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;usize, DriverError&gt; {
<a href=#223 id=223 data-nosnippet>223</a>        <span class="kw">let </span><span class="kw-2">mut </span>dynamic_smem_size = MaybeUninit::uninit();
<a href=#224 id=224 data-nosnippet>224</a>        <span class="kw">unsafe </span>{
<a href=#225 id=225 data-nosnippet>225</a>            lib()
<a href=#226 id=226 data-nosnippet>226</a>                .cuOccupancyAvailableDynamicSMemPerBlock(
<a href=#227 id=227 data-nosnippet>227</a>                    dynamic_smem_size.as_mut_ptr(),
<a href=#228 id=228 data-nosnippet>228</a>                    f,
<a href=#229 id=229 data-nosnippet>229</a>                    num_blocks,
<a href=#230 id=230 data-nosnippet>230</a>                    block_size,
<a href=#231 id=231 data-nosnippet>231</a>                )
<a href=#232 id=232 data-nosnippet>232</a>                .result()<span class="question-mark">?</span>;
<a href=#233 id=233 data-nosnippet>233</a>        }
<a href=#234 id=234 data-nosnippet>234</a>        <span class="prelude-val">Ok</span>(dynamic_smem_size.assume_init())
<a href=#235 id=235 data-nosnippet>235</a>    }
<a href=#236 id=236 data-nosnippet>236</a>
<a href=#237 id=237 data-nosnippet>237</a>    <span class="doccomment">/// Returns occupancy of a function.
<a href=#238 id=238 data-nosnippet>238</a>    ///
<a href=#239 id=239 data-nosnippet>239</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1gcc6e1094d05cba2cee17fe33ddd04a98)
<a href=#240 id=240 data-nosnippet>240</a>    ///
<a href=#241 id=241 data-nosnippet>241</a>    /// # Safety
<a href=#242 id=242 data-nosnippet>242</a>    /// Function must exist.
<a href=#243 id=243 data-nosnippet>243</a>    </span><span class="kw">pub unsafe fn </span>max_active_block_per_multiprocessor(
<a href=#244 id=244 data-nosnippet>244</a>        f: sys::CUfunction,
<a href=#245 id=245 data-nosnippet>245</a>        block_size: c_int,
<a href=#246 id=246 data-nosnippet>246</a>        dynamic_smem_size: usize,
<a href=#247 id=247 data-nosnippet>247</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;i32, DriverError&gt; {
<a href=#248 id=248 data-nosnippet>248</a>        <span class="kw">let </span><span class="kw-2">mut </span>num_blocks = MaybeUninit::uninit();
<a href=#249 id=249 data-nosnippet>249</a>        <span class="kw">unsafe </span>{
<a href=#250 id=250 data-nosnippet>250</a>            lib()
<a href=#251 id=251 data-nosnippet>251</a>                .cuOccupancyMaxActiveBlocksPerMultiprocessor(
<a href=#252 id=252 data-nosnippet>252</a>                    num_blocks.as_mut_ptr(),
<a href=#253 id=253 data-nosnippet>253</a>                    f,
<a href=#254 id=254 data-nosnippet>254</a>                    block_size,
<a href=#255 id=255 data-nosnippet>255</a>                    dynamic_smem_size,
<a href=#256 id=256 data-nosnippet>256</a>                )
<a href=#257 id=257 data-nosnippet>257</a>                .result()<span class="question-mark">?</span>;
<a href=#258 id=258 data-nosnippet>258</a>        }
<a href=#259 id=259 data-nosnippet>259</a>        <span class="prelude-val">Ok</span>(num_blocks.assume_init())
<a href=#260 id=260 data-nosnippet>260</a>    }
<a href=#261 id=261 data-nosnippet>261</a>
<a href=#262 id=262 data-nosnippet>262</a>    <span class="doccomment">/// Returns occupancy of a function.
<a href=#263 id=263 data-nosnippet>263</a>    ///
<a href=#264 id=264 data-nosnippet>264</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1g8f1da4d4983e5c3025447665423ae2c2)
<a href=#265 id=265 data-nosnippet>265</a>    ///
<a href=#266 id=266 data-nosnippet>266</a>    /// # Safety
<a href=#267 id=267 data-nosnippet>267</a>    /// Function must exist. No invalid flags.
<a href=#268 id=268 data-nosnippet>268</a>    </span><span class="kw">pub unsafe fn </span>max_active_block_per_multiprocessor_with_flags(
<a href=#269 id=269 data-nosnippet>269</a>        f: sys::CUfunction,
<a href=#270 id=270 data-nosnippet>270</a>        block_size: c_int,
<a href=#271 id=271 data-nosnippet>271</a>        dynamic_smem_size: usize,
<a href=#272 id=272 data-nosnippet>272</a>        flags: c_uint,
<a href=#273 id=273 data-nosnippet>273</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;i32, DriverError&gt; {
<a href=#274 id=274 data-nosnippet>274</a>        <span class="kw">let </span><span class="kw-2">mut </span>num_blocks = MaybeUninit::uninit();
<a href=#275 id=275 data-nosnippet>275</a>        <span class="kw">unsafe </span>{
<a href=#276 id=276 data-nosnippet>276</a>            lib()
<a href=#277 id=277 data-nosnippet>277</a>                .cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
<a href=#278 id=278 data-nosnippet>278</a>                    num_blocks.as_mut_ptr(),
<a href=#279 id=279 data-nosnippet>279</a>                    f,
<a href=#280 id=280 data-nosnippet>280</a>                    block_size,
<a href=#281 id=281 data-nosnippet>281</a>                    dynamic_smem_size,
<a href=#282 id=282 data-nosnippet>282</a>                    flags,
<a href=#283 id=283 data-nosnippet>283</a>                )
<a href=#284 id=284 data-nosnippet>284</a>                .result()<span class="question-mark">?</span>;
<a href=#285 id=285 data-nosnippet>285</a>        }
<a href=#286 id=286 data-nosnippet>286</a>        <span class="prelude-val">Ok</span>(num_blocks.assume_init())
<a href=#287 id=287 data-nosnippet>287</a>    }
<a href=#288 id=288 data-nosnippet>288</a>
<a href=#289 id=289 data-nosnippet>289</a>    <span class="doccomment">/// Suggest a launch configuration with reasonable occupancy.
<a href=#290 id=290 data-nosnippet>290</a>    ///
<a href=#291 id=291 data-nosnippet>291</a>    /// Returns (min_grid_size, block_size)
<a href=#292 id=292 data-nosnippet>292</a>    ///
<a href=#293 id=293 data-nosnippet>293</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1gf179c4ab78962a8468e41c3f57851f03)
<a href=#294 id=294 data-nosnippet>294</a>    ///
<a href=#295 id=295 data-nosnippet>295</a>    /// # Safety
<a href=#296 id=296 data-nosnippet>296</a>    /// Function must exist and the shared memory function must be correct.  No invalid flags.
<a href=#297 id=297 data-nosnippet>297</a>    </span><span class="kw">pub unsafe fn </span>max_potential_block_size(
<a href=#298 id=298 data-nosnippet>298</a>        f: sys::CUfunction,
<a href=#299 id=299 data-nosnippet>299</a>        block_size_to_dynamic_smem_size: sys::CUoccupancyB2DSize,
<a href=#300 id=300 data-nosnippet>300</a>        dynamic_smem_size: usize,
<a href=#301 id=301 data-nosnippet>301</a>        block_size_limit: c_int,
<a href=#302 id=302 data-nosnippet>302</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;(i32, i32), DriverError&gt; {
<a href=#303 id=303 data-nosnippet>303</a>        <span class="kw">let </span><span class="kw-2">mut </span>min_grid_size = MaybeUninit::uninit();
<a href=#304 id=304 data-nosnippet>304</a>        <span class="kw">let </span><span class="kw-2">mut </span>block_size = MaybeUninit::uninit();
<a href=#305 id=305 data-nosnippet>305</a>        <span class="kw">unsafe </span>{
<a href=#306 id=306 data-nosnippet>306</a>            lib()
<a href=#307 id=307 data-nosnippet>307</a>                .cuOccupancyMaxPotentialBlockSize(
<a href=#308 id=308 data-nosnippet>308</a>                    min_grid_size.as_mut_ptr(),
<a href=#309 id=309 data-nosnippet>309</a>                    block_size.as_mut_ptr(),
<a href=#310 id=310 data-nosnippet>310</a>                    f,
<a href=#311 id=311 data-nosnippet>311</a>                    block_size_to_dynamic_smem_size,
<a href=#312 id=312 data-nosnippet>312</a>                    dynamic_smem_size,
<a href=#313 id=313 data-nosnippet>313</a>                    block_size_limit,
<a href=#314 id=314 data-nosnippet>314</a>                )
<a href=#315 id=315 data-nosnippet>315</a>                .result()<span class="question-mark">?</span>;
<a href=#316 id=316 data-nosnippet>316</a>        }
<a href=#317 id=317 data-nosnippet>317</a>        <span class="prelude-val">Ok</span>((min_grid_size.assume_init(), block_size.assume_init()))
<a href=#318 id=318 data-nosnippet>318</a>    }
<a href=#319 id=319 data-nosnippet>319</a>
<a href=#320 id=320 data-nosnippet>320</a>    <span class="doccomment">/// Suggest a launch configuration with reasonable occupancy.
<a href=#321 id=321 data-nosnippet>321</a>    ///
<a href=#322 id=322 data-nosnippet>322</a>    /// Returns (min_grid_size, block_size)
<a href=#323 id=323 data-nosnippet>323</a>    ///
<a href=#324 id=324 data-nosnippet>324</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__OCCUPANCY.html#group__CUDA__OCCUPANCY_1g04c0bb65630f82d9b99a5ca0203ee5aa)
<a href=#325 id=325 data-nosnippet>325</a>    ///
<a href=#326 id=326 data-nosnippet>326</a>    /// # Safety
<a href=#327 id=327 data-nosnippet>327</a>    /// Function must exist and the shared memory function must be correct.  No invalid flags.
<a href=#328 id=328 data-nosnippet>328</a>    </span><span class="kw">pub unsafe fn </span>max_potential_block_size_with_flags(
<a href=#329 id=329 data-nosnippet>329</a>        f: sys::CUfunction,
<a href=#330 id=330 data-nosnippet>330</a>        block_size_to_dynamic_smem_size: sys::CUoccupancyB2DSize,
<a href=#331 id=331 data-nosnippet>331</a>        dynamic_smem_size: usize,
<a href=#332 id=332 data-nosnippet>332</a>        block_size_limit: c_int,
<a href=#333 id=333 data-nosnippet>333</a>        flags: c_uint,
<a href=#334 id=334 data-nosnippet>334</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;(i32, i32), DriverError&gt; {
<a href=#335 id=335 data-nosnippet>335</a>        <span class="kw">let </span><span class="kw-2">mut </span>min_grid_size = MaybeUninit::uninit();
<a href=#336 id=336 data-nosnippet>336</a>        <span class="kw">let </span><span class="kw-2">mut </span>block_size = MaybeUninit::uninit();
<a href=#337 id=337 data-nosnippet>337</a>        <span class="kw">unsafe </span>{
<a href=#338 id=338 data-nosnippet>338</a>            lib()
<a href=#339 id=339 data-nosnippet>339</a>                .cuOccupancyMaxPotentialBlockSizeWithFlags(
<a href=#340 id=340 data-nosnippet>340</a>                    min_grid_size.as_mut_ptr(),
<a href=#341 id=341 data-nosnippet>341</a>                    block_size.as_mut_ptr(),
<a href=#342 id=342 data-nosnippet>342</a>                    f,
<a href=#343 id=343 data-nosnippet>343</a>                    block_size_to_dynamic_smem_size,
<a href=#344 id=344 data-nosnippet>344</a>                    dynamic_smem_size,
<a href=#345 id=345 data-nosnippet>345</a>                    block_size_limit,
<a href=#346 id=346 data-nosnippet>346</a>                    flags,
<a href=#347 id=347 data-nosnippet>347</a>                )
<a href=#348 id=348 data-nosnippet>348</a>                .result()<span class="question-mark">?</span>;
<a href=#349 id=349 data-nosnippet>349</a>        }
<a href=#350 id=350 data-nosnippet>350</a>        <span class="prelude-val">Ok</span>((min_grid_size.assume_init(), block_size.assume_init()))
<a href=#351 id=351 data-nosnippet>351</a>    }
<a href=#352 id=352 data-nosnippet>352</a>}
<a href=#353 id=353 data-nosnippet>353</a>
<a href=#354 id=354 data-nosnippet>354</a><span class="kw">pub mod </span>primary_ctx {
<a href=#355 id=355 data-nosnippet>355</a>    <span class="doccomment">//! Primary context management functions (`cuDevicePrimaryCtx*`).
<a href=#356 id=356 data-nosnippet>356</a>    //!
<a href=#357 id=357 data-nosnippet>357</a>    //! See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PRIMARY__CTX.html#group__CUDA__PRIMARY__CTX)
<a href=#358 id=358 data-nosnippet>358</a>
<a href=#359 id=359 data-nosnippet>359</a>    </span><span class="kw">use super</span>::{
<a href=#360 id=360 data-nosnippet>360</a>        sys::{<span class="self">self</span>, lib},
<a href=#361 id=361 data-nosnippet>361</a>        DriverError,
<a href=#362 id=362 data-nosnippet>362</a>    };
<a href=#363 id=363 data-nosnippet>363</a>    <span class="kw">use </span>std::mem::MaybeUninit;
<a href=#364 id=364 data-nosnippet>364</a>
<a href=#365 id=365 data-nosnippet>365</a>    <span class="doccomment">/// Creates a primary context on the device and pushes it onto the primary context stack.
<a href=#366 id=366 data-nosnippet>366</a>    /// Call [release] to free it.
<a href=#367 id=367 data-nosnippet>367</a>    ///
<a href=#368 id=368 data-nosnippet>368</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PRIMARY__CTX.html#group__CUDA__PRIMARY__CTX_1g9051f2d5c31501997a6cb0530290a300)
<a href=#369 id=369 data-nosnippet>369</a>    ///
<a href=#370 id=370 data-nosnippet>370</a>    /// # Safety
<a href=#371 id=371 data-nosnippet>371</a>    ///
<a href=#372 id=372 data-nosnippet>372</a>    /// This is only safe with a device that was returned from [super::device::get].
<a href=#373 id=373 data-nosnippet>373</a>    </span><span class="kw">pub unsafe fn </span>retain(dev: sys::CUdevice) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUcontext, DriverError&gt; {
<a href=#374 id=374 data-nosnippet>374</a>        <span class="kw">let </span><span class="kw-2">mut </span>ctx = MaybeUninit::uninit();
<a href=#375 id=375 data-nosnippet>375</a>        lib()
<a href=#376 id=376 data-nosnippet>376</a>            .cuDevicePrimaryCtxRetain(ctx.as_mut_ptr(), dev)
<a href=#377 id=377 data-nosnippet>377</a>            .result()<span class="question-mark">?</span>;
<a href=#378 id=378 data-nosnippet>378</a>        <span class="prelude-val">Ok</span>(ctx.assume_init())
<a href=#379 id=379 data-nosnippet>379</a>    }
<a href=#380 id=380 data-nosnippet>380</a>
<a href=#381 id=381 data-nosnippet>381</a>    <span class="doccomment">/// Release a reference to the current primary context.
<a href=#382 id=382 data-nosnippet>382</a>    ///
<a href=#383 id=383 data-nosnippet>383</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__PRIMARY__CTX.html#group__CUDA__PRIMARY__CTX_1gf2a8bc16f8df0c88031f6a1ba3d6e8ad).
<a href=#384 id=384 data-nosnippet>384</a>    ///
<a href=#385 id=385 data-nosnippet>385</a>    /// # Safety
<a href=#386 id=386 data-nosnippet>386</a>    ///
<a href=#387 id=387 data-nosnippet>387</a>    /// This is only safe with a device that was returned from [super::device::get].
<a href=#388 id=388 data-nosnippet>388</a>    </span><span class="kw">pub unsafe fn </span>release(dev: sys::CUdevice) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#389 id=389 data-nosnippet>389</a>        lib().cuDevicePrimaryCtxRelease_v2(dev).result()
<a href=#390 id=390 data-nosnippet>390</a>    }
<a href=#391 id=391 data-nosnippet>391</a>}
<a href=#392 id=392 data-nosnippet>392</a>
<a href=#393 id=393 data-nosnippet>393</a><span class="kw">pub mod </span>ctx {
<a href=#394 id=394 data-nosnippet>394</a>    <span class="doccomment">//! Context management functions (`cuCtx*`).
<a href=#395 id=395 data-nosnippet>395</a>    //!
<a href=#396 id=396 data-nosnippet>396</a>    //! See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX)
<a href=#397 id=397 data-nosnippet>397</a>
<a href=#398 id=398 data-nosnippet>398</a>    </span><span class="kw">use super</span>::{
<a href=#399 id=399 data-nosnippet>399</a>        sys::{<span class="self">self</span>, lib},
<a href=#400 id=400 data-nosnippet>400</a>        DriverError,
<a href=#401 id=401 data-nosnippet>401</a>    };
<a href=#402 id=402 data-nosnippet>402</a>    <span class="kw">use </span>std::mem::MaybeUninit;
<a href=#403 id=403 data-nosnippet>403</a>
<a href=#404 id=404 data-nosnippet>404</a>    <span class="doccomment">/// Binds the specified CUDA context to the calling CPU thread.
<a href=#405 id=405 data-nosnippet>405</a>    ///
<a href=#406 id=406 data-nosnippet>406</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1gbe562ee6258b4fcc272ca6478ca2a2f7)
<a href=#407 id=407 data-nosnippet>407</a>    ///
<a href=#408 id=408 data-nosnippet>408</a>    /// # Safety
<a href=#409 id=409 data-nosnippet>409</a>    ///
<a href=#410 id=410 data-nosnippet>410</a>    /// This has weird behavior depending on the value of `ctx`. See cuda docs for more info.
<a href=#411 id=411 data-nosnippet>411</a>    /// In general this should only be called with an already initialized context,
<a href=#412 id=412 data-nosnippet>412</a>    /// and one that wasn't already freed.
<a href=#413 id=413 data-nosnippet>413</a>    </span><span class="kw">pub unsafe fn </span>set_current(ctx: sys::CUcontext) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#414 id=414 data-nosnippet>414</a>        lib().cuCtxSetCurrent(ctx).result()
<a href=#415 id=415 data-nosnippet>415</a>    }
<a href=#416 id=416 data-nosnippet>416</a>
<a href=#417 id=417 data-nosnippet>417</a>    <span class="doccomment">/// Returns the CUDA context bound to the calling CPU thread if there is one.
<a href=#418 id=418 data-nosnippet>418</a>    ///
<a href=#419 id=419 data-nosnippet>419</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html#group__CUDA__CTX_1g8f13165846b73750693640fb3e8380d0)
<a href=#420 id=420 data-nosnippet>420</a>    </span><span class="kw">pub fn </span>get_current() -&gt; <span class="prelude-ty">Result</span>&lt;<span class="prelude-ty">Option</span>&lt;sys::CUcontext&gt;, DriverError&gt; {
<a href=#421 id=421 data-nosnippet>421</a>        <span class="kw">let </span><span class="kw-2">mut </span>ctx = MaybeUninit::uninit();
<a href=#422 id=422 data-nosnippet>422</a>        <span class="kw">unsafe </span>{
<a href=#423 id=423 data-nosnippet>423</a>            lib().cuCtxGetCurrent(ctx.as_mut_ptr()).result()<span class="question-mark">?</span>;
<a href=#424 id=424 data-nosnippet>424</a>            <span class="kw">let </span>ctx: sys::CUcontext = ctx.assume_init();
<a href=#425 id=425 data-nosnippet>425</a>            <span class="kw">if </span>ctx.is_null() {
<a href=#426 id=426 data-nosnippet>426</a>                <span class="prelude-val">Ok</span>(<span class="prelude-val">None</span>)
<a href=#427 id=427 data-nosnippet>427</a>            } <span class="kw">else </span>{
<a href=#428 id=428 data-nosnippet>428</a>                <span class="prelude-val">Ok</span>(<span class="prelude-val">Some</span>(ctx))
<a href=#429 id=429 data-nosnippet>429</a>            }
<a href=#430 id=430 data-nosnippet>430</a>        }
<a href=#431 id=431 data-nosnippet>431</a>    }
<a href=#432 id=432 data-nosnippet>432</a>}
<a href=#433 id=433 data-nosnippet>433</a>
<a href=#434 id=434 data-nosnippet>434</a><span class="kw">pub mod </span>stream {
<a href=#435 id=435 data-nosnippet>435</a>    <span class="doccomment">//! Stream management functions (`cuStream*`).
<a href=#436 id=436 data-nosnippet>436</a>    //!
<a href=#437 id=437 data-nosnippet>437</a>    //! See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__STREAM.html#group__CUDA__STREAM).
<a href=#438 id=438 data-nosnippet>438</a>
<a href=#439 id=439 data-nosnippet>439</a>    </span><span class="kw">use super</span>::{
<a href=#440 id=440 data-nosnippet>440</a>        sys::{<span class="self">self</span>, lib},
<a href=#441 id=441 data-nosnippet>441</a>        DriverError,
<a href=#442 id=442 data-nosnippet>442</a>    };
<a href=#443 id=443 data-nosnippet>443</a>    <span class="kw">use </span>std::mem::MaybeUninit;
<a href=#444 id=444 data-nosnippet>444</a>
<a href=#445 id=445 data-nosnippet>445</a>    <span class="doccomment">/// The kind of stream to initialize.
<a href=#446 id=446 data-nosnippet>446</a>    ///
<a href=#447 id=447 data-nosnippet>447</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__STREAM.html#group__CUDA__STREAM_1ga581f0c5833e21ded8b5a56594e243f4)
<a href=#448 id=448 data-nosnippet>448</a>    </span><span class="kw">pub enum </span>StreamKind {
<a href=#449 id=449 data-nosnippet>449</a>        <span class="doccomment">/// From cuda docs:
<a href=#450 id=450 data-nosnippet>450</a>        /// &gt; Default stream creation flag.
<a href=#451 id=451 data-nosnippet>451</a>        </span>Default,
<a href=#452 id=452 data-nosnippet>452</a>
<a href=#453 id=453 data-nosnippet>453</a>        <span class="doccomment">/// From cuda docs:
<a href=#454 id=454 data-nosnippet>454</a>        /// &gt; Specifies that work running in the created stream
<a href=#455 id=455 data-nosnippet>455</a>        /// &gt; may run concurrently with work in stream 0 (the NULL stream),
<a href=#456 id=456 data-nosnippet>456</a>        /// &gt; and that the created stream should perform no implicit
<a href=#457 id=457 data-nosnippet>457</a>        /// &gt; synchronization with stream 0.
<a href=#458 id=458 data-nosnippet>458</a>        </span>NonBlocking,
<a href=#459 id=459 data-nosnippet>459</a>    }
<a href=#460 id=460 data-nosnippet>460</a>
<a href=#461 id=461 data-nosnippet>461</a>    <span class="kw">impl </span>StreamKind {
<a href=#462 id=462 data-nosnippet>462</a>        <span class="kw">fn </span>flags(<span class="self">self</span>) -&gt; sys::CUstream_flags {
<a href=#463 id=463 data-nosnippet>463</a>            <span class="kw">match </span><span class="self">self </span>{
<a href=#464 id=464 data-nosnippet>464</a>                <span class="self">Self</span>::Default =&gt; sys::CUstream_flags::CU_STREAM_DEFAULT,
<a href=#465 id=465 data-nosnippet>465</a>                <span class="self">Self</span>::NonBlocking =&gt; sys::CUstream_flags::CU_STREAM_NON_BLOCKING,
<a href=#466 id=466 data-nosnippet>466</a>            }
<a href=#467 id=467 data-nosnippet>467</a>        }
<a href=#468 id=468 data-nosnippet>468</a>    }
<a href=#469 id=469 data-nosnippet>469</a>
<a href=#470 id=470 data-nosnippet>470</a>    <span class="doccomment">/// The null stream, which is just a null pointer. **Recommend not using this.**
<a href=#471 id=471 data-nosnippet>471</a>    ///
<a href=#472 id=472 data-nosnippet>472</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/stream-sync-behavior.html#stream-sync-behavior__default-stream)
<a href=#473 id=473 data-nosnippet>473</a>    </span><span class="kw">pub fn </span>null() -&gt; sys::CUstream {
<a href=#474 id=474 data-nosnippet>474</a>        std::ptr::null_mut()
<a href=#475 id=475 data-nosnippet>475</a>    }
<a href=#476 id=476 data-nosnippet>476</a>
<a href=#477 id=477 data-nosnippet>477</a>    <span class="doccomment">/// Creates a stream with the specified kind.
<a href=#478 id=478 data-nosnippet>478</a>    ///
<a href=#479 id=479 data-nosnippet>479</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__STREAM.html#group__CUDA__STREAM_1ga581f0c5833e21ded8b5a56594e243f4)
<a href=#480 id=480 data-nosnippet>480</a>    </span><span class="kw">pub fn </span>create(kind: StreamKind) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUstream, DriverError&gt; {
<a href=#481 id=481 data-nosnippet>481</a>        <span class="kw">let </span><span class="kw-2">mut </span>stream = MaybeUninit::uninit();
<a href=#482 id=482 data-nosnippet>482</a>        <span class="kw">unsafe </span>{
<a href=#483 id=483 data-nosnippet>483</a>            lib()
<a href=#484 id=484 data-nosnippet>484</a>                .cuStreamCreate(stream.as_mut_ptr(), kind.flags() <span class="kw">as </span>u32)
<a href=#485 id=485 data-nosnippet>485</a>                .result()<span class="question-mark">?</span>;
<a href=#486 id=486 data-nosnippet>486</a>            <span class="prelude-val">Ok</span>(stream.assume_init())
<a href=#487 id=487 data-nosnippet>487</a>        }
<a href=#488 id=488 data-nosnippet>488</a>    }
<a href=#489 id=489 data-nosnippet>489</a>
<a href=#490 id=490 data-nosnippet>490</a>    <span class="doccomment">/// Wait until a stream's tasks are completed.
<a href=#491 id=491 data-nosnippet>491</a>    ///
<a href=#492 id=492 data-nosnippet>492</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__STREAM.html#group__CUDA__STREAM_1g15e49dd91ec15991eb7c0a741beb7dad)
<a href=#493 id=493 data-nosnippet>493</a>    ///
<a href=#494 id=494 data-nosnippet>494</a>    /// # Safety
<a href=#495 id=495 data-nosnippet>495</a>    ///
<a href=#496 id=496 data-nosnippet>496</a>    /// This should only be called with stream created by [create] and not already
<a href=#497 id=497 data-nosnippet>497</a>    /// destroyed. This follows default stream semantics, see relevant cuda docs.
<a href=#498 id=498 data-nosnippet>498</a>    </span><span class="kw">pub unsafe fn </span>synchronize(stream: sys::CUstream) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#499 id=499 data-nosnippet>499</a>        lib().cuStreamSynchronize(stream).result()
<a href=#500 id=500 data-nosnippet>500</a>    }
<a href=#501 id=501 data-nosnippet>501</a>
<a href=#502 id=502 data-nosnippet>502</a>    <span class="doccomment">/// Destroys a stream.
<a href=#503 id=503 data-nosnippet>503</a>    ///
<a href=#504 id=504 data-nosnippet>504</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__STREAM.html#group__CUDA__STREAM_1g244c8833de4596bcd31a06cdf21ee758)
<a href=#505 id=505 data-nosnippet>505</a>    ///
<a href=#506 id=506 data-nosnippet>506</a>    /// # Safety
<a href=#507 id=507 data-nosnippet>507</a>    ///
<a href=#508 id=508 data-nosnippet>508</a>    /// This should only be called with stream created by [create] and not already
<a href=#509 id=509 data-nosnippet>509</a>    /// destroyed. This follows default stream semantics, see relevant cuda docs.
<a href=#510 id=510 data-nosnippet>510</a>    </span><span class="kw">pub unsafe fn </span>destroy(stream: sys::CUstream) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#511 id=511 data-nosnippet>511</a>        lib().cuStreamDestroy_v2(stream).result()
<a href=#512 id=512 data-nosnippet>512</a>    }
<a href=#513 id=513 data-nosnippet>513</a>
<a href=#514 id=514 data-nosnippet>514</a>    <span class="doccomment">/// Make a compute stream wait on an event.
<a href=#515 id=515 data-nosnippet>515</a>    ///
<a href=#516 id=516 data-nosnippet>516</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__STREAM.html#group__CUDA__STREAM_1g6a898b652dfc6aa1d5c8d97062618b2f)
<a href=#517 id=517 data-nosnippet>517</a>    ///
<a href=#518 id=518 data-nosnippet>518</a>    /// # Safety
<a href=#519 id=519 data-nosnippet>519</a>    /// 1. Both stream and event must not have been freed already
<a href=#520 id=520 data-nosnippet>520</a>    </span><span class="kw">pub unsafe fn </span>wait_event(
<a href=#521 id=521 data-nosnippet>521</a>        stream: sys::CUstream,
<a href=#522 id=522 data-nosnippet>522</a>        event: sys::CUevent,
<a href=#523 id=523 data-nosnippet>523</a>        flags: sys::CUevent_wait_flags,
<a href=#524 id=524 data-nosnippet>524</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#525 id=525 data-nosnippet>525</a>        lib()
<a href=#526 id=526 data-nosnippet>526</a>            .cuStreamWaitEvent(stream, event, flags <span class="kw">as </span>u32)
<a href=#527 id=527 data-nosnippet>527</a>            .result()
<a href=#528 id=528 data-nosnippet>528</a>    }
<a href=#529 id=529 data-nosnippet>529</a>
<a href=#530 id=530 data-nosnippet>530</a>    <span class="doccomment">/// Attach managed memory to a stream.
<a href=#531 id=531 data-nosnippet>531</a>    ///
<a href=#532 id=532 data-nosnippet>532</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__STREAM.html#group__CUDA__STREAM_1g6e468d680e263e7eba02a56643c50533)
<a href=#533 id=533 data-nosnippet>533</a>    ///
<a href=#534 id=534 data-nosnippet>534</a>    /// # Safety
<a href=#535 id=535 data-nosnippet>535</a>    /// See the cuda docs, there are a lot of considerations for this one.
<a href=#536 id=536 data-nosnippet>536</a>    /// &gt; Accessing memory on the device from streams that are not associated with it will produce undefined results. No error checking is performed by the Unified Memory system to ensure that kernels launched into other streams do not access this region.
<a href=#537 id=537 data-nosnippet>537</a>    </span><span class="kw">pub unsafe fn </span>attach_mem_async(
<a href=#538 id=538 data-nosnippet>538</a>        stream: sys::CUstream,
<a href=#539 id=539 data-nosnippet>539</a>        dptr: sys::CUdeviceptr,
<a href=#540 id=540 data-nosnippet>540</a>        num_bytes: usize,
<a href=#541 id=541 data-nosnippet>541</a>        flags: sys::CUmemAttach_flags,
<a href=#542 id=542 data-nosnippet>542</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#543 id=543 data-nosnippet>543</a>        lib()
<a href=#544 id=544 data-nosnippet>544</a>            .cuStreamAttachMemAsync(stream, dptr, num_bytes, flags <span class="kw">as </span>u32)
<a href=#545 id=545 data-nosnippet>545</a>            .result()
<a href=#546 id=546 data-nosnippet>546</a>    }
<a href=#547 id=547 data-nosnippet>547</a>}
<a href=#548 id=548 data-nosnippet>548</a>
<a href=#549 id=549 data-nosnippet>549</a><span class="doccomment">/// Allocates memory with stream ordered semantics.
<a href=#550 id=550 data-nosnippet>550</a>///
<a href=#551 id=551 data-nosnippet>551</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g13413273e84a641bce1929eae9e6501f)
<a href=#552 id=552 data-nosnippet>552</a>///
<a href=#553 id=553 data-nosnippet>553</a>/// # Safety
<a href=#554 id=554 data-nosnippet>554</a>/// 1. The stream should be an already created stream.
<a href=#555 id=555 data-nosnippet>555</a>/// 2. The memory return by this is unset, which may be invalid for `T`.
<a href=#556 id=556 data-nosnippet>556</a>/// 3. All uses of this memory must be on the same stream.
<a href=#557 id=557 data-nosnippet>557</a></span><span class="kw">pub unsafe fn </span>malloc_async(
<a href=#558 id=558 data-nosnippet>558</a>    stream: sys::CUstream,
<a href=#559 id=559 data-nosnippet>559</a>    num_bytes: usize,
<a href=#560 id=560 data-nosnippet>560</a>) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUdeviceptr, DriverError&gt; {
<a href=#561 id=561 data-nosnippet>561</a>    <span class="kw">let </span><span class="kw-2">mut </span>dev_ptr = MaybeUninit::uninit();
<a href=#562 id=562 data-nosnippet>562</a>    lib()
<a href=#563 id=563 data-nosnippet>563</a>        .cuMemAllocAsync(dev_ptr.as_mut_ptr(), num_bytes, stream)
<a href=#564 id=564 data-nosnippet>564</a>        .result()<span class="question-mark">?</span>;
<a href=#565 id=565 data-nosnippet>565</a>    <span class="prelude-val">Ok</span>(dev_ptr.assume_init())
<a href=#566 id=566 data-nosnippet>566</a>}
<a href=#567 id=567 data-nosnippet>567</a>
<a href=#568 id=568 data-nosnippet>568</a><span class="doccomment">/// Allocates memory
<a href=#569 id=569 data-nosnippet>569</a>///
<a href=#570 id=570 data-nosnippet>570</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gb82d2a09844a58dd9e744dc31e8aa467)
<a href=#571 id=571 data-nosnippet>571</a>///
<a href=#572 id=572 data-nosnippet>572</a>/// # Safety
<a href=#573 id=573 data-nosnippet>573</a>/// 1. The memory return by this is unset, which may be invalid for `T`.
<a href=#574 id=574 data-nosnippet>574</a></span><span class="kw">pub unsafe fn </span>malloc_sync(num_bytes: usize) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUdeviceptr, DriverError&gt; {
<a href=#575 id=575 data-nosnippet>575</a>    <span class="kw">let </span><span class="kw-2">mut </span>dev_ptr = MaybeUninit::uninit();
<a href=#576 id=576 data-nosnippet>576</a>    lib()
<a href=#577 id=577 data-nosnippet>577</a>        .cuMemAlloc_v2(dev_ptr.as_mut_ptr(), num_bytes)
<a href=#578 id=578 data-nosnippet>578</a>        .result()<span class="question-mark">?</span>;
<a href=#579 id=579 data-nosnippet>579</a>    <span class="prelude-val">Ok</span>(dev_ptr.assume_init())
<a href=#580 id=580 data-nosnippet>580</a>}
<a href=#581 id=581 data-nosnippet>581</a>
<a href=#582 id=582 data-nosnippet>582</a><span class="doccomment">/// Allocates managed memory.
<a href=#583 id=583 data-nosnippet>583</a>///
<a href=#584 id=584 data-nosnippet>584</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gb347ded34dc326af404aa02af5388a32)
<a href=#585 id=585 data-nosnippet>585</a>///
<a href=#586 id=586 data-nosnippet>586</a>/// # Safety
<a href=#587 id=587 data-nosnippet>587</a>/// 1. The memory return by this is unset, which may be invalid for `T`.
<a href=#588 id=588 data-nosnippet>588</a></span><span class="kw">pub unsafe fn </span>malloc_managed(
<a href=#589 id=589 data-nosnippet>589</a>    num_bytes: usize,
<a href=#590 id=590 data-nosnippet>590</a>    flags: sys::CUmemAttach_flags,
<a href=#591 id=591 data-nosnippet>591</a>) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUdeviceptr, DriverError&gt; {
<a href=#592 id=592 data-nosnippet>592</a>    <span class="kw">let </span><span class="kw-2">mut </span>dev_ptr = MaybeUninit::uninit();
<a href=#593 id=593 data-nosnippet>593</a>    lib()
<a href=#594 id=594 data-nosnippet>594</a>        .cuMemAllocManaged(dev_ptr.as_mut_ptr(), num_bytes, flags <span class="kw">as </span>u32)
<a href=#595 id=595 data-nosnippet>595</a>        .result()<span class="question-mark">?</span>;
<a href=#596 id=596 data-nosnippet>596</a>    <span class="prelude-val">Ok</span>(dev_ptr.assume_init())
<a href=#597 id=597 data-nosnippet>597</a>}
<a href=#598 id=598 data-nosnippet>598</a>
<a href=#599 id=599 data-nosnippet>599</a><span class="doccomment">/// Advise about the usage of a given memory range.
<a href=#600 id=600 data-nosnippet>600</a>///
<a href=#601 id=601 data-nosnippet>601</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1g27608c857a9254789c13f3e3b72029e2)
<a href=#602 id=602 data-nosnippet>602</a>/// **Only available in 12.2+.
<a href=#603 id=603 data-nosnippet>603</a>///
<a href=#604 id=604 data-nosnippet>604</a>/// # Safety
<a href=#605 id=605 data-nosnippet>605</a>/// 1. Memory must have been allocated by [malloc_managed()]
<a href=#606 id=606 data-nosnippet>606</a>/// 2. num_bytes must be the amount of bytes passed to [malloc_managed()]
<a href=#607 id=607 data-nosnippet>607</a></span><span class="attr">#[cfg(any(
<a href=#608 id=608 data-nosnippet>608</a>    feature = <span class="string">"cuda-12020"</span>,
<a href=#609 id=609 data-nosnippet>609</a>    feature = <span class="string">"cuda-12030"</span>,
<a href=#610 id=610 data-nosnippet>610</a>    feature = <span class="string">"cuda-12040"</span>,
<a href=#611 id=611 data-nosnippet>611</a>    feature = <span class="string">"cuda-12050"
<a href=#612 id=612 data-nosnippet>612</a></span>))]
<a href=#613 id=613 data-nosnippet>613</a></span><span class="kw">pub unsafe fn </span>mem_advise(
<a href=#614 id=614 data-nosnippet>614</a>    dptr: sys::CUdeviceptr,
<a href=#615 id=615 data-nosnippet>615</a>    num_bytes: usize,
<a href=#616 id=616 data-nosnippet>616</a>    advice: sys::CUmem_advise,
<a href=#617 id=617 data-nosnippet>617</a>    location: sys::CUmemLocation,
<a href=#618 id=618 data-nosnippet>618</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#619 id=619 data-nosnippet>619</a>    lib()
<a href=#620 id=620 data-nosnippet>620</a>        .cuMemAdvise_v2(dptr, num_bytes, advice, location)
<a href=#621 id=621 data-nosnippet>621</a>        .result()
<a href=#622 id=622 data-nosnippet>622</a>}
<a href=#623 id=623 data-nosnippet>623</a>
<a href=#624 id=624 data-nosnippet>624</a><span class="doccomment">/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__UNIFIED.html#group__CUDA__UNIFIED_1gfe94f8b7fb56291ebcea44261aa4cb84)
<a href=#625 id=625 data-nosnippet>625</a>/// **Only available in 12.2+.
<a href=#626 id=626 data-nosnippet>626</a>///
<a href=#627 id=627 data-nosnippet>627</a>/// # Safety
<a href=#628 id=628 data-nosnippet>628</a>/// 1. The dptr/num_bytes must be allocated by [malloc_managed()] and must be the exact same memory range.
<a href=#629 id=629 data-nosnippet>629</a></span><span class="attr">#[cfg(any(
<a href=#630 id=630 data-nosnippet>630</a>    feature = <span class="string">"cuda-12020"</span>,
<a href=#631 id=631 data-nosnippet>631</a>    feature = <span class="string">"cuda-12030"</span>,
<a href=#632 id=632 data-nosnippet>632</a>    feature = <span class="string">"cuda-12040"</span>,
<a href=#633 id=633 data-nosnippet>633</a>    feature = <span class="string">"cuda-12050"
<a href=#634 id=634 data-nosnippet>634</a></span>))]
<a href=#635 id=635 data-nosnippet>635</a></span><span class="kw">pub unsafe fn </span>mem_prefetch_async(
<a href=#636 id=636 data-nosnippet>636</a>    dptr: sys::CUdeviceptr,
<a href=#637 id=637 data-nosnippet>637</a>    num_bytes: usize,
<a href=#638 id=638 data-nosnippet>638</a>    location: sys::CUmemLocation,
<a href=#639 id=639 data-nosnippet>639</a>    stream: sys::CUstream,
<a href=#640 id=640 data-nosnippet>640</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#641 id=641 data-nosnippet>641</a>    lib()
<a href=#642 id=642 data-nosnippet>642</a>        .cuMemPrefetchAsync_v2(dptr, num_bytes, location, <span class="number">0</span>, stream)
<a href=#643 id=643 data-nosnippet>643</a>        .result()
<a href=#644 id=644 data-nosnippet>644</a>}
<a href=#645 id=645 data-nosnippet>645</a>
<a href=#646 id=646 data-nosnippet>646</a><span class="doccomment">/// Frees memory with stream ordered semantics.
<a href=#647 id=647 data-nosnippet>647</a>///
<a href=#648 id=648 data-nosnippet>648</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MALLOC__ASYNC.html#group__CUDA__MALLOC__ASYNC_1g41acf4131f672a2a75cd93d3241f10cf)
<a href=#649 id=649 data-nosnippet>649</a>///
<a href=#650 id=650 data-nosnippet>650</a>/// # Safety
<a href=#651 id=651 data-nosnippet>651</a>/// 1. The stream should be an already created stream.
<a href=#652 id=652 data-nosnippet>652</a>/// 2. The memory should have been allocated on this stream.
<a href=#653 id=653 data-nosnippet>653</a>/// 3. The memory should not have been freed already (double free)
<a href=#654 id=654 data-nosnippet>654</a></span><span class="kw">pub unsafe fn </span>free_async(dptr: sys::CUdeviceptr, stream: sys::CUstream) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#655 id=655 data-nosnippet>655</a>    lib().cuMemFreeAsync(dptr, stream).result()
<a href=#656 id=656 data-nosnippet>656</a>}
<a href=#657 id=657 data-nosnippet>657</a>
<a href=#658 id=658 data-nosnippet>658</a><span class="doccomment">/// Allocates memory
<a href=#659 id=659 data-nosnippet>659</a>///
<a href=#660 id=660 data-nosnippet>660</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g89b3f154e17cc89b6eea277dbdf5c93a)
<a href=#661 id=661 data-nosnippet>661</a>///
<a href=#662 id=662 data-nosnippet>662</a>/// # Safety
<a href=#663 id=663 data-nosnippet>663</a>/// 1. The memory should have been allocated with malloc_sync
<a href=#664 id=664 data-nosnippet>664</a></span><span class="kw">pub unsafe fn </span>free_sync(dptr: sys::CUdeviceptr) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#665 id=665 data-nosnippet>665</a>    lib().cuMemFree_v2(dptr).result()
<a href=#666 id=666 data-nosnippet>666</a>}
<a href=#667 id=667 data-nosnippet>667</a>
<a href=#668 id=668 data-nosnippet>668</a><span class="doccomment">/// Frees device memory.
<a href=#669 id=669 data-nosnippet>669</a>///
<a href=#670 id=670 data-nosnippet>670</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g89b3f154e17cc89b6eea277dbdf5c93a)
<a href=#671 id=671 data-nosnippet>671</a>///
<a href=#672 id=672 data-nosnippet>672</a>/// # Safety
<a href=#673 id=673 data-nosnippet>673</a>/// 1. Memory must only be freed once.
<a href=#674 id=674 data-nosnippet>674</a>/// 2. All async accesses to this pointer must have been completed.
<a href=#675 id=675 data-nosnippet>675</a></span><span class="kw">pub unsafe fn </span>memory_free(device_ptr: sys::CUdeviceptr) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#676 id=676 data-nosnippet>676</a>    lib().cuMemFree_v2(device_ptr).result()
<a href=#677 id=677 data-nosnippet>677</a>}
<a href=#678 id=678 data-nosnippet>678</a>
<a href=#679 id=679 data-nosnippet>679</a><span class="doccomment">/// Sets device memory with stream ordered semantics.
<a href=#680 id=680 data-nosnippet>680</a>///
<a href=#681 id=681 data-nosnippet>681</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1gaef08a7ccd61112f94e82f2b30d43627)
<a href=#682 id=682 data-nosnippet>682</a>///
<a href=#683 id=683 data-nosnippet>683</a>/// # Safety
<a href=#684 id=684 data-nosnippet>684</a>/// 1. The resulting memory pattern may not be valid for `T`.
<a href=#685 id=685 data-nosnippet>685</a>/// 2. The device pointer should not have been freed already (double free)
<a href=#686 id=686 data-nosnippet>686</a>/// 3. The stream should be the stream the memory was allocated on.
<a href=#687 id=687 data-nosnippet>687</a></span><span class="kw">pub unsafe fn </span>memset_d8_async(
<a href=#688 id=688 data-nosnippet>688</a>    dptr: sys::CUdeviceptr,
<a href=#689 id=689 data-nosnippet>689</a>    uc: c_uchar,
<a href=#690 id=690 data-nosnippet>690</a>    num_bytes: usize,
<a href=#691 id=691 data-nosnippet>691</a>    stream: sys::CUstream,
<a href=#692 id=692 data-nosnippet>692</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#693 id=693 data-nosnippet>693</a>    lib().cuMemsetD8Async(dptr, uc, num_bytes, stream).result()
<a href=#694 id=694 data-nosnippet>694</a>}
<a href=#695 id=695 data-nosnippet>695</a>
<a href=#696 id=696 data-nosnippet>696</a><span class="doccomment">/// Sets device memory with stream ordered semantics.
<a href=#697 id=697 data-nosnippet>697</a>///
<a href=#698 id=698 data-nosnippet>698</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g6e582bf866e9e2fb014297bfaf354d7b)
<a href=#699 id=699 data-nosnippet>699</a>///
<a href=#700 id=700 data-nosnippet>700</a>/// # Safety
<a href=#701 id=701 data-nosnippet>701</a>/// 1. The resulting memory pattern may not be valid for `T`.
<a href=#702 id=702 data-nosnippet>702</a>/// 2. The device pointer should not have been freed already (double free)
<a href=#703 id=703 data-nosnippet>703</a></span><span class="kw">pub unsafe fn </span>memset_d8_sync(
<a href=#704 id=704 data-nosnippet>704</a>    dptr: sys::CUdeviceptr,
<a href=#705 id=705 data-nosnippet>705</a>    uc: c_uchar,
<a href=#706 id=706 data-nosnippet>706</a>    num_bytes: usize,
<a href=#707 id=707 data-nosnippet>707</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#708 id=708 data-nosnippet>708</a>    lib().cuMemsetD8_v2(dptr, uc, num_bytes).result()
<a href=#709 id=709 data-nosnippet>709</a>}
<a href=#710 id=710 data-nosnippet>710</a>
<a href=#711 id=711 data-nosnippet>711</a><span class="doccomment">/// Copies memory from Host to Device with stream ordered semantics.
<a href=#712 id=712 data-nosnippet>712</a>///
<a href=#713 id=713 data-nosnippet>713</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4d32266788c440b0220b1a9ba5795169)
<a href=#714 id=714 data-nosnippet>714</a>///
<a href=#715 id=715 data-nosnippet>715</a>/// # Safety
<a href=#716 id=716 data-nosnippet>716</a>/// **This function is asynchronous** in most cases, so the data from `src`
<a href=#717 id=717 data-nosnippet>717</a>/// will be copied at a later point after this function returns.
<a href=#718 id=718 data-nosnippet>718</a>///
<a href=#719 id=719 data-nosnippet>719</a>/// 1. `T` must be the type that device pointer was allocated with.
<a href=#720 id=720 data-nosnippet>720</a>/// 2. The device pointer should not have been freed already (double free)
<a href=#721 id=721 data-nosnippet>721</a>/// 3. The stream should be the stream the memory was allocated on.
<a href=#722 id=722 data-nosnippet>722</a>/// 4. `src` must not be moved
<a href=#723 id=723 data-nosnippet>723</a></span><span class="kw">pub unsafe fn </span>memcpy_htod_async&lt;T&gt;(
<a href=#724 id=724 data-nosnippet>724</a>    dst: sys::CUdeviceptr,
<a href=#725 id=725 data-nosnippet>725</a>    src: <span class="kw-2">&amp;</span>[T],
<a href=#726 id=726 data-nosnippet>726</a>    stream: sys::CUstream,
<a href=#727 id=727 data-nosnippet>727</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#728 id=728 data-nosnippet>728</a>    lib()
<a href=#729 id=729 data-nosnippet>729</a>        .cuMemcpyHtoDAsync_v2(
<a href=#730 id=730 data-nosnippet>730</a>            dst,
<a href=#731 id=731 data-nosnippet>731</a>            src.as_ptr() <span class="kw">as </span><span class="kw-2">*const </span><span class="kw">_</span>,
<a href=#732 id=732 data-nosnippet>732</a>            std::mem::size_of_val(src),
<a href=#733 id=733 data-nosnippet>733</a>            stream,
<a href=#734 id=734 data-nosnippet>734</a>        )
<a href=#735 id=735 data-nosnippet>735</a>        .result()
<a href=#736 id=736 data-nosnippet>736</a>}
<a href=#737 id=737 data-nosnippet>737</a>
<a href=#738 id=738 data-nosnippet>738</a><span class="doccomment">/// Copies memory from Host to Device
<a href=#739 id=739 data-nosnippet>739</a>///
<a href=#740 id=740 data-nosnippet>740</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g4d32266788c440b0220b1a9ba5795169)
<a href=#741 id=741 data-nosnippet>741</a>///
<a href=#742 id=742 data-nosnippet>742</a>/// # Safety
<a href=#743 id=743 data-nosnippet>743</a>/// **This function is synchronous**///
<a href=#744 id=744 data-nosnippet>744</a>/// 1. `T` must be the type that device pointer was allocated with.
<a href=#745 id=745 data-nosnippet>745</a>/// 2. The device pointer should not have been freed already (double free)
<a href=#746 id=746 data-nosnippet>746</a>/// 3. `src` must not be moved
<a href=#747 id=747 data-nosnippet>747</a></span><span class="kw">pub unsafe fn </span>memcpy_htod_sync&lt;T&gt;(dst: sys::CUdeviceptr, src: <span class="kw-2">&amp;</span>[T]) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#748 id=748 data-nosnippet>748</a>    lib()
<a href=#749 id=749 data-nosnippet>749</a>        .cuMemcpyHtoD_v2(dst, src.as_ptr() <span class="kw">as </span><span class="kw-2">*const </span><span class="kw">_</span>, std::mem::size_of_val(src))
<a href=#750 id=750 data-nosnippet>750</a>        .result()
<a href=#751 id=751 data-nosnippet>751</a>}
<a href=#752 id=752 data-nosnippet>752</a>
<a href=#753 id=753 data-nosnippet>753</a><span class="doccomment">/// Copies memory from Device to Host with stream ordered semantics.
<a href=#754 id=754 data-nosnippet>754</a>///
<a href=#755 id=755 data-nosnippet>755</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g56f30236c7c5247f8e061b59d3268362)
<a href=#756 id=756 data-nosnippet>756</a>///
<a href=#757 id=757 data-nosnippet>757</a>/// # Safety
<a href=#758 id=758 data-nosnippet>758</a>/// **This function is asynchronous** in most cases, so `dst` will be
<a href=#759 id=759 data-nosnippet>759</a>/// mutated at a later point after this function returns.
<a href=#760 id=760 data-nosnippet>760</a>///
<a href=#761 id=761 data-nosnippet>761</a>/// 1. `T` must be the type that device pointer was allocated with.
<a href=#762 id=762 data-nosnippet>762</a>/// 2. The device pointer should not have been freed already (double free)
<a href=#763 id=763 data-nosnippet>763</a>/// 3. The stream should be the stream the memory was allocated on.
<a href=#764 id=764 data-nosnippet>764</a></span><span class="kw">pub unsafe fn </span>memcpy_dtoh_async&lt;T&gt;(
<a href=#765 id=765 data-nosnippet>765</a>    dst: <span class="kw-2">&amp;mut </span>[T],
<a href=#766 id=766 data-nosnippet>766</a>    src: sys::CUdeviceptr,
<a href=#767 id=767 data-nosnippet>767</a>    stream: sys::CUstream,
<a href=#768 id=768 data-nosnippet>768</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#769 id=769 data-nosnippet>769</a>    lib()
<a href=#770 id=770 data-nosnippet>770</a>        .cuMemcpyDtoHAsync_v2(
<a href=#771 id=771 data-nosnippet>771</a>            dst.as_mut_ptr() <span class="kw">as </span><span class="kw-2">*mut </span><span class="kw">_</span>,
<a href=#772 id=772 data-nosnippet>772</a>            src,
<a href=#773 id=773 data-nosnippet>773</a>            std::mem::size_of_val(dst),
<a href=#774 id=774 data-nosnippet>774</a>            stream,
<a href=#775 id=775 data-nosnippet>775</a>        )
<a href=#776 id=776 data-nosnippet>776</a>        .result()
<a href=#777 id=777 data-nosnippet>777</a>}
<a href=#778 id=778 data-nosnippet>778</a>
<a href=#779 id=779 data-nosnippet>779</a><span class="doccomment">/// Copies memory from Device to Host with stream ordered semantics.
<a href=#780 id=780 data-nosnippet>780</a>///
<a href=#781 id=781 data-nosnippet>781</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g3480368ee0208a98f75019c9a8450893)
<a href=#782 id=782 data-nosnippet>782</a>///
<a href=#783 id=783 data-nosnippet>783</a>/// # Safety
<a href=#784 id=784 data-nosnippet>784</a>/// **This function is synchronous**
<a href=#785 id=785 data-nosnippet>785</a>///
<a href=#786 id=786 data-nosnippet>786</a>/// 1. `T` must be the type that device pointer was allocated with.
<a href=#787 id=787 data-nosnippet>787</a>/// 2. The device pointer should not have been freed already (double free)
<a href=#788 id=788 data-nosnippet>788</a></span><span class="kw">pub unsafe fn </span>memcpy_dtoh_sync&lt;T&gt;(dst: <span class="kw-2">&amp;mut </span>[T], src: sys::CUdeviceptr) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#789 id=789 data-nosnippet>789</a>    lib()
<a href=#790 id=790 data-nosnippet>790</a>        .cuMemcpyDtoH_v2(dst.as_mut_ptr() <span class="kw">as </span><span class="kw-2">*mut </span><span class="kw">_</span>, src, std::mem::size_of_val(dst))
<a href=#791 id=791 data-nosnippet>791</a>        .result()
<a href=#792 id=792 data-nosnippet>792</a>}
<a href=#793 id=793 data-nosnippet>793</a>
<a href=#794 id=794 data-nosnippet>794</a><span class="doccomment">/// Copies memory from Device to Device with stream ordered semantics.
<a href=#795 id=795 data-nosnippet>795</a>///
<a href=#796 id=796 data-nosnippet>796</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g39ea09ba682b8eccc9c3e0c04319b5c8)
<a href=#797 id=797 data-nosnippet>797</a>///
<a href=#798 id=798 data-nosnippet>798</a>/// # Safety
<a href=#799 id=799 data-nosnippet>799</a>/// 1. `T` must be the type that BOTH device pointers were allocated with.
<a href=#800 id=800 data-nosnippet>800</a>/// 2. Neither device pointer should not have been freed already (double free)
<a href=#801 id=801 data-nosnippet>801</a>/// 3. The stream should be the stream the memory was allocated on.
<a href=#802 id=802 data-nosnippet>802</a></span><span class="kw">pub unsafe fn </span>memcpy_dtod_async(
<a href=#803 id=803 data-nosnippet>803</a>    dst: sys::CUdeviceptr,
<a href=#804 id=804 data-nosnippet>804</a>    src: sys::CUdeviceptr,
<a href=#805 id=805 data-nosnippet>805</a>    num_bytes: usize,
<a href=#806 id=806 data-nosnippet>806</a>    stream: sys::CUstream,
<a href=#807 id=807 data-nosnippet>807</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#808 id=808 data-nosnippet>808</a>    lib()
<a href=#809 id=809 data-nosnippet>809</a>        .cuMemcpyDtoDAsync_v2(dst, src, num_bytes, stream)
<a href=#810 id=810 data-nosnippet>810</a>        .result()
<a href=#811 id=811 data-nosnippet>811</a>}
<a href=#812 id=812 data-nosnippet>812</a>
<a href=#813 id=813 data-nosnippet>813</a><span class="doccomment">/// Copies memory from Device to Device
<a href=#814 id=814 data-nosnippet>814</a>///
<a href=#815 id=815 data-nosnippet>815</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g1725774abf8b51b91945f3336b778c8b)
<a href=#816 id=816 data-nosnippet>816</a>///
<a href=#817 id=817 data-nosnippet>817</a>/// # Safety
<a href=#818 id=818 data-nosnippet>818</a>/// 1. `T` must be the type that BOTH device pointers were allocated with.
<a href=#819 id=819 data-nosnippet>819</a>/// 2. Neither device pointer should not have been freed already (double free)
<a href=#820 id=820 data-nosnippet>820</a></span><span class="kw">pub unsafe fn </span>memcpy_dtod_sync(
<a href=#821 id=821 data-nosnippet>821</a>    dst: sys::CUdeviceptr,
<a href=#822 id=822 data-nosnippet>822</a>    src: sys::CUdeviceptr,
<a href=#823 id=823 data-nosnippet>823</a>    num_bytes: usize,
<a href=#824 id=824 data-nosnippet>824</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#825 id=825 data-nosnippet>825</a>    lib().cuMemcpyDtoD_v2(dst, src, num_bytes).result()
<a href=#826 id=826 data-nosnippet>826</a>}
<a href=#827 id=827 data-nosnippet>827</a>
<a href=#828 id=828 data-nosnippet>828</a><span class="doccomment">/// Returns (free, total) memory in bytes.
<a href=#829 id=829 data-nosnippet>829</a>///
<a href=#830 id=830 data-nosnippet>830</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MEM.html#group__CUDA__MEM_1g808f555540d0143a331cc42aa98835c0)
<a href=#831 id=831 data-nosnippet>831</a></span><span class="kw">pub fn </span>mem_get_info() -&gt; <span class="prelude-ty">Result</span>&lt;(usize, usize), DriverError&gt; {
<a href=#832 id=832 data-nosnippet>832</a>    <span class="kw">let </span><span class="kw-2">mut </span>free = <span class="number">0</span>;
<a href=#833 id=833 data-nosnippet>833</a>    <span class="kw">let </span><span class="kw-2">mut </span>total = <span class="number">0</span>;
<a href=#834 id=834 data-nosnippet>834</a>    <span class="kw">unsafe </span>{ lib().cuMemGetInfo_v2(<span class="kw-2">&amp;mut </span>free <span class="kw">as </span><span class="kw-2">*mut </span><span class="kw">_</span>, <span class="kw-2">&amp;mut </span>total <span class="kw">as </span><span class="kw-2">*mut </span><span class="kw">_</span>) }.result()<span class="question-mark">?</span>;
<a href=#835 id=835 data-nosnippet>835</a>    <span class="prelude-val">Ok</span>((free, total))
<a href=#836 id=836 data-nosnippet>836</a>}
<a href=#837 id=837 data-nosnippet>837</a>
<a href=#838 id=838 data-nosnippet>838</a><span class="kw">pub mod </span>module {
<a href=#839 id=839 data-nosnippet>839</a>    <span class="doccomment">//! Module management functions (`cuModule*`).
<a href=#840 id=840 data-nosnippet>840</a>    //!
<a href=#841 id=841 data-nosnippet>841</a>    //! See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE.html#group__CUDA__MODULE)
<a href=#842 id=842 data-nosnippet>842</a>
<a href=#843 id=843 data-nosnippet>843</a>    </span><span class="kw">use super</span>::{
<a href=#844 id=844 data-nosnippet>844</a>        sys::{<span class="self">self</span>, lib},
<a href=#845 id=845 data-nosnippet>845</a>        DriverError,
<a href=#846 id=846 data-nosnippet>846</a>    };
<a href=#847 id=847 data-nosnippet>847</a>    <span class="kw">use </span>core::ffi::c_void;
<a href=#848 id=848 data-nosnippet>848</a>    <span class="kw">use </span>std::ffi::CString;
<a href=#849 id=849 data-nosnippet>849</a>    <span class="kw">use </span>std::mem::MaybeUninit;
<a href=#850 id=850 data-nosnippet>850</a>
<a href=#851 id=851 data-nosnippet>851</a>    <span class="doccomment">/// Loads a compute module from a given file.
<a href=#852 id=852 data-nosnippet>852</a>    ///
<a href=#853 id=853 data-nosnippet>853</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE.html#group__CUDA__MODULE_1g366093bd269dafd0af21f1c7d18115d3)
<a href=#854 id=854 data-nosnippet>854</a>    </span><span class="kw">pub fn </span>load(fname: CString) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUmodule, DriverError&gt; {
<a href=#855 id=855 data-nosnippet>855</a>        <span class="kw">let </span>fname_ptr = fname.as_c_str().as_ptr();
<a href=#856 id=856 data-nosnippet>856</a>        <span class="kw">let </span><span class="kw-2">mut </span>module = MaybeUninit::uninit();
<a href=#857 id=857 data-nosnippet>857</a>        <span class="kw">unsafe </span>{
<a href=#858 id=858 data-nosnippet>858</a>            lib()
<a href=#859 id=859 data-nosnippet>859</a>                .cuModuleLoad(module.as_mut_ptr(), fname_ptr)
<a href=#860 id=860 data-nosnippet>860</a>                .result()<span class="question-mark">?</span>;
<a href=#861 id=861 data-nosnippet>861</a>            <span class="prelude-val">Ok</span>(module.assume_init())
<a href=#862 id=862 data-nosnippet>862</a>        }
<a href=#863 id=863 data-nosnippet>863</a>    }
<a href=#864 id=864 data-nosnippet>864</a>
<a href=#865 id=865 data-nosnippet>865</a>    <span class="doccomment">/// Load a module's data:
<a href=#866 id=866 data-nosnippet>866</a>    ///
<a href=#867 id=867 data-nosnippet>867</a>    /// &gt; The pointer may be obtained by mapping a cubin or PTX or fatbin file,
<a href=#868 id=868 data-nosnippet>868</a>    /// &gt; passing a cubin or PTX or fatbin file as a NULL-terminated text string,
<a href=#869 id=869 data-nosnippet>869</a>    /// &gt; or incorporating a cubin or fatbin object into the executable resources
<a href=#870 id=870 data-nosnippet>870</a>    /// &gt; and using operating system calls such as Windows FindResource() to obtain the pointer.
<a href=#871 id=871 data-nosnippet>871</a>    ///
<a href=#872 id=872 data-nosnippet>872</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE.html#group__CUDA__MODULE_1g04ce266ce03720f479eab76136b90c0b)
<a href=#873 id=873 data-nosnippet>873</a>    ///
<a href=#874 id=874 data-nosnippet>874</a>    /// # Safety
<a href=#875 id=875 data-nosnippet>875</a>    /// The image must be properly formed pointer
<a href=#876 id=876 data-nosnippet>876</a>    </span><span class="kw">pub unsafe fn </span>load_data(image: <span class="kw-2">*const </span>c_void) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUmodule, DriverError&gt; {
<a href=#877 id=877 data-nosnippet>877</a>        <span class="kw">let </span><span class="kw-2">mut </span>module = MaybeUninit::uninit();
<a href=#878 id=878 data-nosnippet>878</a>        lib()
<a href=#879 id=879 data-nosnippet>879</a>            .cuModuleLoadData(module.as_mut_ptr(), image)
<a href=#880 id=880 data-nosnippet>880</a>            .result()<span class="question-mark">?</span>;
<a href=#881 id=881 data-nosnippet>881</a>        <span class="prelude-val">Ok</span>(module.assume_init())
<a href=#882 id=882 data-nosnippet>882</a>    }
<a href=#883 id=883 data-nosnippet>883</a>
<a href=#884 id=884 data-nosnippet>884</a>    <span class="doccomment">/// Returns a function handle from the given module.
<a href=#885 id=885 data-nosnippet>885</a>    ///
<a href=#886 id=886 data-nosnippet>886</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE.html#group__CUDA__MODULE_1ga52be009b0d4045811b30c965e1cb2cf)
<a href=#887 id=887 data-nosnippet>887</a>    ///
<a href=#888 id=888 data-nosnippet>888</a>    /// # Safety
<a href=#889 id=889 data-nosnippet>889</a>    /// `module` must be a properly allocated and not freed module.
<a href=#890 id=890 data-nosnippet>890</a>    </span><span class="kw">pub unsafe fn </span>get_function(
<a href=#891 id=891 data-nosnippet>891</a>        module: sys::CUmodule,
<a href=#892 id=892 data-nosnippet>892</a>        name: CString,
<a href=#893 id=893 data-nosnippet>893</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUfunction, DriverError&gt; {
<a href=#894 id=894 data-nosnippet>894</a>        <span class="kw">let </span>name_ptr = name.as_c_str().as_ptr();
<a href=#895 id=895 data-nosnippet>895</a>        <span class="kw">let </span><span class="kw-2">mut </span>func = MaybeUninit::uninit();
<a href=#896 id=896 data-nosnippet>896</a>        lib()
<a href=#897 id=897 data-nosnippet>897</a>            .cuModuleGetFunction(func.as_mut_ptr(), module, name_ptr)
<a href=#898 id=898 data-nosnippet>898</a>            .result()<span class="question-mark">?</span>;
<a href=#899 id=899 data-nosnippet>899</a>        <span class="prelude-val">Ok</span>(func.assume_init())
<a href=#900 id=900 data-nosnippet>900</a>    }
<a href=#901 id=901 data-nosnippet>901</a>
<a href=#902 id=902 data-nosnippet>902</a>    <span class="doccomment">/// Unloads a module.
<a href=#903 id=903 data-nosnippet>903</a>    ///
<a href=#904 id=904 data-nosnippet>904</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__MODULE.html#group__CUDA__MODULE_1g8ea3d716524369de3763104ced4ea57b)
<a href=#905 id=905 data-nosnippet>905</a>    ///
<a href=#906 id=906 data-nosnippet>906</a>    /// # Safety
<a href=#907 id=907 data-nosnippet>907</a>    /// `module` must not have be unloaded already.
<a href=#908 id=908 data-nosnippet>908</a>    </span><span class="kw">pub unsafe fn </span>unload(module: sys::CUmodule) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#909 id=909 data-nosnippet>909</a>        lib().cuModuleUnload(module).result()
<a href=#910 id=910 data-nosnippet>910</a>    }
<a href=#911 id=911 data-nosnippet>911</a>}
<a href=#912 id=912 data-nosnippet>912</a>
<a href=#913 id=913 data-nosnippet>913</a><span class="kw">pub mod </span>event {
<a href=#914 id=914 data-nosnippet>914</a>    <span class="kw">use super</span>::{
<a href=#915 id=915 data-nosnippet>915</a>        sys::{<span class="self">self</span>, lib},
<a href=#916 id=916 data-nosnippet>916</a>        DriverError,
<a href=#917 id=917 data-nosnippet>917</a>    };
<a href=#918 id=918 data-nosnippet>918</a>    <span class="kw">use </span>std::mem::MaybeUninit;
<a href=#919 id=919 data-nosnippet>919</a>
<a href=#920 id=920 data-nosnippet>920</a>    <span class="doccomment">/// Creates an event.
<a href=#921 id=921 data-nosnippet>921</a>    ///
<a href=#922 id=922 data-nosnippet>922</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EVENT.html#group__CUDA__EVENT_1g450687e75f3ff992fe01662a43d9d3db)
<a href=#923 id=923 data-nosnippet>923</a>    </span><span class="kw">pub fn </span>create(flags: sys::CUevent_flags) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUevent, DriverError&gt; {
<a href=#924 id=924 data-nosnippet>924</a>        <span class="kw">let </span><span class="kw-2">mut </span>event = MaybeUninit::uninit();
<a href=#925 id=925 data-nosnippet>925</a>        <span class="kw">unsafe </span>{
<a href=#926 id=926 data-nosnippet>926</a>            lib()
<a href=#927 id=927 data-nosnippet>927</a>                .cuEventCreate(event.as_mut_ptr(), flags <span class="kw">as </span>u32)
<a href=#928 id=928 data-nosnippet>928</a>                .result()<span class="question-mark">?</span>;
<a href=#929 id=929 data-nosnippet>929</a>            <span class="prelude-val">Ok</span>(event.assume_init())
<a href=#930 id=930 data-nosnippet>930</a>        }
<a href=#931 id=931 data-nosnippet>931</a>    }
<a href=#932 id=932 data-nosnippet>932</a>
<a href=#933 id=933 data-nosnippet>933</a>    <span class="doccomment">/// Records an event.
<a href=#934 id=934 data-nosnippet>934</a>    ///
<a href=#935 id=935 data-nosnippet>935</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EVENT.html#group__CUDA__EVENT_1g95424d3be52c4eb95d83861b70fb89d1)
<a href=#936 id=936 data-nosnippet>936</a>    ///
<a href=#937 id=937 data-nosnippet>937</a>    /// # Safety
<a href=#938 id=938 data-nosnippet>938</a>    /// This function is unsafe because event can be a null event, in which case
<a href=#939 id=939 data-nosnippet>939</a>    </span><span class="kw">pub unsafe fn </span>record(event: sys::CUevent, stream: sys::CUstream) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#940 id=940 data-nosnippet>940</a>        <span class="kw">unsafe </span>{ lib().cuEventRecord(event, stream).result() }
<a href=#941 id=941 data-nosnippet>941</a>    }
<a href=#942 id=942 data-nosnippet>942</a>
<a href=#943 id=943 data-nosnippet>943</a>    <span class="doccomment">/// Computes the elapsed time (in milliseconds) between two events.
<a href=#944 id=944 data-nosnippet>944</a>    ///
<a href=#945 id=945 data-nosnippet>945</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EVENT.html#group__CUDA__EVENT_1gdfb1178807353bbcaa9e245da497cf97)
<a href=#946 id=946 data-nosnippet>946</a>    /// # Safety
<a href=#947 id=947 data-nosnippet>947</a>    /// 1. Events must have been created by [create]
<a href=#948 id=948 data-nosnippet>948</a>    /// 2. They should be on the same stream
<a href=#949 id=949 data-nosnippet>949</a>    /// 3. They must not have been destroyed.
<a href=#950 id=950 data-nosnippet>950</a>    </span><span class="kw">pub unsafe fn </span>elapsed(start: sys::CUevent, end: sys::CUevent) -&gt; <span class="prelude-ty">Result</span>&lt;f32, DriverError&gt; {
<a href=#951 id=951 data-nosnippet>951</a>        <span class="kw">let </span><span class="kw-2">mut </span>ms: f32 = <span class="number">0.0</span>;
<a href=#952 id=952 data-nosnippet>952</a>        <span class="kw">unsafe </span>{
<a href=#953 id=953 data-nosnippet>953</a>            lib()
<a href=#954 id=954 data-nosnippet>954</a>                .cuEventElapsedTime((<span class="kw-2">&amp;mut </span>ms) <span class="kw">as </span><span class="kw-2">*mut </span><span class="kw">_</span>, start, end)
<a href=#955 id=955 data-nosnippet>955</a>                .result()<span class="question-mark">?</span>;
<a href=#956 id=956 data-nosnippet>956</a>        }
<a href=#957 id=957 data-nosnippet>957</a>        <span class="prelude-val">Ok</span>(ms)
<a href=#958 id=958 data-nosnippet>958</a>    }
<a href=#959 id=959 data-nosnippet>959</a>
<a href=#960 id=960 data-nosnippet>960</a>    <span class="doccomment">/// Destroys an event.
<a href=#961 id=961 data-nosnippet>961</a>    ///
<a href=#962 id=962 data-nosnippet>962</a>    /// &gt; An event may be destroyed before it is complete (i.e., while cuEventQuery() would return CUDA_ERROR_NOT_READY).
<a href=#963 id=963 data-nosnippet>963</a>    /// &gt; In this case, the call does not block on completion of the event,
<a href=#964 id=964 data-nosnippet>964</a>    /// &gt; and any associated resources will automatically be released asynchronously at completion.
<a href=#965 id=965 data-nosnippet>965</a>    ///
<a href=#966 id=966 data-nosnippet>966</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EVENT.html#group__CUDA__EVENT_1g593ec73a8ec5a5fc031311d3e4dca1ef)
<a href=#967 id=967 data-nosnippet>967</a>    ///
<a href=#968 id=968 data-nosnippet>968</a>    /// # Safety
<a href=#969 id=969 data-nosnippet>969</a>    /// 1. Event must not have been freed already
<a href=#970 id=970 data-nosnippet>970</a>    </span><span class="kw">pub unsafe fn </span>destroy(event: sys::CUevent) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#971 id=971 data-nosnippet>971</a>        lib().cuEventDestroy_v2(event).result()
<a href=#972 id=972 data-nosnippet>972</a>    }
<a href=#973 id=973 data-nosnippet>973</a>}
<a href=#974 id=974 data-nosnippet>974</a>
<a href=#975 id=975 data-nosnippet>975</a><span class="doccomment">/// Launches a cuda functions
<a href=#976 id=976 data-nosnippet>976</a>///
<a href=#977 id=977 data-nosnippet>977</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html#group__CUDA__EXEC_1gb8f3dc3031b40da29d5f9a7139e52e15)
<a href=#978 id=978 data-nosnippet>978</a>///
<a href=#979 id=979 data-nosnippet>979</a>/// # Safety
<a href=#980 id=980 data-nosnippet>980</a>/// This method is **very unsafe**.
<a href=#981 id=981 data-nosnippet>981</a>///
<a href=#982 id=982 data-nosnippet>982</a>/// 1. The cuda function must be a valid handle returned from a non-unloaded module.
<a href=#983 id=983 data-nosnippet>983</a>/// 2. This is asynchronous, so the results of calling this function happen
<a href=#984 id=984 data-nosnippet>984</a>///    at a later point after this function returns.
<a href=#985 id=985 data-nosnippet>985</a>/// 3. All parameters used for this kernel should have been allocated by stream (I think?)
<a href=#986 id=986 data-nosnippet>986</a>/// 4. The cuda kernel has mutable access to every parameter, that means every parameter
<a href=#987 id=987 data-nosnippet>987</a>///    can change at a later point after callign this function. *Even non-mutable references*.
<a href=#988 id=988 data-nosnippet>988</a></span><span class="attr">#[inline]
<a href=#989 id=989 data-nosnippet>989</a></span><span class="kw">pub unsafe fn </span>launch_kernel(
<a href=#990 id=990 data-nosnippet>990</a>    f: sys::CUfunction,
<a href=#991 id=991 data-nosnippet>991</a>    grid_dim: (c_uint, c_uint, c_uint),
<a href=#992 id=992 data-nosnippet>992</a>    block_dim: (c_uint, c_uint, c_uint),
<a href=#993 id=993 data-nosnippet>993</a>    shared_mem_bytes: c_uint,
<a href=#994 id=994 data-nosnippet>994</a>    stream: sys::CUstream,
<a href=#995 id=995 data-nosnippet>995</a>    kernel_params: <span class="kw-2">&amp;mut </span>[<span class="kw-2">*mut </span>c_void],
<a href=#996 id=996 data-nosnippet>996</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#997 id=997 data-nosnippet>997</a>    lib()
<a href=#998 id=998 data-nosnippet>998</a>        .cuLaunchKernel(
<a href=#999 id=999 data-nosnippet>999</a>            f,
<a href=#1000 id=1000 data-nosnippet>1000</a>            grid_dim.<span class="number">0</span>,
<a href=#1001 id=1001 data-nosnippet>1001</a>            grid_dim.<span class="number">1</span>,
<a href=#1002 id=1002 data-nosnippet>1002</a>            grid_dim.<span class="number">2</span>,
<a href=#1003 id=1003 data-nosnippet>1003</a>            block_dim.<span class="number">0</span>,
<a href=#1004 id=1004 data-nosnippet>1004</a>            block_dim.<span class="number">1</span>,
<a href=#1005 id=1005 data-nosnippet>1005</a>            block_dim.<span class="number">2</span>,
<a href=#1006 id=1006 data-nosnippet>1006</a>            shared_mem_bytes,
<a href=#1007 id=1007 data-nosnippet>1007</a>            stream,
<a href=#1008 id=1008 data-nosnippet>1008</a>            kernel_params.as_mut_ptr(),
<a href=#1009 id=1009 data-nosnippet>1009</a>            std::ptr::null_mut(),
<a href=#1010 id=1010 data-nosnippet>1010</a>        )
<a href=#1011 id=1011 data-nosnippet>1011</a>        .result()
<a href=#1012 id=1012 data-nosnippet>1012</a>}
<a href=#1013 id=1013 data-nosnippet>1013</a>
<a href=#1014 id=1014 data-nosnippet>1014</a><span class="doccomment">/// Launches a cuda functions
<a href=#1015 id=1015 data-nosnippet>1015</a>///
<a href=#1016 id=1016 data-nosnippet>1016</a>/// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html#group__CUDA__EXEC_1g06d753134145c4584c0c62525c1894cb)
<a href=#1017 id=1017 data-nosnippet>1017</a>///
<a href=#1018 id=1018 data-nosnippet>1018</a>/// # Safety
<a href=#1019 id=1019 data-nosnippet>1019</a>/// This method is **very unsafe**.
<a href=#1020 id=1020 data-nosnippet>1020</a>///
<a href=#1021 id=1021 data-nosnippet>1021</a>/// 1. The cuda function must be a valid handle returned from a non-unloaded module.
<a href=#1022 id=1022 data-nosnippet>1022</a>/// 2. This is asynchronous, so the results of calling this function happen
<a href=#1023 id=1023 data-nosnippet>1023</a>///    at a later point after this function returns.
<a href=#1024 id=1024 data-nosnippet>1024</a>/// 3. All parameters used for this kernel should have been allocated by stream (I think?)
<a href=#1025 id=1025 data-nosnippet>1025</a>/// 4. The cuda kernel has mutable access to every parameter, that means every parameter
<a href=#1026 id=1026 data-nosnippet>1026</a>///    can change at a later point after callign this function. *Even non-mutable references*.
<a href=#1027 id=1027 data-nosnippet>1027</a></span><span class="attr">#[inline]
<a href=#1028 id=1028 data-nosnippet>1028</a></span><span class="kw">pub unsafe fn </span>launch_cooperative_kernel(
<a href=#1029 id=1029 data-nosnippet>1029</a>    f: sys::CUfunction,
<a href=#1030 id=1030 data-nosnippet>1030</a>    grid_dim: (c_uint, c_uint, c_uint),
<a href=#1031 id=1031 data-nosnippet>1031</a>    block_dim: (c_uint, c_uint, c_uint),
<a href=#1032 id=1032 data-nosnippet>1032</a>    shared_mem_bytes: c_uint,
<a href=#1033 id=1033 data-nosnippet>1033</a>    stream: sys::CUstream,
<a href=#1034 id=1034 data-nosnippet>1034</a>    kernel_params: <span class="kw-2">&amp;mut </span>[<span class="kw-2">*mut </span>c_void],
<a href=#1035 id=1035 data-nosnippet>1035</a>) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#1036 id=1036 data-nosnippet>1036</a>    lib()
<a href=#1037 id=1037 data-nosnippet>1037</a>        .cuLaunchCooperativeKernel(
<a href=#1038 id=1038 data-nosnippet>1038</a>            f,
<a href=#1039 id=1039 data-nosnippet>1039</a>            grid_dim.<span class="number">0</span>,
<a href=#1040 id=1040 data-nosnippet>1040</a>            grid_dim.<span class="number">1</span>,
<a href=#1041 id=1041 data-nosnippet>1041</a>            grid_dim.<span class="number">2</span>,
<a href=#1042 id=1042 data-nosnippet>1042</a>            block_dim.<span class="number">0</span>,
<a href=#1043 id=1043 data-nosnippet>1043</a>            block_dim.<span class="number">1</span>,
<a href=#1044 id=1044 data-nosnippet>1044</a>            block_dim.<span class="number">2</span>,
<a href=#1045 id=1045 data-nosnippet>1045</a>            shared_mem_bytes,
<a href=#1046 id=1046 data-nosnippet>1046</a>            stream,
<a href=#1047 id=1047 data-nosnippet>1047</a>            kernel_params.as_mut_ptr(),
<a href=#1048 id=1048 data-nosnippet>1048</a>        )
<a href=#1049 id=1049 data-nosnippet>1049</a>        .result()
<a href=#1050 id=1050 data-nosnippet>1050</a>}
<a href=#1051 id=1051 data-nosnippet>1051</a>
<a href=#1052 id=1052 data-nosnippet>1052</a><span class="kw">pub mod </span>external_memory {
<a href=#1053 id=1053 data-nosnippet>1053</a>    <span class="kw">use </span>std::mem::MaybeUninit;
<a href=#1054 id=1054 data-nosnippet>1054</a>
<a href=#1055 id=1055 data-nosnippet>1055</a>    <span class="kw">use super</span>::{
<a href=#1056 id=1056 data-nosnippet>1056</a>        sys::{<span class="self">self</span>, lib},
<a href=#1057 id=1057 data-nosnippet>1057</a>        DriverError,
<a href=#1058 id=1058 data-nosnippet>1058</a>    };
<a href=#1059 id=1059 data-nosnippet>1059</a>
<a href=#1060 id=1060 data-nosnippet>1060</a>    <span class="doccomment">/// Imports an external memory object, in this case an OpaqueFd.
<a href=#1061 id=1061 data-nosnippet>1061</a>    ///
<a href=#1062 id=1062 data-nosnippet>1062</a>    /// The memory should be destroyed using [`destroy_external_memory`].
<a href=#1063 id=1063 data-nosnippet>1063</a>    ///
<a href=#1064 id=1064 data-nosnippet>1064</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXTRES__INTEROP.html#group__CUDA__EXTRES__INTEROP_1g52aba3a7f780157d8ba12972b2481735)
<a href=#1065 id=1065 data-nosnippet>1065</a>    ///
<a href=#1066 id=1066 data-nosnippet>1066</a>    /// # Safety
<a href=#1067 id=1067 data-nosnippet>1067</a>    /// `size` must be the size of the size of the memory object in bytes.
<a href=#1068 id=1068 data-nosnippet>1068</a>    </span><span class="attr">#[cfg(unix)]
<a href=#1069 id=1069 data-nosnippet>1069</a>    </span><span class="kw">pub unsafe fn </span>import_external_memory_opaque_fd(
<a href=#1070 id=1070 data-nosnippet>1070</a>        fd: std::os::fd::RawFd,
<a href=#1071 id=1071 data-nosnippet>1071</a>        size: u64,
<a href=#1072 id=1072 data-nosnippet>1072</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUexternalMemory, DriverError&gt; {
<a href=#1073 id=1073 data-nosnippet>1073</a>        <span class="kw">let </span><span class="kw-2">mut </span>external_memory = MaybeUninit::uninit();
<a href=#1074 id=1074 data-nosnippet>1074</a>        <span class="kw">let </span>handle_description = sys::CUDA_EXTERNAL_MEMORY_HANDLE_DESC {
<a href=#1075 id=1075 data-nosnippet>1075</a>            type_: sys::CUexternalMemoryHandleType::CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD,
<a href=#1076 id=1076 data-nosnippet>1076</a>            handle: sys::CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1 { fd },
<a href=#1077 id=1077 data-nosnippet>1077</a>            size,
<a href=#1078 id=1078 data-nosnippet>1078</a>            ..Default::default()
<a href=#1079 id=1079 data-nosnippet>1079</a>        };
<a href=#1080 id=1080 data-nosnippet>1080</a>        lib()
<a href=#1081 id=1081 data-nosnippet>1081</a>            .cuImportExternalMemory(external_memory.as_mut_ptr(), <span class="kw-2">&amp;</span>handle_description)
<a href=#1082 id=1082 data-nosnippet>1082</a>            .result()<span class="question-mark">?</span>;
<a href=#1083 id=1083 data-nosnippet>1083</a>        <span class="prelude-val">Ok</span>(external_memory.assume_init())
<a href=#1084 id=1084 data-nosnippet>1084</a>    }
<a href=#1085 id=1085 data-nosnippet>1085</a>
<a href=#1086 id=1086 data-nosnippet>1086</a>    <span class="doccomment">/// Imports an external memory object, in this case an OpaqueWin32 handle.
<a href=#1087 id=1087 data-nosnippet>1087</a>    ///
<a href=#1088 id=1088 data-nosnippet>1088</a>    /// The memory should be destroyed using [`destroy_external_memory`].
<a href=#1089 id=1089 data-nosnippet>1089</a>    ///
<a href=#1090 id=1090 data-nosnippet>1090</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXTRES__INTEROP.html#group__CUDA__EXTRES__INTEROP_1g52aba3a7f780157d8ba12972b2481735)
<a href=#1091 id=1091 data-nosnippet>1091</a>    ///
<a href=#1092 id=1092 data-nosnippet>1092</a>    /// # Safety
<a href=#1093 id=1093 data-nosnippet>1093</a>    /// `size` must be the size of the size of the memory object in bytes.
<a href=#1094 id=1094 data-nosnippet>1094</a>    </span><span class="attr">#[cfg(windows)]
<a href=#1095 id=1095 data-nosnippet>1095</a>    </span><span class="kw">pub unsafe fn </span>import_external_memory_opaque_win32(
<a href=#1096 id=1096 data-nosnippet>1096</a>        handle: std::os::windows::io::RawHandle,
<a href=#1097 id=1097 data-nosnippet>1097</a>        size: u64,
<a href=#1098 id=1098 data-nosnippet>1098</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUexternalMemory, DriverError&gt; {
<a href=#1099 id=1099 data-nosnippet>1099</a>        <span class="kw">let </span><span class="kw-2">mut </span>external_memory = MaybeUninit::uninit();
<a href=#1100 id=1100 data-nosnippet>1100</a>        <span class="kw">let </span>handle_description = sys::CUDA_EXTERNAL_MEMORY_HANDLE_DESC {
<a href=#1101 id=1101 data-nosnippet>1101</a>            type_: sys::CUexternalMemoryHandleType::CU_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32,
<a href=#1102 id=1102 data-nosnippet>1102</a>            handle: sys::CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1 {
<a href=#1103 id=1103 data-nosnippet>1103</a>                win32: sys::CUDA_EXTERNAL_MEMORY_HANDLE_DESC_st__bindgen_ty_1__bindgen_ty_1 {
<a href=#1104 id=1104 data-nosnippet>1104</a>                    handle,
<a href=#1105 id=1105 data-nosnippet>1105</a>                    name: std::ptr::null(),
<a href=#1106 id=1106 data-nosnippet>1106</a>                },
<a href=#1107 id=1107 data-nosnippet>1107</a>            },
<a href=#1108 id=1108 data-nosnippet>1108</a>            size,
<a href=#1109 id=1109 data-nosnippet>1109</a>            ..Default::default()
<a href=#1110 id=1110 data-nosnippet>1110</a>        };
<a href=#1111 id=1111 data-nosnippet>1111</a>        lib()
<a href=#1112 id=1112 data-nosnippet>1112</a>            .cuImportExternalMemory(external_memory.as_mut_ptr(), <span class="kw-2">&amp;</span>handle_description)
<a href=#1113 id=1113 data-nosnippet>1113</a>            .result()<span class="question-mark">?</span>;
<a href=#1114 id=1114 data-nosnippet>1114</a>        <span class="prelude-val">Ok</span>(external_memory.assume_init())
<a href=#1115 id=1115 data-nosnippet>1115</a>    }
<a href=#1116 id=1116 data-nosnippet>1116</a>
<a href=#1117 id=1117 data-nosnippet>1117</a>    <span class="doccomment">/// Destroys an external memory object.
<a href=#1118 id=1118 data-nosnippet>1118</a>    ///
<a href=#1119 id=1119 data-nosnippet>1119</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXTRES__INTEROP.html#group__CUDA__EXTRES__INTEROP_1g1b586dda86565617e7e0883b956c7052)
<a href=#1120 id=1120 data-nosnippet>1120</a>    ///
<a href=#1121 id=1121 data-nosnippet>1121</a>    /// # Safety
<a href=#1122 id=1122 data-nosnippet>1122</a>    /// 1. Any mapped buffers onto this object must already be freed.
<a href=#1123 id=1123 data-nosnippet>1123</a>    /// 2. The external memory must only be destroyed once.
<a href=#1124 id=1124 data-nosnippet>1124</a>    </span><span class="kw">pub unsafe fn </span>destroy_external_memory(
<a href=#1125 id=1125 data-nosnippet>1125</a>        external_memory: sys::CUexternalMemory,
<a href=#1126 id=1126 data-nosnippet>1126</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;(), DriverError&gt; {
<a href=#1127 id=1127 data-nosnippet>1127</a>        lib().cuDestroyExternalMemory(external_memory).result()
<a href=#1128 id=1128 data-nosnippet>1128</a>    }
<a href=#1129 id=1129 data-nosnippet>1129</a>
<a href=#1130 id=1130 data-nosnippet>1130</a>    <span class="doccomment">/// Maps a buffer onto an imported memory object.
<a href=#1131 id=1131 data-nosnippet>1131</a>    ///
<a href=#1132 id=1132 data-nosnippet>1132</a>    /// The buffer must be freed using [`memory_free`](super::memory_free).
<a href=#1133 id=1133 data-nosnippet>1133</a>    ///
<a href=#1134 id=1134 data-nosnippet>1134</a>    /// See [cuda docs](https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXTRES__INTEROP.html#group__CUDA__EXTRES__INTEROP_1gb9fec33920400c70961b4e33d838da91)
<a href=#1135 id=1135 data-nosnippet>1135</a>    ///
<a href=#1136 id=1136 data-nosnippet>1136</a>    /// # Safety
<a href=#1137 id=1137 data-nosnippet>1137</a>    /// Mapped buffers may overlap.
<a href=#1138 id=1138 data-nosnippet>1138</a>    </span><span class="kw">pub unsafe fn </span>get_mapped_buffer(
<a href=#1139 id=1139 data-nosnippet>1139</a>        external_memory: sys::CUexternalMemory,
<a href=#1140 id=1140 data-nosnippet>1140</a>        offset: u64,
<a href=#1141 id=1141 data-nosnippet>1141</a>        size: u64,
<a href=#1142 id=1142 data-nosnippet>1142</a>    ) -&gt; <span class="prelude-ty">Result</span>&lt;sys::CUdeviceptr, DriverError&gt; {
<a href=#1143 id=1143 data-nosnippet>1143</a>        <span class="kw">let </span><span class="kw-2">mut </span>device_ptr = MaybeUninit::uninit();
<a href=#1144 id=1144 data-nosnippet>1144</a>        <span class="kw">let </span>buffer_description = sys::CUDA_EXTERNAL_MEMORY_BUFFER_DESC {
<a href=#1145 id=1145 data-nosnippet>1145</a>            offset,
<a href=#1146 id=1146 data-nosnippet>1146</a>            size,
<a href=#1147 id=1147 data-nosnippet>1147</a>            ..Default::default()
<a href=#1148 id=1148 data-nosnippet>1148</a>        };
<a href=#1149 id=1149 data-nosnippet>1149</a>        lib()
<a href=#1150 id=1150 data-nosnippet>1150</a>            .cuExternalMemoryGetMappedBuffer(
<a href=#1151 id=1151 data-nosnippet>1151</a>                device_ptr.as_mut_ptr(),
<a href=#1152 id=1152 data-nosnippet>1152</a>                external_memory,
<a href=#1153 id=1153 data-nosnippet>1153</a>                <span class="kw-2">&amp;</span>buffer_description,
<a href=#1154 id=1154 data-nosnippet>1154</a>            )
<a href=#1155 id=1155 data-nosnippet>1155</a>            .result()<span class="question-mark">?</span>;
<a href=#1156 id=1156 data-nosnippet>1156</a>        <span class="prelude-val">Ok</span>(device_ptr.assume_init())
<a href=#1157 id=1157 data-nosnippet>1157</a>    }
<a href=#1158 id=1158 data-nosnippet>1158</a>}</code></pre></div></section></main></body></html>